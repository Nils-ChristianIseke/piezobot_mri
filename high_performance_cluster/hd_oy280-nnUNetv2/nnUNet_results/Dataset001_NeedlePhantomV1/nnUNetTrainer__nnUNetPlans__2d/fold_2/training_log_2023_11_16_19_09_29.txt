
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 44, 'patch_size': [56, 40], 'median_image_size_in_voxels': [56.0, 36.0], 'spacing': [1.46875, 1.46875], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'num_pool_per_axis': [3, 3], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_NeedlePhantomV1', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.419999837875366, 1.46875, 1.46875], 'original_median_shape_after_transp': [22, 56, 36], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1610.0, 'mean': 465.1097412109375, 'median': 478.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 1246.0, 'std': 241.4937744140625}}} 
 
2023-11-16 19:09:30.751176: unpacking dataset... 
2023-11-16 19:09:37.385905: unpacking done... 
2023-11-16 19:09:37.386529: do_dummy_2d_data_aug: False 
2023-11-16 19:09:37.387211: Using splits from existing split file: /workspace/nnUNet_preprocessed/Dataset001_NeedlePhantomV1/splits_final.json 
2023-11-16 19:09:37.387661: The split file contains 5 splits. 
2023-11-16 19:09:37.387847: Desired fold for training: 2 
2023-11-16 19:09:37.388013: This split has 36 training and 8 validation cases. 
2023-11-16 19:09:47.895604: Unable to plot network architecture: 
2023-11-16 19:09:47.896137: 'torch._C.Node' object is not subscriptable 
2023-11-16 19:09:47.919117:  
2023-11-16 19:09:47.919340: Epoch 0 
2023-11-16 19:09:47.919651: Current learning rate: 0.01 
2023-11-16 19:10:00.740698: train_loss -0.0835 
2023-11-16 19:10:00.741273: val_loss -0.5615 
2023-11-16 19:10:00.744204: Pseudo dice [0.6847, 0.8324, 0.9497, 0.0, 0.9143] 
2023-11-16 19:10:00.744587: Epoch time: 12.81 s 
2023-11-16 19:10:00.744867: Yayy! New best EMA pseudo Dice: 0.6762 
2023-11-16 19:10:02.080918:  
2023-11-16 19:10:02.081206: Epoch 1 
2023-11-16 19:10:02.081449: Current learning rate: 0.00999 
2023-11-16 19:10:09.408519: train_loss -0.5835 
2023-11-16 19:10:09.409073: val_loss -0.6477 
2023-11-16 19:10:09.409451: Pseudo dice [0.7906, 0.8998, 0.9582, 0.0, 0.92] 
2023-11-16 19:10:09.409852: Epoch time: 7.33 s 
2023-11-16 19:10:09.411573: Yayy! New best EMA pseudo Dice: 0.68 
2023-11-16 19:10:10.499369:  
2023-11-16 19:10:10.499659: Epoch 2 
2023-11-16 19:10:10.499895: Current learning rate: 0.00998 
2023-11-16 19:10:17.581780: train_loss -0.638 
2023-11-16 19:10:17.582185: val_loss -0.6676 
2023-11-16 19:10:17.582472: Pseudo dice [0.8211, 0.9113, 0.9635, 0.0, 0.9275] 
2023-11-16 19:10:17.582776: Epoch time: 7.08 s 
2023-11-16 19:10:17.583097: Yayy! New best EMA pseudo Dice: 0.6844 
2023-11-16 19:10:18.719274:  
2023-11-16 19:10:18.719588: Epoch 3 
2023-11-16 19:10:18.719868: Current learning rate: 0.00997 
