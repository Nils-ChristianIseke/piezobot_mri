
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [24, 56, 40], 'median_image_size_in_voxels': [22.0, 56.0, 36.0], 'spacing': [2.419999837875366, 1.46875, 1.46875], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'num_pool_per_axis': [2, 3, 3], 'pool_op_kernel_sizes': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 320, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_NeedlePhantomV1', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.419999837875366, 1.46875, 1.46875], 'original_median_shape_after_transp': [22, 56, 36], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1610.0, 'mean': 465.1097412109375, 'median': 478.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 1246.0, 'std': 241.4937744140625}}} 
 
2023-10-26 15:22:39.651284: unpacking dataset... 
2023-10-26 15:22:49.459022: unpacking done... 
2023-10-26 15:22:49.460234: do_dummy_2d_data_aug: False 
2023-10-26 15:22:49.461439: Using splits from existing split file: /workspace/nnUNet_preprocessed/Dataset001_NeedlePhantomV1/splits_final.json 
2023-10-26 15:22:49.462229: The split file contains 5 splits. 
2023-10-26 15:22:49.462506: Desired fold for training: 2 
2023-10-26 15:22:49.462775: This split has 36 training and 8 validation cases. 
2023-10-26 15:23:01.840235: Unable to plot network architecture: 
2023-10-26 15:23:01.840832: 'torch._C.Node' object is not subscriptable 
2023-10-26 15:23:01.866635:  
2023-10-26 15:23:01.866925: Epoch 0 
2023-10-26 15:23:01.867242: Current learning rate: 0.01 
2023-10-26 15:23:10.968354: train_loss -0.1244 
2023-10-26 15:23:10.968745: val_loss -0.4356 
2023-10-26 15:23:10.969023: Pseudo dice [0.722, 0.8591, 0.9484, 0.0, 0.8414] 
2023-10-26 15:23:10.969255: Epoch time: 9.1 s 
2023-10-26 15:23:10.969481: Yayy! New best EMA pseudo Dice: 0.6742 
2023-10-26 15:23:12.191057:  
2023-10-26 15:23:12.191352: Epoch 1 
2023-10-26 15:23:12.191586: Current learning rate: 0.00999 
2023-10-26 15:23:16.567276: train_loss -0.5464 
2023-10-26 15:23:16.567721: val_loss -0.5391 
2023-10-26 15:23:16.568017: Pseudo dice [0.755, 0.8692, 0.9583, 0.0, 0.9013] 
2023-10-26 15:23:16.568251: Epoch time: 4.38 s 
2023-10-26 15:23:16.568464: Yayy! New best EMA pseudo Dice: 0.6764 
2023-10-26 15:23:17.646668:  
2023-10-26 15:23:17.647000: Epoch 2 
2023-10-26 15:23:17.647388: Current learning rate: 0.00998 
2023-10-26 15:23:21.951320: train_loss -0.6608 
2023-10-26 15:23:21.951836: val_loss -0.6457 
2023-10-26 15:23:21.952156: Pseudo dice [0.7947, 0.8867, 0.9615, 0.0, 0.8934] 
2023-10-26 15:23:21.952392: Epoch time: 4.31 s 
2023-10-26 15:23:21.952627: Yayy! New best EMA pseudo Dice: 0.6795 
2023-10-26 15:23:23.286334:  
2023-10-26 15:23:23.286680: Epoch 3 
2023-10-26 15:23:23.286989: Current learning rate: 0.00997 
2023-10-26 15:23:27.587536: train_loss -0.6912 
2023-10-26 15:23:27.587930: val_loss -0.6404 
2023-10-26 15:23:27.588205: Pseudo dice [0.7955, 0.9009, 0.9612, 0.0, 0.8996] 
2023-10-26 15:23:27.588441: Epoch time: 4.3 s 
2023-10-26 15:23:27.588643: Yayy! New best EMA pseudo Dice: 0.6827 
2023-10-26 15:23:28.745198:  
2023-10-26 15:23:28.745565: Epoch 4 
2023-10-26 15:23:28.745905: Current learning rate: 0.00996 
2023-10-26 15:23:32.838807: train_loss -0.7087 
2023-10-26 15:23:32.839236: val_loss -0.6567 
2023-10-26 15:23:32.839502: Pseudo dice [0.811, 0.9047, 0.9625, 0.0, 0.9165] 
2023-10-26 15:23:32.839744: Epoch time: 4.09 s 
2023-10-26 15:23:32.839977: Yayy! New best EMA pseudo Dice: 0.6863 
2023-10-26 15:23:34.032277:  
2023-10-26 15:23:34.032569: Epoch 5 
2023-10-26 15:23:34.032814: Current learning rate: 0.00995 
2023-10-26 15:23:38.449946: train_loss -0.7154 
2023-10-26 15:23:38.450381: val_loss -0.65 
2023-10-26 15:23:38.450651: Pseudo dice [0.8235, 0.8984, 0.9611, 0.0, 0.9188] 
2023-10-26 15:23:38.450899: Epoch time: 4.42 s 
2023-10-26 15:23:38.451122: Yayy! New best EMA pseudo Dice: 0.6897 
2023-10-26 15:23:39.538948:  
2023-10-26 15:23:39.539241: Epoch 6 
2023-10-26 15:23:39.539483: Current learning rate: 0.00995 
2023-10-26 15:23:43.837605: train_loss -0.7262 
2023-10-26 15:23:43.838000: val_loss -0.6685 
2023-10-26 15:23:43.838261: Pseudo dice [0.821, 0.9095, 0.9673, 0.0, 0.9253] 
2023-10-26 15:23:43.838495: Epoch time: 4.3 s 
2023-10-26 15:23:43.838700: Yayy! New best EMA pseudo Dice: 0.6932 
2023-10-26 15:23:44.948982:  
2023-10-26 15:23:44.949286: Epoch 7 
2023-10-26 15:23:44.949527: Current learning rate: 0.00994 
2023-10-26 15:23:49.289458: train_loss -0.7733 
2023-10-26 15:23:49.289884: val_loss -0.7203 
2023-10-26 15:23:49.290148: Pseudo dice [0.831, 0.9061, 0.964, 0.0, 0.9111] 
2023-10-26 15:23:49.290385: Epoch time: 4.34 s 
2023-10-26 15:23:49.290586: Yayy! New best EMA pseudo Dice: 0.6961 
2023-10-26 15:23:50.438497:  
2023-10-26 15:23:50.438837: Epoch 8 
2023-10-26 15:23:50.439081: Current learning rate: 0.00993 
2023-10-26 15:23:54.682032: train_loss -0.7973 
2023-10-26 15:23:54.682406: val_loss -0.7308 
2023-10-26 15:23:54.682664: Pseudo dice [0.8361, 0.909, 0.9671, 0.0, 0.9255] 
2023-10-26 15:23:54.682896: Epoch time: 4.24 s 
2023-10-26 15:23:54.683100: Yayy! New best EMA pseudo Dice: 0.6993 
2023-10-26 15:23:56.077940:  
2023-10-26 15:23:56.078335: Epoch 9 
2023-10-26 15:23:56.078666: Current learning rate: 0.00992 
2023-10-26 15:24:00.371244: train_loss -0.7947 
2023-10-26 15:24:00.371916: val_loss -0.741 
2023-10-26 15:24:00.372188: Pseudo dice [0.8375, 0.9103, 0.9677, 0.0, 0.9158] 
2023-10-26 15:24:00.372472: Epoch time: 4.29 s 
2023-10-26 15:24:00.372707: Yayy! New best EMA pseudo Dice: 0.702 
2023-10-26 15:24:01.542801:  
2023-10-26 15:24:01.543125: Epoch 10 
2023-10-26 15:24:01.543380: Current learning rate: 0.00991 
2023-10-26 15:24:05.772739: train_loss -0.7993 
2023-10-26 15:24:05.773126: val_loss -0.7497 
2023-10-26 15:24:05.773444: Pseudo dice [0.8398, 0.9123, 0.9652, 0.0, 0.9262] 
2023-10-26 15:24:05.773693: Epoch time: 4.23 s 
2023-10-26 15:24:05.773921: Yayy! New best EMA pseudo Dice: 0.7047 
2023-10-26 15:24:06.910674:  
2023-10-26 15:24:06.911026: Epoch 11 
2023-10-26 15:24:06.911364: Current learning rate: 0.0099 
2023-10-26 15:24:11.187799: train_loss -0.8021 
2023-10-26 15:24:11.188238: val_loss -0.7465 
2023-10-26 15:24:11.188506: Pseudo dice [0.853, 0.9032, 0.9669, 0.0, 0.9275] 
2023-10-26 15:24:11.188742: Epoch time: 4.28 s 
2023-10-26 15:24:11.188988: Yayy! New best EMA pseudo Dice: 0.7072 
2023-10-26 15:24:12.344122:  
2023-10-26 15:24:12.344716: Epoch 12 
2023-10-26 15:24:12.345155: Current learning rate: 0.00989 
2023-10-26 15:24:16.716495: train_loss -0.8021 
2023-10-26 15:24:16.716911: val_loss -0.7424 
2023-10-26 15:24:16.717190: Pseudo dice [0.8448, 0.9115, 0.9686, 0.0, 0.9231] 
2023-10-26 15:24:16.717452: Epoch time: 4.37 s 
2023-10-26 15:24:16.717661: Yayy! New best EMA pseudo Dice: 0.7094 
2023-10-26 15:24:17.878963:  
2023-10-26 15:24:17.879299: Epoch 13 
2023-10-26 15:24:17.879564: Current learning rate: 0.00988 
2023-10-26 15:24:22.212348: train_loss -0.8133 
2023-10-26 15:24:22.212743: val_loss -0.7495 
2023-10-26 15:24:22.213010: Pseudo dice [0.8414, 0.9135, 0.9636, 0.0, 0.9183] 
2023-10-26 15:24:22.213246: Epoch time: 4.33 s 
2023-10-26 15:24:22.213458: Yayy! New best EMA pseudo Dice: 0.7112 
2023-10-26 15:24:23.332140:  
2023-10-26 15:24:23.332453: Epoch 14 
2023-10-26 15:24:23.332722: Current learning rate: 0.00987 
2023-10-26 15:24:27.618158: train_loss -0.8117 
2023-10-26 15:24:27.618648: val_loss -0.7572 
2023-10-26 15:24:27.618900: Pseudo dice [0.8544, 0.9143, 0.9674, 0.0, 0.9303] 
2023-10-26 15:24:27.619126: Epoch time: 4.29 s 
2023-10-26 15:24:27.619332: Yayy! New best EMA pseudo Dice: 0.7134 
2023-10-26 15:24:28.743217:  
2023-10-26 15:24:28.743551: Epoch 15 
2023-10-26 15:24:28.743791: Current learning rate: 0.00986 
2023-10-26 15:24:32.891520: train_loss -0.8192 
2023-10-26 15:24:32.891907: val_loss -0.7504 
2023-10-26 15:24:32.892169: Pseudo dice [0.8487, 0.9003, 0.9651, 0.0, 0.9243] 
2023-10-26 15:24:32.892396: Epoch time: 4.15 s 
2023-10-26 15:24:32.892614: Yayy! New best EMA pseudo Dice: 0.7149 
2023-10-26 15:24:34.227840:  
2023-10-26 15:24:34.228153: Epoch 16 
2023-10-26 15:24:34.228411: Current learning rate: 0.00986 
2023-10-26 15:24:38.557178: train_loss -0.8024 
2023-10-26 15:24:38.557577: val_loss -0.7558 
2023-10-26 15:24:38.557822: Pseudo dice [0.8514, 0.914, 0.9683, 0.0, 0.9311] 
2023-10-26 15:24:38.558059: Epoch time: 4.33 s 
2023-10-26 15:24:38.558258: Yayy! New best EMA pseudo Dice: 0.7167 
2023-10-26 15:24:39.702250:  
2023-10-26 15:24:39.702580: Epoch 17 
2023-10-26 15:24:39.702863: Current learning rate: 0.00985 
2023-10-26 15:24:43.942726: train_loss -0.8109 
2023-10-26 15:24:43.943160: val_loss -0.7447 
2023-10-26 15:24:43.943442: Pseudo dice [0.8429, 0.9099, 0.9667, 0.0, 0.9272] 
2023-10-26 15:24:43.943696: Epoch time: 4.24 s 
2023-10-26 15:24:43.943913: Yayy! New best EMA pseudo Dice: 0.7179 
2023-10-26 15:24:45.092793:  
2023-10-26 15:24:45.093092: Epoch 18 
2023-10-26 15:24:45.093328: Current learning rate: 0.00984 
2023-10-26 15:24:49.275083: train_loss -0.8177 
2023-10-26 15:24:49.275493: val_loss -0.753 
2023-10-26 15:24:49.275785: Pseudo dice [0.8566, 0.9141, 0.9663, 0.0, 0.9295] 
2023-10-26 15:24:49.276056: Epoch time: 4.18 s 
2023-10-26 15:24:49.276315: Yayy! New best EMA pseudo Dice: 0.7195 
2023-10-26 15:24:50.431210:  
2023-10-26 15:24:50.431521: Epoch 19 
2023-10-26 15:24:50.431771: Current learning rate: 0.00983 
2023-10-26 15:24:54.561856: train_loss -0.8166 
2023-10-26 15:24:54.562259: val_loss -0.7237 
2023-10-26 15:24:54.562510: Pseudo dice [0.8309, 0.9035, 0.9648, 0.0, 0.9045] 
2023-10-26 15:24:54.562739: Epoch time: 4.13 s 
2023-10-26 15:24:54.562939: Yayy! New best EMA pseudo Dice: 0.7196 
2023-10-26 15:24:55.802817:  
2023-10-26 15:24:55.803123: Epoch 20 
2023-10-26 15:24:55.803370: Current learning rate: 0.00982 
2023-10-26 15:24:59.963156: train_loss -0.8127 
2023-10-26 15:24:59.963762: val_loss -0.7463 
2023-10-26 15:24:59.964054: Pseudo dice [0.841, 0.9136, 0.9676, 0.0, 0.9101] 
2023-10-26 15:24:59.964297: Epoch time: 4.16 s 
2023-10-26 15:24:59.964506: Yayy! New best EMA pseudo Dice: 0.7203 
2023-10-26 15:25:01.133019:  
2023-10-26 15:25:01.133322: Epoch 21 
2023-10-26 15:25:01.133563: Current learning rate: 0.00981 
2023-10-26 15:25:05.614937: train_loss -0.8214 
2023-10-26 15:25:05.615306: val_loss -0.7396 
2023-10-26 15:25:05.615575: Pseudo dice [0.8456, 0.911, 0.9634, 0.0, 0.933] 
2023-10-26 15:25:05.615805: Epoch time: 4.48 s 
2023-10-26 15:25:05.616011: Yayy! New best EMA pseudo Dice: 0.7213 
2023-10-26 15:25:06.719794:  
2023-10-26 15:25:06.720109: Epoch 22 
2023-10-26 15:25:06.720353: Current learning rate: 0.0098 
2023-10-26 15:25:10.950395: train_loss -0.8258 
2023-10-26 15:25:10.950764: val_loss -0.7476 
2023-10-26 15:25:10.951035: Pseudo dice [0.8423, 0.9112, 0.9651, 0.0, 0.9257] 
2023-10-26 15:25:10.951268: Epoch time: 4.23 s 
2023-10-26 15:25:10.951470: Yayy! New best EMA pseudo Dice: 0.7221 
2023-10-26 15:25:12.056265:  
2023-10-26 15:25:12.056563: Epoch 23 
2023-10-26 15:25:12.056809: Current learning rate: 0.00979 
2023-10-26 15:25:16.472360: train_loss -0.8176 
2023-10-26 15:25:16.472807: val_loss -0.7519 
2023-10-26 15:25:16.473086: Pseudo dice [0.8493, 0.9151, 0.9653, 0.0, 0.9334] 
2023-10-26 15:25:16.473337: Epoch time: 4.42 s 
2023-10-26 15:25:16.473590: Yayy! New best EMA pseudo Dice: 0.7231 
2023-10-26 15:25:17.610068:  
2023-10-26 15:25:17.610429: Epoch 24 
2023-10-26 15:25:17.610740: Current learning rate: 0.00978 
2023-10-26 15:25:21.912554: train_loss -0.8211 
2023-10-26 15:25:21.913063: val_loss -0.7724 
2023-10-26 15:25:21.913581: Pseudo dice [0.8661, 0.9217, 0.9675, 0.0, 0.9241] 
2023-10-26 15:25:21.913953: Epoch time: 4.3 s 
2023-10-26 15:25:21.914300: Yayy! New best EMA pseudo Dice: 0.7244 
2023-10-26 15:25:23.062309:  
2023-10-26 15:25:23.062642: Epoch 25 
2023-10-26 15:25:23.062902: Current learning rate: 0.00977 
2023-10-26 15:25:27.289003: train_loss -0.8167 
2023-10-26 15:25:27.289428: val_loss -0.7668 
2023-10-26 15:25:27.289709: Pseudo dice [0.8528, 0.9194, 0.9682, 0.0, 0.9341] 
2023-10-26 15:25:27.289960: Epoch time: 4.23 s 
2023-10-26 15:25:27.290184: Yayy! New best EMA pseudo Dice: 0.7255 
2023-10-26 15:25:28.445529:  
2023-10-26 15:25:28.445805: Epoch 26 
2023-10-26 15:25:28.446069: Current learning rate: 0.00977 
2023-10-26 15:25:32.721885: train_loss -0.8205 
2023-10-26 15:25:32.722374: val_loss -0.7497 
2023-10-26 15:25:32.722638: Pseudo dice [0.8499, 0.9163, 0.9681, 0.0, 0.9333] 
2023-10-26 15:25:32.722881: Epoch time: 4.28 s 
2023-10-26 15:25:32.723125: Yayy! New best EMA pseudo Dice: 0.7263 
2023-10-26 15:25:33.846692:  
2023-10-26 15:25:33.847264: Epoch 27 
2023-10-26 15:25:33.847644: Current learning rate: 0.00976 
2023-10-26 15:25:37.945671: train_loss -0.8197 
2023-10-26 15:25:37.946043: val_loss -0.7497 
2023-10-26 15:25:37.946326: Pseudo dice [0.837, 0.9173, 0.9688, 0.0, 0.9282] 
2023-10-26 15:25:37.946553: Epoch time: 4.1 s 
2023-10-26 15:25:37.946763: Yayy! New best EMA pseudo Dice: 0.7267 
2023-10-26 15:25:39.226046:  
2023-10-26 15:25:39.226331: Epoch 28 
2023-10-26 15:25:39.226567: Current learning rate: 0.00975 
2023-10-26 15:25:43.306489: train_loss -0.8259 
2023-10-26 15:25:43.306932: val_loss -0.7407 
2023-10-26 15:25:43.307231: Pseudo dice [0.8494, 0.9164, 0.9658, 0.0, 0.9088] 
2023-10-26 15:25:43.307470: Epoch time: 4.08 s 
2023-10-26 15:25:43.307683: Yayy! New best EMA pseudo Dice: 0.7268 
2023-10-26 15:25:44.441105:  
2023-10-26 15:25:44.441404: Epoch 29 
2023-10-26 15:25:44.441640: Current learning rate: 0.00974 
2023-10-26 15:25:48.722329: train_loss -0.8173 
2023-10-26 15:25:48.722716: val_loss -0.7622 
2023-10-26 15:25:48.722971: Pseudo dice [0.8643, 0.9175, 0.9675, 0.0, 0.9334] 
2023-10-26 15:25:48.723208: Epoch time: 4.28 s 
2023-10-26 15:25:48.723423: Yayy! New best EMA pseudo Dice: 0.7278 
2023-10-26 15:25:49.858831:  
2023-10-26 15:25:49.859137: Epoch 30 
2023-10-26 15:25:49.859399: Current learning rate: 0.00973 
2023-10-26 15:25:54.312474: train_loss -0.8241 
2023-10-26 15:25:54.312819: val_loss -0.7096 
2023-10-26 15:25:54.313068: Pseudo dice [0.8458, 0.912, 0.9672, 0.0, 0.9117] 
2023-10-26 15:25:54.313288: Epoch time: 4.45 s 
2023-10-26 15:25:55.349018:  
2023-10-26 15:25:55.349300: Epoch 31 
2023-10-26 15:25:55.349554: Current learning rate: 0.00972 
2023-10-26 15:25:59.731203: train_loss -0.8105 
2023-10-26 15:25:59.731614: val_loss -0.7334 
2023-10-26 15:25:59.731894: Pseudo dice [0.8539, 0.9223, 0.9669, 0.0, 0.9294] 
2023-10-26 15:25:59.732128: Epoch time: 4.38 s 
2023-10-26 15:25:59.732323: Yayy! New best EMA pseudo Dice: 0.7284 
2023-10-26 15:26:00.828956:  
2023-10-26 15:26:00.829271: Epoch 32 
2023-10-26 15:26:00.829589: Current learning rate: 0.00971 
2023-10-26 15:26:05.099137: train_loss -0.8138 
2023-10-26 15:26:05.099505: val_loss -0.7501 
2023-10-26 15:26:05.099788: Pseudo dice [0.8579, 0.9184, 0.9672, 0.0, 0.9275] 
2023-10-26 15:26:05.100021: Epoch time: 4.27 s 
2023-10-26 15:26:05.100226: Yayy! New best EMA pseudo Dice: 0.729 
2023-10-26 15:26:06.314765:  
2023-10-26 15:26:06.315053: Epoch 33 
2023-10-26 15:26:06.315290: Current learning rate: 0.0097 
2023-10-26 15:26:10.612792: train_loss -0.8142 
2023-10-26 15:26:10.613178: val_loss -0.7456 
2023-10-26 15:26:10.613438: Pseudo dice [0.8562, 0.9157, 0.9663, 0.0, 0.921] 
2023-10-26 15:26:10.613657: Epoch time: 4.3 s 
2023-10-26 15:26:10.613863: Yayy! New best EMA pseudo Dice: 0.7293 
2023-10-26 15:26:11.875043:  
2023-10-26 15:26:11.875334: Epoch 34 
2023-10-26 15:26:11.875582: Current learning rate: 0.00969 
2023-10-26 15:26:16.180668: train_loss -0.8201 
2023-10-26 15:26:16.181083: val_loss -0.7395 
2023-10-26 15:26:16.181385: Pseudo dice [0.8491, 0.9204, 0.9657, 0.0, 0.9272] 
2023-10-26 15:26:16.181633: Epoch time: 4.31 s 
2023-10-26 15:26:16.181848: Yayy! New best EMA pseudo Dice: 0.7296 
2023-10-26 15:26:17.376102:  
2023-10-26 15:26:17.376405: Epoch 35 
2023-10-26 15:26:17.376655: Current learning rate: 0.00968 
2023-10-26 15:26:21.587866: train_loss -0.81 
2023-10-26 15:26:21.588211: val_loss -0.7494 
2023-10-26 15:26:21.588462: Pseudo dice [0.8387, 0.9166, 0.9687, 0.0, 0.9214] 
2023-10-26 15:26:21.588706: Epoch time: 4.21 s 
2023-10-26 15:26:22.651226:  
2023-10-26 15:26:22.651513: Epoch 36 
2023-10-26 15:26:22.651747: Current learning rate: 0.00968 
2023-10-26 15:26:26.896247: train_loss -0.8187 
2023-10-26 15:26:26.896641: val_loss -0.7548 
2023-10-26 15:26:26.896909: Pseudo dice [0.8531, 0.921, 0.9677, 0.0, 0.9309] 
2023-10-26 15:26:26.897155: Epoch time: 4.25 s 
2023-10-26 15:26:26.897364: Yayy! New best EMA pseudo Dice: 0.73 
2023-10-26 15:26:28.052560:  
2023-10-26 15:26:28.052865: Epoch 37 
2023-10-26 15:26:28.053109: Current learning rate: 0.00967 
2023-10-26 15:26:32.191923: train_loss -0.8296 
2023-10-26 15:26:32.192266: val_loss -0.7435 
2023-10-26 15:26:32.192516: Pseudo dice [0.8455, 0.922, 0.9661, 0.0, 0.9161] 
2023-10-26 15:26:32.192806: Epoch time: 4.14 s 
2023-10-26 15:26:33.265393:  
2023-10-26 15:26:33.265687: Epoch 38 
2023-10-26 15:26:33.265944: Current learning rate: 0.00966 
2023-10-26 15:26:37.708234: train_loss -0.8245 
2023-10-26 15:26:37.708710: val_loss -0.7538 
2023-10-26 15:26:37.709040: Pseudo dice [0.8549, 0.9176, 0.9677, 0.0, 0.9342] 
2023-10-26 15:26:37.709430: Epoch time: 4.44 s 
2023-10-26 15:26:37.709753: Yayy! New best EMA pseudo Dice: 0.7305 
2023-10-26 15:26:38.860549:  
2023-10-26 15:26:38.860858: Epoch 39 
2023-10-26 15:26:38.861186: Current learning rate: 0.00965 
2023-10-26 15:26:43.272217: train_loss -0.827 
2023-10-26 15:26:43.272563: val_loss -0.7603 
2023-10-26 15:26:43.272823: Pseudo dice [0.8551, 0.9242, 0.9682, 0.0, 0.9281] 
2023-10-26 15:26:43.273071: Epoch time: 4.41 s 
2023-10-26 15:26:43.273293: Yayy! New best EMA pseudo Dice: 0.731 
2023-10-26 15:26:44.588166:  
2023-10-26 15:26:44.588529: Epoch 40 
2023-10-26 15:26:44.588787: Current learning rate: 0.00964 
2023-10-26 15:26:48.842175: train_loss -0.8245 
2023-10-26 15:26:48.842558: val_loss -0.7362 
2023-10-26 15:26:48.842820: Pseudo dice [0.8352, 0.9146, 0.9663, 0.0, 0.9298] 
2023-10-26 15:26:48.843059: Epoch time: 4.25 s 
2023-10-26 15:26:49.928386:  
2023-10-26 15:26:49.928768: Epoch 41 
2023-10-26 15:26:49.929032: Current learning rate: 0.00963 
2023-10-26 15:26:54.149204: train_loss -0.8255 
2023-10-26 15:26:54.149621: val_loss -0.743 
2023-10-26 15:26:54.149901: Pseudo dice [0.8469, 0.9227, 0.9646, 0.0, 0.9308] 
2023-10-26 15:26:54.150147: Epoch time: 4.22 s 
2023-10-26 15:26:54.150380: Yayy! New best EMA pseudo Dice: 0.731 
2023-10-26 15:26:55.305653:  
2023-10-26 15:26:55.305980: Epoch 42 
2023-10-26 15:26:55.306235: Current learning rate: 0.00962 
2023-10-26 15:26:59.501040: train_loss -0.8185 
2023-10-26 15:26:59.501433: val_loss -0.7434 
2023-10-26 15:26:59.501691: Pseudo dice [0.8442, 0.9183, 0.968, 0.0, 0.9275] 
2023-10-26 15:26:59.501971: Epoch time: 4.2 s 
2023-10-26 15:26:59.502184: Yayy! New best EMA pseudo Dice: 0.7311 
2023-10-26 15:27:00.629308:  
2023-10-26 15:27:00.629626: Epoch 43 
2023-10-26 15:27:00.629893: Current learning rate: 0.00961 
2023-10-26 15:27:04.956787: train_loss -0.8296 
2023-10-26 15:27:04.957760: val_loss -0.756 
2023-10-26 15:27:04.958050: Pseudo dice [0.855, 0.9175, 0.9667, 0.0, 0.9197] 
2023-10-26 15:27:04.958494: Epoch time: 4.33 s 
2023-10-26 15:27:04.958712: Yayy! New best EMA pseudo Dice: 0.7311 
2023-10-26 15:27:06.092164:  
2023-10-26 15:27:06.092456: Epoch 44 
2023-10-26 15:27:06.092695: Current learning rate: 0.0096 
2023-10-26 15:27:10.377869: train_loss -0.8404 
2023-10-26 15:27:10.378434: val_loss -0.7719 
2023-10-26 15:27:10.378898: Pseudo dice [0.8635, 0.9242, 0.9695, 0.0, 0.9285] 
2023-10-26 15:27:10.379344: Epoch time: 4.29 s 
2023-10-26 15:27:10.379636: Yayy! New best EMA pseudo Dice: 0.7317 
2023-10-26 15:27:11.542930:  
2023-10-26 15:27:11.543233: Epoch 45 
2023-10-26 15:27:11.543486: Current learning rate: 0.00959 
2023-10-26 15:27:15.883166: train_loss -0.8302 
2023-10-26 15:27:15.883576: val_loss -0.7608 
2023-10-26 15:27:15.883838: Pseudo dice [0.8591, 0.9244, 0.9681, 0.0, 0.9308] 
2023-10-26 15:27:15.884087: Epoch time: 4.34 s 
2023-10-26 15:27:15.884293: Yayy! New best EMA pseudo Dice: 0.7322 
2023-10-26 15:27:17.155788:  
2023-10-26 15:27:17.156251: Epoch 46 
2023-10-26 15:27:17.156516: Current learning rate: 0.00959 
2023-10-26 15:27:21.399866: train_loss -0.8325 
2023-10-26 15:27:21.400260: val_loss -0.7482 
2023-10-26 15:27:21.400517: Pseudo dice [0.8436, 0.9224, 0.9681, 0.0, 0.9277] 
2023-10-26 15:27:21.400748: Epoch time: 4.24 s 
2023-10-26 15:27:21.400967: Yayy! New best EMA pseudo Dice: 0.7322 
2023-10-26 15:27:22.518572:  
2023-10-26 15:27:22.518913: Epoch 47 
2023-10-26 15:27:22.519173: Current learning rate: 0.00958 
2023-10-26 15:27:26.845513: train_loss -0.8232 
2023-10-26 15:27:26.846012: val_loss -0.7578 
2023-10-26 15:27:26.846309: Pseudo dice [0.8478, 0.9274, 0.9689, 0.0, 0.9356] 
2023-10-26 15:27:26.846572: Epoch time: 4.33 s 
2023-10-26 15:27:26.846803: Yayy! New best EMA pseudo Dice: 0.7326 
2023-10-26 15:27:27.989353:  
2023-10-26 15:27:27.989664: Epoch 48 
2023-10-26 15:27:27.989918: Current learning rate: 0.00957 
2023-10-26 15:27:32.254507: train_loss -0.8321 
2023-10-26 15:27:32.254940: val_loss -0.7463 
2023-10-26 15:27:32.255361: Pseudo dice [0.8542, 0.9206, 0.9667, 0.0, 0.9309] 
2023-10-26 15:27:32.255679: Epoch time: 4.27 s 
2023-10-26 15:27:32.255946: Yayy! New best EMA pseudo Dice: 0.7328 
2023-10-26 15:27:33.398550:  
2023-10-26 15:27:33.398857: Epoch 49 
2023-10-26 15:27:33.399110: Current learning rate: 0.00956 
2023-10-26 15:27:37.592459: train_loss -0.8335 
2023-10-26 15:27:37.592859: val_loss -0.7637 
2023-10-26 15:27:37.593132: Pseudo dice [0.8593, 0.9258, 0.9679, 0.0, 0.9337] 
2023-10-26 15:27:37.593367: Epoch time: 4.19 s 
2023-10-26 15:27:37.664990: Yayy! New best EMA pseudo Dice: 0.7332 
2023-10-26 15:27:38.790502:  
2023-10-26 15:27:38.790802: Epoch 50 
2023-10-26 15:27:38.791063: Current learning rate: 0.00955 
2023-10-26 15:27:43.083157: train_loss -0.8347 
2023-10-26 15:27:43.083543: val_loss -0.7564 
2023-10-26 15:27:43.083814: Pseudo dice [0.8548, 0.9235, 0.9657, 0.0, 0.9323] 
2023-10-26 15:27:43.084046: Epoch time: 4.29 s 
2023-10-26 15:27:43.084263: Yayy! New best EMA pseudo Dice: 0.7334 
2023-10-26 15:27:44.201852:  
2023-10-26 15:27:44.202158: Epoch 51 
2023-10-26 15:27:44.202404: Current learning rate: 0.00954 
2023-10-26 15:27:48.642119: train_loss -0.8275 
2023-10-26 15:27:48.642550: val_loss -0.7441 
2023-10-26 15:27:48.642891: Pseudo dice [0.8521, 0.9225, 0.967, 0.0, 0.935] 
2023-10-26 15:27:48.643151: Epoch time: 4.44 s 
2023-10-26 15:27:48.643434: Yayy! New best EMA pseudo Dice: 0.7336 
2023-10-26 15:27:49.750268:  
2023-10-26 15:27:49.750574: Epoch 52 
2023-10-26 15:27:49.750827: Current learning rate: 0.00953 
2023-10-26 15:27:54.080006: train_loss -0.8259 
2023-10-26 15:27:54.080502: val_loss -0.7589 
2023-10-26 15:27:54.080879: Pseudo dice [0.8552, 0.9223, 0.9679, 0.0, 0.9333] 
2023-10-26 15:27:54.081231: Epoch time: 4.33 s 
2023-10-26 15:27:54.081527: Yayy! New best EMA pseudo Dice: 0.7338 
2023-10-26 15:27:55.259321:  
2023-10-26 15:27:55.259617: Epoch 53 
2023-10-26 15:27:55.259857: Current learning rate: 0.00952 
2023-10-26 15:27:59.562690: train_loss -0.835 
2023-10-26 15:27:59.563104: val_loss -0.7506 
2023-10-26 15:27:59.563375: Pseudo dice [0.8538, 0.924, 0.9669, 0.0, 0.931] 
2023-10-26 15:27:59.563614: Epoch time: 4.3 s 
2023-10-26 15:27:59.563843: Yayy! New best EMA pseudo Dice: 0.734 
2023-10-26 15:28:00.670936:  
2023-10-26 15:28:00.671246: Epoch 54 
2023-10-26 15:28:00.671494: Current learning rate: 0.00951 
2023-10-26 15:28:04.988398: train_loss -0.8291 
2023-10-26 15:28:04.988760: val_loss -0.7399 
2023-10-26 15:28:04.989020: Pseudo dice [0.8461, 0.924, 0.97, 0.0, 0.9199] 
2023-10-26 15:28:04.989245: Epoch time: 4.32 s 
2023-10-26 15:28:06.024265:  
2023-10-26 15:28:06.024559: Epoch 55 
2023-10-26 15:28:06.024792: Current learning rate: 0.0095 
2023-10-26 15:28:10.378439: train_loss -0.8316 
2023-10-26 15:28:10.378904: val_loss -0.7585 
2023-10-26 15:28:10.379264: Pseudo dice [0.8503, 0.9169, 0.9676, 0.0, 0.9265] 
2023-10-26 15:28:10.379674: Epoch time: 4.35 s 
2023-10-26 15:28:11.434896:  
2023-10-26 15:28:11.435189: Epoch 56 
2023-10-26 15:28:11.435438: Current learning rate: 0.00949 
2023-10-26 15:28:15.681771: train_loss -0.8249 
2023-10-26 15:28:15.682212: val_loss -0.7536 
2023-10-26 15:28:15.682462: Pseudo dice [0.8503, 0.9252, 0.9691, 0.0, 0.9144] 
2023-10-26 15:28:15.682687: Epoch time: 4.25 s 
2023-10-26 15:28:16.709701:  
2023-10-26 15:28:16.709988: Epoch 57 
2023-10-26 15:28:16.710219: Current learning rate: 0.00949 
2023-10-26 15:28:21.075184: train_loss -0.8337 
2023-10-26 15:28:21.075774: val_loss -0.7473 
2023-10-26 15:28:21.076165: Pseudo dice [0.8512, 0.9178, 0.968, 0.0, 0.9335] 
2023-10-26 15:28:21.076464: Epoch time: 4.37 s 
2023-10-26 15:28:22.377080:  
2023-10-26 15:28:22.377388: Epoch 58 
2023-10-26 15:28:22.377630: Current learning rate: 0.00948 
2023-10-26 15:28:26.852324: train_loss -0.8288 
2023-10-26 15:28:26.852670: val_loss -0.7542 
2023-10-26 15:28:26.852930: Pseudo dice [0.8498, 0.9216, 0.966, 0.0, 0.9332] 
2023-10-26 15:28:26.853153: Epoch time: 4.48 s 
2023-10-26 15:28:27.909059:  
2023-10-26 15:28:27.909430: Epoch 59 
2023-10-26 15:28:27.909723: Current learning rate: 0.00947 
2023-10-26 15:28:32.283432: train_loss -0.8259 
2023-10-26 15:28:32.283818: val_loss -0.7631 
2023-10-26 15:28:32.284081: Pseudo dice [0.8571, 0.9209, 0.9671, 0.0, 0.9412] 
2023-10-26 15:28:32.284323: Epoch time: 4.38 s 
2023-10-26 15:28:33.488711:  
2023-10-26 15:28:33.489038: Epoch 60 
2023-10-26 15:28:33.489387: Current learning rate: 0.00946 
2023-10-26 15:28:37.744674: train_loss -0.832 
2023-10-26 15:28:37.745078: val_loss -0.7448 
2023-10-26 15:28:37.745351: Pseudo dice [0.8444, 0.9201, 0.9675, 0.0, 0.9167] 
2023-10-26 15:28:37.745596: Epoch time: 4.26 s 
2023-10-26 15:28:38.859392:  
2023-10-26 15:28:38.859697: Epoch 61 
2023-10-26 15:28:38.859951: Current learning rate: 0.00945 
2023-10-26 15:28:43.090397: train_loss -0.8336 
2023-10-26 15:28:43.090782: val_loss -0.7666 
2023-10-26 15:28:43.091046: Pseudo dice [0.8589, 0.9241, 0.9683, 0.0, 0.9234] 
2023-10-26 15:28:43.091278: Epoch time: 4.23 s 
2023-10-26 15:28:44.184011:  
2023-10-26 15:28:44.184342: Epoch 62 
2023-10-26 15:28:44.184584: Current learning rate: 0.00944 
2023-10-26 15:28:48.416943: train_loss -0.824 
2023-10-26 15:28:48.417626: val_loss -0.7678 
2023-10-26 15:28:48.417923: Pseudo dice [0.8608, 0.9257, 0.9683, 0.0, 0.9294] 
2023-10-26 15:28:48.418268: Epoch time: 4.23 s 
2023-10-26 15:28:48.418523: Yayy! New best EMA pseudo Dice: 0.734 
2023-10-26 15:28:49.566196:  
2023-10-26 15:28:49.566489: Epoch 63 
2023-10-26 15:28:49.566730: Current learning rate: 0.00943 
2023-10-26 15:28:53.834417: train_loss -0.8283 
2023-10-26 15:28:53.834828: val_loss -0.76 
2023-10-26 15:28:53.835099: Pseudo dice [0.863, 0.9243, 0.9667, 0.0, 0.9209] 
2023-10-26 15:28:53.835347: Epoch time: 4.27 s 
2023-10-26 15:28:53.835568: Yayy! New best EMA pseudo Dice: 0.7341 
2023-10-26 15:28:55.158059:  
2023-10-26 15:28:55.158471: Epoch 64 
2023-10-26 15:28:55.158713: Current learning rate: 0.00942 
2023-10-26 15:28:59.336605: train_loss -0.8259 
2023-10-26 15:28:59.337316: val_loss -0.762 
2023-10-26 15:28:59.337592: Pseudo dice [0.8616, 0.9249, 0.9679, 0.0, 0.9365] 
2023-10-26 15:28:59.337859: Epoch time: 4.18 s 
2023-10-26 15:28:59.338194: Yayy! New best EMA pseudo Dice: 0.7345 
2023-10-26 15:29:00.463792:  
2023-10-26 15:29:00.464098: Epoch 65 
2023-10-26 15:29:00.464342: Current learning rate: 0.00941 
2023-10-26 15:29:04.614690: train_loss -0.8286 
2023-10-26 15:29:04.615173: val_loss -0.7539 
2023-10-26 15:29:04.615493: Pseudo dice [0.8524, 0.9267, 0.9682, 0.0, 0.9312] 
2023-10-26 15:29:04.615788: Epoch time: 4.15 s 
2023-10-26 15:29:04.616055: Yayy! New best EMA pseudo Dice: 0.7346 
2023-10-26 15:29:05.770549:  
2023-10-26 15:29:05.770863: Epoch 66 
2023-10-26 15:29:05.771116: Current learning rate: 0.0094 
2023-10-26 15:29:10.011223: train_loss -0.8314 
2023-10-26 15:29:10.011617: val_loss -0.7536 
2023-10-26 15:29:10.011885: Pseudo dice [0.8467, 0.9187, 0.9668, 0.0, 0.9287] 
2023-10-26 15:29:10.012113: Epoch time: 4.24 s 
2023-10-26 15:29:11.079092:  
2023-10-26 15:29:11.079398: Epoch 67 
2023-10-26 15:29:11.079633: Current learning rate: 0.00939 
2023-10-26 15:29:15.323877: train_loss -0.8268 
2023-10-26 15:29:15.324239: val_loss -0.7453 
2023-10-26 15:29:15.324504: Pseudo dice [0.849, 0.9207, 0.9681, 0.0, 0.9178] 
2023-10-26 15:29:15.324757: Epoch time: 4.25 s 
2023-10-26 15:29:16.400245:  
2023-10-26 15:29:16.400557: Epoch 68 
2023-10-26 15:29:16.400804: Current learning rate: 0.00939 
2023-10-26 15:29:20.651635: train_loss -0.8284 
2023-10-26 15:29:20.652157: val_loss -0.7474 
2023-10-26 15:29:20.652441: Pseudo dice [0.8476, 0.921, 0.9672, 0.0, 0.9317] 
2023-10-26 15:29:20.652770: Epoch time: 4.25 s 
2023-10-26 15:29:21.742677:  
2023-10-26 15:29:21.743029: Epoch 69 
2023-10-26 15:29:21.743274: Current learning rate: 0.00938 
2023-10-26 15:29:25.990608: train_loss -0.8357 
2023-10-26 15:29:25.991043: val_loss -0.7555 
2023-10-26 15:29:25.991313: Pseudo dice [0.8617, 0.9268, 0.9708, 0.0, 0.9218] 
2023-10-26 15:29:25.991556: Epoch time: 4.25 s 
2023-10-26 15:29:27.261688:  
2023-10-26 15:29:27.262014: Epoch 70 
2023-10-26 15:29:27.262286: Current learning rate: 0.00937 
2023-10-26 15:29:31.692332: train_loss -0.8307 
2023-10-26 15:29:31.692755: val_loss -0.7598 
2023-10-26 15:29:31.693112: Pseudo dice [0.8565, 0.9222, 0.9661, 0.0, 0.9355] 
2023-10-26 15:29:31.693447: Epoch time: 4.43 s 
2023-10-26 15:29:32.777191:  
2023-10-26 15:29:32.777471: Epoch 71 
2023-10-26 15:29:32.777707: Current learning rate: 0.00936 
2023-10-26 15:29:37.094311: train_loss -0.8427 
2023-10-26 15:29:37.094796: val_loss -0.7421 
2023-10-26 15:29:37.095109: Pseudo dice [0.8353, 0.9227, 0.968, 0.0, 0.9287] 
2023-10-26 15:29:37.095390: Epoch time: 4.32 s 
2023-10-26 15:29:38.218336:  
2023-10-26 15:29:38.218648: Epoch 72 
2023-10-26 15:29:38.218938: Current learning rate: 0.00935 
2023-10-26 15:29:42.545660: train_loss -0.835 
2023-10-26 15:29:42.546088: val_loss -0.7503 
2023-10-26 15:29:42.546513: Pseudo dice [0.8482, 0.9221, 0.9695, 0.0, 0.92] 
2023-10-26 15:29:42.546941: Epoch time: 4.33 s 
2023-10-26 15:29:43.602636:  
2023-10-26 15:29:43.602912: Epoch 73 
2023-10-26 15:29:43.603153: Current learning rate: 0.00934 
2023-10-26 15:29:47.939174: train_loss -0.8317 
2023-10-26 15:29:47.939620: val_loss -0.7593 
2023-10-26 15:29:47.940186: Pseudo dice [0.8513, 0.928, 0.9692, 0.0, 0.9374] 
2023-10-26 15:29:47.940522: Epoch time: 4.34 s 
2023-10-26 15:29:49.000081:  
2023-10-26 15:29:49.000368: Epoch 74 
2023-10-26 15:29:49.000603: Current learning rate: 0.00933 
2023-10-26 15:29:53.261214: train_loss -0.8285 
2023-10-26 15:29:53.261590: val_loss -0.7412 
2023-10-26 15:29:53.261853: Pseudo dice [0.836, 0.9206, 0.9681, 0.0, 0.9318] 
2023-10-26 15:29:53.262092: Epoch time: 4.26 s 
2023-10-26 15:29:54.302462:  
2023-10-26 15:29:54.302752: Epoch 75 
2023-10-26 15:29:54.302995: Current learning rate: 0.00932 
2023-10-26 15:29:58.620753: train_loss -0.8388 
2023-10-26 15:29:58.621133: val_loss -0.7458 
2023-10-26 15:29:58.621390: Pseudo dice [0.8471, 0.9243, 0.9689, 0.0, 0.9338] 
2023-10-26 15:29:58.621623: Epoch time: 4.32 s 
2023-10-26 15:29:59.860511:  
2023-10-26 15:29:59.860826: Epoch 76 
2023-10-26 15:29:59.861072: Current learning rate: 0.00931 
2023-10-26 15:30:04.225393: train_loss -0.8394 
2023-10-26 15:30:04.225738: val_loss -0.751 
2023-10-26 15:30:04.226002: Pseudo dice [0.8599, 0.9201, 0.9683, 0.0, 0.9334] 
2023-10-26 15:30:04.226229: Epoch time: 4.37 s 
2023-10-26 15:30:05.275080:  
2023-10-26 15:30:05.275403: Epoch 77 
2023-10-26 15:30:05.275646: Current learning rate: 0.0093 
2023-10-26 15:30:09.555480: train_loss -0.8466 
2023-10-26 15:30:09.555811: val_loss -0.7466 
2023-10-26 15:30:09.556063: Pseudo dice [0.8367, 0.9164, 0.9665, 0.0, 0.932] 
2023-10-26 15:30:09.556282: Epoch time: 4.28 s 
2023-10-26 15:30:10.625319:  
2023-10-26 15:30:10.625632: Epoch 78 
2023-10-26 15:30:10.625891: Current learning rate: 0.0093 
2023-10-26 15:30:14.854566: train_loss -0.8317 
2023-10-26 15:30:14.854934: val_loss -0.7494 
2023-10-26 15:30:14.855240: Pseudo dice [0.8416, 0.9197, 0.9647, 0.0, 0.9359] 
2023-10-26 15:30:14.855511: Epoch time: 4.23 s 
2023-10-26 15:30:15.986287:  
2023-10-26 15:30:15.986585: Epoch 79 
2023-10-26 15:30:15.986830: Current learning rate: 0.00929 
2023-10-26 15:30:20.258534: train_loss -0.8374 
2023-10-26 15:30:20.258945: val_loss -0.7473 
2023-10-26 15:30:20.259429: Pseudo dice [0.842, 0.9152, 0.9663, 0.0, 0.931] 
2023-10-26 15:30:20.259759: Epoch time: 4.27 s 
2023-10-26 15:30:21.346068:  
2023-10-26 15:30:21.346406: Epoch 80 
2023-10-26 15:30:21.346657: Current learning rate: 0.00928 
2023-10-26 15:30:25.568425: train_loss -0.8345 
2023-10-26 15:30:25.568821: val_loss -0.7565 
2023-10-26 15:30:25.569073: Pseudo dice [0.8426, 0.9181, 0.9648, 0.0, 0.9355] 
2023-10-26 15:30:25.569295: Epoch time: 4.22 s 
2023-10-26 15:30:26.660997:  
2023-10-26 15:30:26.661293: Epoch 81 
2023-10-26 15:30:26.661547: Current learning rate: 0.00927 
2023-10-26 15:30:30.929105: train_loss -0.8293 
2023-10-26 15:30:30.929616: val_loss -0.7493 
2023-10-26 15:30:30.929992: Pseudo dice [0.8429, 0.9251, 0.9668, 0.0, 0.9068] 
2023-10-26 15:30:30.930289: Epoch time: 4.27 s 
2023-10-26 15:30:32.279938:  
2023-10-26 15:30:32.280312: Epoch 82 
2023-10-26 15:30:32.280620: Current learning rate: 0.00926 
2023-10-26 15:30:36.622719: train_loss -0.8365 
2023-10-26 15:30:36.623099: val_loss -0.7618 
2023-10-26 15:30:36.623377: Pseudo dice [0.8501, 0.9165, 0.965, 0.0, 0.9285] 
2023-10-26 15:30:36.623608: Epoch time: 4.34 s 
2023-10-26 15:30:37.679107:  
2023-10-26 15:30:37.679400: Epoch 83 
2023-10-26 15:30:37.679657: Current learning rate: 0.00925 
2023-10-26 15:30:42.015282: train_loss -0.8376 
2023-10-26 15:30:42.015695: val_loss -0.7708 
2023-10-26 15:30:42.015974: Pseudo dice [0.8546, 0.9242, 0.971, 0.0, 0.9267] 
2023-10-26 15:30:42.016209: Epoch time: 4.34 s 
2023-10-26 15:30:43.057822:  
2023-10-26 15:30:43.058145: Epoch 84 
2023-10-26 15:30:43.058411: Current learning rate: 0.00924 
2023-10-26 15:30:47.309534: train_loss -0.8386 
2023-10-26 15:30:47.309914: val_loss -0.7815 
2023-10-26 15:30:47.310185: Pseudo dice [0.8503, 0.922, 0.9652, 0.2689, 0.8914] 
2023-10-26 15:30:47.310418: Epoch time: 4.25 s 
2023-10-26 15:30:47.310627: Yayy! New best EMA pseudo Dice: 0.7376 
2023-10-26 15:30:48.422505:  
2023-10-26 15:30:48.422803: Epoch 85 
2023-10-26 15:30:48.423058: Current learning rate: 0.00923 
2023-10-26 15:30:52.705971: train_loss -0.8128 
2023-10-26 15:30:52.706929: val_loss -0.7489 
2023-10-26 15:30:52.707321: Pseudo dice [0.8362, 0.9194, 0.9674, 0.0, 0.9229] 
2023-10-26 15:30:52.707689: Epoch time: 4.28 s 
2023-10-26 15:30:53.800237:  
2023-10-26 15:30:53.800593: Epoch 86 
2023-10-26 15:30:53.800861: Current learning rate: 0.00922 
2023-10-26 15:30:58.032154: train_loss -0.8263 
2023-10-26 15:30:58.032567: val_loss -0.7652 
2023-10-26 15:30:58.032825: Pseudo dice [0.8618, 0.9252, 0.9659, 0.0, 0.8847] 
2023-10-26 15:30:58.033083: Epoch time: 4.23 s 
2023-10-26 15:30:59.079798:  
2023-10-26 15:30:59.080094: Epoch 87 
2023-10-26 15:30:59.080346: Current learning rate: 0.00921 
2023-10-26 15:31:03.306115: train_loss -0.8338 
2023-10-26 15:31:03.306524: val_loss -0.7641 
2023-10-26 15:31:03.306811: Pseudo dice [0.8317, 0.9071, 0.9643, 0.4136, 0.8578] 
2023-10-26 15:31:03.307079: Epoch time: 4.23 s 
2023-10-26 15:31:03.307294: Yayy! New best EMA pseudo Dice: 0.7418 
2023-10-26 15:31:04.581953:  
2023-10-26 15:31:04.582259: Epoch 88 
2023-10-26 15:31:04.582494: Current learning rate: 0.0092 
2023-10-26 15:31:08.875731: train_loss -0.8317 
2023-10-26 15:31:08.876298: val_loss -0.7501 
2023-10-26 15:31:08.876581: Pseudo dice [0.8303, 0.8965, 0.9651, 0.0704, 0.9227] 
2023-10-26 15:31:08.876905: Epoch time: 4.29 s 
2023-10-26 15:31:09.898785:  
2023-10-26 15:31:09.899131: Epoch 89 
2023-10-26 15:31:09.899480: Current learning rate: 0.0092 
2023-10-26 15:31:14.307180: train_loss -0.8431 
2023-10-26 15:31:14.307591: val_loss -0.8006 
2023-10-26 15:31:14.307860: Pseudo dice [0.8451, 0.9175, 0.9664, 0.5605, 0.9381] 
2023-10-26 15:31:14.308117: Epoch time: 4.41 s 
2023-10-26 15:31:14.308337: Yayy! New best EMA pseudo Dice: 0.7517 
2023-10-26 15:31:15.411654:  
2023-10-26 15:31:15.411968: Epoch 90 
2023-10-26 15:31:15.412223: Current learning rate: 0.00919 
2023-10-26 15:31:19.725131: train_loss -0.827 
2023-10-26 15:31:19.725528: val_loss -0.7824 
2023-10-26 15:31:19.725849: Pseudo dice [0.8323, 0.9212, 0.9637, 0.458, 0.915] 
2023-10-26 15:31:19.726220: Epoch time: 4.31 s 
2023-10-26 15:31:19.726558: Yayy! New best EMA pseudo Dice: 0.7583 
2023-10-26 15:31:20.859291:  
2023-10-26 15:31:20.861599: Epoch 91 
2023-10-26 15:31:20.861905: Current learning rate: 0.00918 
2023-10-26 15:31:25.100795: train_loss -0.8253 
2023-10-26 15:31:25.101224: val_loss -0.7597 
2023-10-26 15:31:25.101584: Pseudo dice [0.8527, 0.9122, 0.9658, 0.0, 0.9298] 
2023-10-26 15:31:25.101909: Epoch time: 4.24 s 
2023-10-26 15:31:26.171164:  
2023-10-26 15:31:26.171470: Epoch 92 
2023-10-26 15:31:26.171728: Current learning rate: 0.00917 
2023-10-26 15:31:30.537631: train_loss -0.8134 
2023-10-26 15:31:30.538236: val_loss -0.7484 
2023-10-26 15:31:30.538618: Pseudo dice [0.8504, 0.9233, 0.9685, 0.0, 0.9168] 
2023-10-26 15:31:30.538952: Epoch time: 4.37 s 
2023-10-26 15:31:31.614509:  
2023-10-26 15:31:31.614825: Epoch 93 
2023-10-26 15:31:31.615076: Current learning rate: 0.00916 
2023-10-26 15:31:35.836176: train_loss -0.8245 
2023-10-26 15:31:35.836596: val_loss -0.7638 
2023-10-26 15:31:35.836860: Pseudo dice [0.848, 0.9242, 0.9675, 0.0, 0.9295] 
2023-10-26 15:31:35.837107: Epoch time: 4.22 s 
2023-10-26 15:31:36.873301:  
2023-10-26 15:31:36.873719: Epoch 94 
2023-10-26 15:31:36.873973: Current learning rate: 0.00915 
2023-10-26 15:31:41.145426: train_loss -0.8305 
2023-10-26 15:31:41.145831: val_loss -0.7479 
2023-10-26 15:31:41.146087: Pseudo dice [0.8343, 0.9075, 0.9668, 0.0077, 0.9356] 
2023-10-26 15:31:41.146322: Epoch time: 4.27 s 
2023-10-26 15:31:42.421062:  
2023-10-26 15:31:42.421392: Epoch 95 
2023-10-26 15:31:42.421648: Current learning rate: 0.00914 
2023-10-26 15:31:46.643675: train_loss -0.8387 
2023-10-26 15:31:46.644127: val_loss -0.7675 
2023-10-26 15:31:46.644396: Pseudo dice [0.8342, 0.9239, 0.9666, 0.1745, 0.9311] 
2023-10-26 15:31:46.644640: Epoch time: 4.22 s 
2023-10-26 15:31:47.671585:  
2023-10-26 15:31:47.671941: Epoch 96 
2023-10-26 15:31:47.672251: Current learning rate: 0.00913 
2023-10-26 15:31:51.835754: train_loss -0.8535 
2023-10-26 15:31:51.836158: val_loss -0.7662 
2023-10-26 15:31:51.836447: Pseudo dice [0.8514, 0.9136, 0.9648, 0.1793, 0.931] 
2023-10-26 15:31:51.836684: Epoch time: 4.16 s 
2023-10-26 15:31:52.889992:  
2023-10-26 15:31:52.890363: Epoch 97 
2023-10-26 15:31:52.890625: Current learning rate: 0.00912 
2023-10-26 15:31:57.004409: train_loss -0.8539 
2023-10-26 15:31:57.004954: val_loss -0.7996 
2023-10-26 15:31:57.005311: Pseudo dice [0.8514, 0.924, 0.9672, 0.3348, 0.9345] 
2023-10-26 15:31:57.005684: Epoch time: 4.12 s 
2023-10-26 15:31:58.074669:  
2023-10-26 15:31:58.074984: Epoch 98 
2023-10-26 15:31:58.075233: Current learning rate: 0.00911 
2023-10-26 15:32:02.248884: train_loss -0.8627 
2023-10-26 15:32:02.249270: val_loss -0.7677 
2023-10-26 15:32:02.249539: Pseudo dice [0.8451, 0.9192, 0.9683, 0.1189, 0.9165] 
2023-10-26 15:32:02.249784: Epoch time: 4.17 s 
2023-10-26 15:32:03.283904:  
2023-10-26 15:32:03.284198: Epoch 99 
2023-10-26 15:32:03.284439: Current learning rate: 0.0091 
2023-10-26 15:32:07.512930: train_loss -0.8581 
2023-10-26 15:32:07.513349: val_loss -0.7877 
2023-10-26 15:32:07.513621: Pseudo dice [0.8481, 0.9137, 0.9677, 0.3745, 0.9175] 
2023-10-26 15:32:07.513883: Epoch time: 4.23 s 
2023-10-26 15:32:07.587965: Yayy! New best EMA pseudo Dice: 0.7619 
2023-10-26 15:32:08.708604:  
2023-10-26 15:32:08.708902: Epoch 100 
2023-10-26 15:32:08.709153: Current learning rate: 0.0091 
2023-10-26 15:32:12.879908: train_loss -0.8472 
2023-10-26 15:32:12.880372: val_loss -0.7473 
2023-10-26 15:32:12.880634: Pseudo dice [0.848, 0.9195, 0.9681, 0.0, 0.9278] 
2023-10-26 15:32:12.880865: Epoch time: 4.17 s 
2023-10-26 15:32:14.147911:  
2023-10-26 15:32:14.148227: Epoch 101 
2023-10-26 15:32:14.148464: Current learning rate: 0.00909 
2023-10-26 15:32:18.525363: train_loss -0.8508 
2023-10-26 15:32:18.525815: val_loss -0.7439 
2023-10-26 15:32:18.526181: Pseudo dice [0.835, 0.9128, 0.967, 0.0763, 0.9297] 
2023-10-26 15:32:18.526441: Epoch time: 4.38 s 
2023-10-26 15:32:19.570351:  
2023-10-26 15:32:19.570647: Epoch 102 
2023-10-26 15:32:19.570888: Current learning rate: 0.00908 
2023-10-26 15:32:23.748614: train_loss -0.8518 
2023-10-26 15:32:23.749013: val_loss -0.7704 
2023-10-26 15:32:23.749287: Pseudo dice [0.8551, 0.9203, 0.9672, 0.0971, 0.9333] 
2023-10-26 15:32:23.749535: Epoch time: 4.18 s 
2023-10-26 15:32:24.800996:  
2023-10-26 15:32:24.801333: Epoch 103 
2023-10-26 15:32:24.801586: Current learning rate: 0.00907 
2023-10-26 15:32:29.150767: train_loss -0.8543 
2023-10-26 15:32:29.151311: val_loss -0.8038 
2023-10-26 15:32:29.151630: Pseudo dice [0.8541, 0.9166, 0.967, 0.4868, 0.9296] 
2023-10-26 15:32:29.151891: Epoch time: 4.35 s 
2023-10-26 15:32:29.152111: Yayy! New best EMA pseudo Dice: 0.7646 
2023-10-26 15:32:30.299699:  
2023-10-26 15:32:30.300203: Epoch 104 
2023-10-26 15:32:30.300490: Current learning rate: 0.00906 
2023-10-26 15:32:34.655961: train_loss -0.869 
2023-10-26 15:32:34.656320: val_loss -0.7967 
2023-10-26 15:32:34.656589: Pseudo dice [0.8516, 0.918, 0.9692, 0.4717, 0.9353] 
2023-10-26 15:32:34.656833: Epoch time: 4.36 s 
2023-10-26 15:32:34.657081: Yayy! New best EMA pseudo Dice: 0.771 
2023-10-26 15:32:35.772480:  
2023-10-26 15:32:35.772817: Epoch 105 
2023-10-26 15:32:35.773134: Current learning rate: 0.00905 
2023-10-26 15:32:40.074039: train_loss -0.867 
2023-10-26 15:32:40.074406: val_loss -0.8245 
2023-10-26 15:32:40.074654: Pseudo dice [0.8586, 0.929, 0.968, 0.6663, 0.9314] 
2023-10-26 15:32:40.074886: Epoch time: 4.3 s 
2023-10-26 15:32:40.075089: Yayy! New best EMA pseudo Dice: 0.781 
2023-10-26 15:32:41.224437:  
2023-10-26 15:32:41.224748: Epoch 106 
2023-10-26 15:32:41.225024: Current learning rate: 0.00904 
2023-10-26 15:32:45.566649: train_loss -0.8645 
2023-10-26 15:32:45.567075: val_loss -0.7983 
2023-10-26 15:32:45.567354: Pseudo dice [0.8475, 0.9163, 0.9646, 0.4786, 0.9383] 
2023-10-26 15:32:45.567601: Epoch time: 4.34 s 
2023-10-26 15:32:45.567809: Yayy! New best EMA pseudo Dice: 0.7858 
2023-10-26 15:32:46.691834:  
2023-10-26 15:32:46.692200: Epoch 107 
2023-10-26 15:32:46.692437: Current learning rate: 0.00903 
2023-10-26 15:32:50.853155: train_loss -0.8534 
2023-10-26 15:32:50.853545: val_loss -0.7909 
2023-10-26 15:32:50.853815: Pseudo dice [0.8535, 0.9304, 0.9701, 0.4502, 0.9323] 
2023-10-26 15:32:50.854164: Epoch time: 4.16 s 
2023-10-26 15:32:50.854398: Yayy! New best EMA pseudo Dice: 0.79 
2023-10-26 15:32:52.219087:  
2023-10-26 15:32:52.219393: Epoch 108 
2023-10-26 15:32:52.219670: Current learning rate: 0.00902 
2023-10-26 15:32:56.501587: train_loss -0.8564 
2023-10-26 15:32:56.501999: val_loss -0.7841 
2023-10-26 15:32:56.502258: Pseudo dice [0.8479, 0.9176, 0.9691, 0.4331, 0.9213] 
2023-10-26 15:32:56.502502: Epoch time: 4.28 s 
2023-10-26 15:32:56.502716: Yayy! New best EMA pseudo Dice: 0.7927 
2023-10-26 15:32:57.625862:  
2023-10-26 15:32:57.626196: Epoch 109 
2023-10-26 15:32:57.626432: Current learning rate: 0.00901 
2023-10-26 15:33:01.942309: train_loss -0.862 
2023-10-26 15:33:01.942704: val_loss -0.7836 
2023-10-26 15:33:01.942968: Pseudo dice [0.8465, 0.9167, 0.9676, 0.4261, 0.9265] 
2023-10-26 15:33:01.943215: Epoch time: 4.32 s 
2023-10-26 15:33:01.943436: Yayy! New best EMA pseudo Dice: 0.7951 
2023-10-26 15:33:03.096505:  
2023-10-26 15:33:03.096856: Epoch 110 
2023-10-26 15:33:03.097139: Current learning rate: 0.009 
2023-10-26 15:33:07.391617: train_loss -0.859 
2023-10-26 15:33:07.393016: val_loss -0.7965 
2023-10-26 15:33:07.393301: Pseudo dice [0.8456, 0.9217, 0.9691, 0.5372, 0.9335] 
2023-10-26 15:33:07.393536: Epoch time: 4.3 s 
2023-10-26 15:33:07.393746: Yayy! New best EMA pseudo Dice: 0.7998 
2023-10-26 15:33:08.553178:  
2023-10-26 15:33:08.553496: Epoch 111 
2023-10-26 15:33:08.553745: Current learning rate: 0.009 
2023-10-26 15:33:12.831805: train_loss -0.8653 
2023-10-26 15:33:12.832227: val_loss -0.8011 
2023-10-26 15:33:12.832501: Pseudo dice [0.8224, 0.9239, 0.9649, 0.6711, 0.9348] 
2023-10-26 15:33:12.832746: Epoch time: 4.28 s 
2023-10-26 15:33:12.832984: Yayy! New best EMA pseudo Dice: 0.8061 
2023-10-26 15:33:14.018631:  
2023-10-26 15:33:14.018924: Epoch 112 
2023-10-26 15:33:14.019170: Current learning rate: 0.00899 
2023-10-26 15:33:18.349007: train_loss -0.855 
2023-10-26 15:33:18.349417: val_loss -0.7904 
2023-10-26 15:33:18.349670: Pseudo dice [0.8533, 0.9222, 0.9673, 0.3831, 0.9186] 
2023-10-26 15:33:18.349923: Epoch time: 4.33 s 
2023-10-26 15:33:18.350156: Yayy! New best EMA pseudo Dice: 0.8064 
2023-10-26 15:33:19.767282:  
2023-10-26 15:33:19.767665: Epoch 113 
2023-10-26 15:33:19.767980: Current learning rate: 0.00898 
2023-10-26 15:33:24.045831: train_loss -0.8615 
2023-10-26 15:33:24.046446: val_loss -0.7513 
2023-10-26 15:33:24.046775: Pseudo dice [0.8493, 0.9161, 0.9679, 0.0, 0.9183] 
2023-10-26 15:33:24.047088: Epoch time: 4.28 s 
2023-10-26 15:33:25.120158:  
2023-10-26 15:33:25.120538: Epoch 114 
2023-10-26 15:33:25.120862: Current learning rate: 0.00897 
2023-10-26 15:33:29.496835: train_loss -0.8602 
2023-10-26 15:33:29.497227: val_loss -0.8124 
2023-10-26 15:33:29.497500: Pseudo dice [0.8488, 0.9242, 0.9685, 0.628, 0.9342] 
2023-10-26 15:33:29.497750: Epoch time: 4.38 s 
2023-10-26 15:33:30.543254:  
2023-10-26 15:33:30.543568: Epoch 115 
2023-10-26 15:33:30.543814: Current learning rate: 0.00896 
2023-10-26 15:33:34.873654: train_loss -0.8623 
2023-10-26 15:33:34.874084: val_loss -0.7995 
2023-10-26 15:33:34.874351: Pseudo dice [0.8535, 0.9189, 0.9661, 0.4533, 0.9271] 
2023-10-26 15:33:34.874632: Epoch time: 4.33 s 
2023-10-26 15:33:34.874841: Yayy! New best EMA pseudo Dice: 0.8069 
2023-10-26 15:33:36.035007:  
2023-10-26 15:33:36.035316: Epoch 116 
2023-10-26 15:33:36.035570: Current learning rate: 0.00895 
2023-10-26 15:33:40.342686: train_loss -0.8675 
2023-10-26 15:33:40.343115: val_loss -0.8043 
2023-10-26 15:33:40.343414: Pseudo dice [0.8475, 0.9193, 0.966, 0.5651, 0.9387] 
2023-10-26 15:33:40.343657: Epoch time: 4.31 s 
2023-10-26 15:33:40.343869: Yayy! New best EMA pseudo Dice: 0.8109 
2023-10-26 15:33:41.472019:  
2023-10-26 15:33:41.472324: Epoch 117 
2023-10-26 15:33:41.472582: Current learning rate: 0.00894 
2023-10-26 15:33:45.745042: train_loss -0.8611 
2023-10-26 15:33:45.745384: val_loss -0.7963 
2023-10-26 15:33:45.745640: Pseudo dice [0.8509, 0.9242, 0.9663, 0.3446, 0.935] 
2023-10-26 15:33:45.745867: Epoch time: 4.27 s 
2023-10-26 15:33:46.842429:  
2023-10-26 15:33:46.842746: Epoch 118 
2023-10-26 15:33:46.843014: Current learning rate: 0.00893 
2023-10-26 15:33:51.084347: train_loss -0.867 
2023-10-26 15:33:51.084753: val_loss -0.8189 
2023-10-26 15:33:51.085019: Pseudo dice [0.8518, 0.9256, 0.9681, 0.6518, 0.9281] 
2023-10-26 15:33:51.085294: Epoch time: 4.24 s 
2023-10-26 15:33:51.085577: Yayy! New best EMA pseudo Dice: 0.8157 
2023-10-26 15:33:52.230720:  
2023-10-26 15:33:52.231023: Epoch 119 
2023-10-26 15:33:52.231261: Current learning rate: 0.00892 
2023-10-26 15:33:56.430913: train_loss -0.8716 
2023-10-26 15:33:56.431268: val_loss -0.8182 
2023-10-26 15:33:56.431522: Pseudo dice [0.8489, 0.9242, 0.967, 0.6652, 0.9312] 
2023-10-26 15:33:56.431756: Epoch time: 4.2 s 
2023-10-26 15:33:56.431997: Yayy! New best EMA pseudo Dice: 0.8209 
2023-10-26 15:33:57.729412:  
2023-10-26 15:33:57.729716: Epoch 120 
2023-10-26 15:33:57.730004: Current learning rate: 0.00891 
2023-10-26 15:34:01.979692: train_loss -0.8667 
2023-10-26 15:34:01.980124: val_loss -0.801 
2023-10-26 15:34:01.980393: Pseudo dice [0.8414, 0.9177, 0.9671, 0.6425, 0.9213] 
2023-10-26 15:34:01.980636: Epoch time: 4.25 s 
2023-10-26 15:34:01.980843: Yayy! New best EMA pseudo Dice: 0.8246 
2023-10-26 15:34:03.171704:  
2023-10-26 15:34:03.172030: Epoch 121 
2023-10-26 15:34:03.172325: Current learning rate: 0.0089 
2023-10-26 15:34:07.414106: train_loss -0.8598 
2023-10-26 15:34:07.414501: val_loss -0.7939 
2023-10-26 15:34:07.414759: Pseudo dice [0.8574, 0.9219, 0.9679, 0.2811, 0.9338] 
2023-10-26 15:34:07.415037: Epoch time: 4.24 s 
2023-10-26 15:34:08.496303:  
2023-10-26 15:34:08.496608: Epoch 122 
2023-10-26 15:34:08.496866: Current learning rate: 0.00889 
2023-10-26 15:34:12.650999: train_loss -0.8586 
2023-10-26 15:34:12.651399: val_loss -0.8151 
2023-10-26 15:34:12.651656: Pseudo dice [0.8474, 0.9256, 0.9663, 0.7211, 0.9264] 
2023-10-26 15:34:12.651894: Epoch time: 4.16 s 
2023-10-26 15:34:12.652106: Yayy! New best EMA pseudo Dice: 0.827 
2023-10-26 15:34:13.880180:  
2023-10-26 15:34:13.880472: Epoch 123 
2023-10-26 15:34:13.880713: Current learning rate: 0.00889 
2023-10-26 15:34:18.070535: train_loss -0.8658 
2023-10-26 15:34:18.070989: val_loss -0.8155 
2023-10-26 15:34:18.071421: Pseudo dice [0.85, 0.9222, 0.9668, 0.6584, 0.9207] 
2023-10-26 15:34:18.071668: Epoch time: 4.19 s 
2023-10-26 15:34:18.072098: Yayy! New best EMA pseudo Dice: 0.8306 
2023-10-26 15:34:19.252767:  
2023-10-26 15:34:19.253073: Epoch 124 
2023-10-26 15:34:19.253333: Current learning rate: 0.00888 
2023-10-26 15:34:23.346928: train_loss -0.8708 
2023-10-26 15:34:23.347316: val_loss -0.8332 
2023-10-26 15:34:23.347571: Pseudo dice [0.8622, 0.9216, 0.9669, 0.6892, 0.9179] 
2023-10-26 15:34:23.347832: Epoch time: 4.09 s 
2023-10-26 15:34:23.348096: Yayy! New best EMA pseudo Dice: 0.8347 
2023-10-26 15:34:24.499538:  
2023-10-26 15:34:24.499820: Epoch 125 
2023-10-26 15:34:24.500051: Current learning rate: 0.00887 
2023-10-26 15:34:28.658080: train_loss -0.8615 
2023-10-26 15:34:28.658595: val_loss -0.7819 
2023-10-26 15:34:28.658865: Pseudo dice [0.8352, 0.9108, 0.9647, 0.3931, 0.9011] 
2023-10-26 15:34:28.659230: Epoch time: 4.16 s 
2023-10-26 15:34:29.919525:  
2023-10-26 15:34:29.919834: Epoch 126 
2023-10-26 15:34:29.920078: Current learning rate: 0.00886 
2023-10-26 15:34:34.071260: train_loss -0.856 
2023-10-26 15:34:34.071654: val_loss -0.7254 
2023-10-26 15:34:34.071916: Pseudo dice [0.821, 0.9147, 0.9675, 0.0011, 0.8668] 
2023-10-26 15:34:34.072150: Epoch time: 4.15 s 
2023-10-26 15:34:35.142925:  
2023-10-26 15:34:35.143213: Epoch 127 
2023-10-26 15:34:35.143455: Current learning rate: 0.00885 
2023-10-26 15:34:39.352081: train_loss -0.8632 
2023-10-26 15:34:39.352488: val_loss -0.7998 
2023-10-26 15:34:39.352918: Pseudo dice [0.839, 0.9247, 0.9685, 0.6426, 0.8888] 
2023-10-26 15:34:39.353249: Epoch time: 4.21 s 
2023-10-26 15:34:40.427347:  
2023-10-26 15:34:40.427653: Epoch 128 
2023-10-26 15:34:40.427929: Current learning rate: 0.00884 
2023-10-26 15:34:44.682971: train_loss -0.8602 
2023-10-26 15:34:44.683387: val_loss -0.8031 
2023-10-26 15:34:44.683673: Pseudo dice [0.8539, 0.9226, 0.9644, 0.5638, 0.9222] 
2023-10-26 15:34:44.684112: Epoch time: 4.26 s 
2023-10-26 15:34:45.886798:  
2023-10-26 15:34:45.887123: Epoch 129 
2023-10-26 15:34:45.887393: Current learning rate: 0.00883 
2023-10-26 15:34:50.062617: train_loss -0.8717 
2023-10-26 15:34:50.063036: val_loss -0.7941 
2023-10-26 15:34:50.063323: Pseudo dice [0.833, 0.9208, 0.9678, 0.4398, 0.9035] 
2023-10-26 15:34:50.063576: Epoch time: 4.18 s 
2023-10-26 15:34:51.149485:  
2023-10-26 15:34:51.149856: Epoch 130 
2023-10-26 15:34:51.150198: Current learning rate: 0.00882 
2023-10-26 15:34:55.347769: train_loss -0.8705 
2023-10-26 15:34:55.348165: val_loss -0.7553 
2023-10-26 15:34:55.348533: Pseudo dice [0.8301, 0.9103, 0.9659, 0.0, 0.8971] 
2023-10-26 15:34:55.348852: Epoch time: 4.2 s 
2023-10-26 15:34:56.520860:  
2023-10-26 15:34:56.521361: Epoch 131 
2023-10-26 15:34:56.521688: Current learning rate: 0.00881 
2023-10-26 15:35:00.836495: train_loss -0.8527 
2023-10-26 15:35:00.836934: val_loss -0.7393 
2023-10-26 15:35:00.837214: Pseudo dice [0.8219, 0.8867, 0.9653, 0.0041, 0.9247] 
2023-10-26 15:35:00.837474: Epoch time: 4.32 s 
2023-10-26 15:35:02.121448:  
2023-10-26 15:35:02.121787: Epoch 132 
2023-10-26 15:35:02.122053: Current learning rate: 0.0088 
2023-10-26 15:35:06.273511: train_loss -0.8572 
2023-10-26 15:35:06.273917: val_loss -0.8251 
2023-10-26 15:35:06.274194: Pseudo dice [0.8564, 0.917, 0.9656, 0.6685, 0.921] 
2023-10-26 15:35:06.274435: Epoch time: 4.15 s 
2023-10-26 15:35:07.367446:  
2023-10-26 15:35:07.367748: Epoch 133 
2023-10-26 15:35:07.368041: Current learning rate: 0.00879 
2023-10-26 15:35:11.605499: train_loss -0.8599 
2023-10-26 15:35:11.605965: val_loss -0.8111 
2023-10-26 15:35:11.606336: Pseudo dice [0.854, 0.9244, 0.9669, 0.4593, 0.9272] 
2023-10-26 15:35:11.606680: Epoch time: 4.24 s 
2023-10-26 15:35:12.716700:  
2023-10-26 15:35:12.716988: Epoch 134 
2023-10-26 15:35:12.717254: Current learning rate: 0.00879 
2023-10-26 15:35:16.912411: train_loss -0.8642 
2023-10-26 15:35:16.912891: val_loss -0.7853 
2023-10-26 15:35:16.913191: Pseudo dice [0.8435, 0.9161, 0.9669, 0.4617, 0.9065] 
2023-10-26 15:35:16.913566: Epoch time: 4.2 s 
2023-10-26 15:35:18.046623:  
2023-10-26 15:35:18.046946: Epoch 135 
2023-10-26 15:35:18.047257: Current learning rate: 0.00878 
2023-10-26 15:35:22.295814: train_loss -0.8621 
2023-10-26 15:35:22.296242: val_loss -0.7553 
2023-10-26 15:35:22.296506: Pseudo dice [0.8341, 0.9239, 0.9688, 0.1575, 0.8477] 
2023-10-26 15:35:22.296744: Epoch time: 4.25 s 
2023-10-26 15:35:23.433069:  
2023-10-26 15:35:23.433392: Epoch 136 
2023-10-26 15:35:23.433651: Current learning rate: 0.00877 
2023-10-26 15:35:27.761295: train_loss -0.8558 
2023-10-26 15:35:27.761656: val_loss -0.8269 
2023-10-26 15:35:27.761951: Pseudo dice [0.8371, 0.9182, 0.9664, 0.7172, 0.926] 
2023-10-26 15:35:27.762199: Epoch time: 4.33 s 
2023-10-26 15:35:28.842583:  
2023-10-26 15:35:28.842921: Epoch 137 
2023-10-26 15:35:28.843228: Current learning rate: 0.00876 
2023-10-26 15:35:33.167169: train_loss -0.8635 
2023-10-26 15:35:33.167556: val_loss -0.7974 
2023-10-26 15:35:33.167962: Pseudo dice [0.8531, 0.9191, 0.9679, 0.3677, 0.9135] 
2023-10-26 15:35:33.168258: Epoch time: 4.33 s 
2023-10-26 15:35:34.414446:  
2023-10-26 15:35:34.414781: Epoch 138 
2023-10-26 15:35:34.415019: Current learning rate: 0.00875 
2023-10-26 15:35:38.793734: train_loss -0.8562 
2023-10-26 15:35:38.794159: val_loss -0.8179 
2023-10-26 15:35:38.794444: Pseudo dice [0.8378, 0.9195, 0.9677, 0.773, 0.868] 
2023-10-26 15:35:38.794710: Epoch time: 4.38 s 
2023-10-26 15:35:39.888071:  
2023-10-26 15:35:39.888412: Epoch 139 
2023-10-26 15:35:39.888658: Current learning rate: 0.00874 
2023-10-26 15:35:44.197279: train_loss -0.8645 
2023-10-26 15:35:44.197670: val_loss -0.8185 
2023-10-26 15:35:44.197929: Pseudo dice [0.8417, 0.915, 0.9636, 0.7314, 0.9191] 
2023-10-26 15:35:44.198170: Epoch time: 4.31 s 
2023-10-26 15:35:45.300483:  
2023-10-26 15:35:45.300836: Epoch 140 
2023-10-26 15:35:45.301137: Current learning rate: 0.00873 
2023-10-26 15:35:49.505262: train_loss -0.8554 
2023-10-26 15:35:49.505703: val_loss -0.7828 
2023-10-26 15:35:49.506052: Pseudo dice [0.8356, 0.9218, 0.9704, 0.4921, 0.9262] 
2023-10-26 15:35:49.506317: Epoch time: 4.21 s 
2023-10-26 15:35:50.656656:  
2023-10-26 15:35:50.656974: Epoch 141 
2023-10-26 15:35:50.657223: Current learning rate: 0.00872 
2023-10-26 15:35:54.912740: train_loss -0.8645 
2023-10-26 15:35:54.913134: val_loss -0.8081 
2023-10-26 15:35:54.913460: Pseudo dice [0.8535, 0.928, 0.9706, 0.7224, 0.8663] 
2023-10-26 15:35:54.913728: Epoch time: 4.26 s 
2023-10-26 15:35:56.034716:  
2023-10-26 15:35:56.035129: Epoch 142 
2023-10-26 15:35:56.035422: Current learning rate: 0.00871 
2023-10-26 15:36:00.334497: train_loss -0.8737 
2023-10-26 15:36:00.334984: val_loss -0.8194 
2023-10-26 15:36:00.335337: Pseudo dice [0.8474, 0.9196, 0.9681, 0.7497, 0.9365] 
2023-10-26 15:36:00.335637: Epoch time: 4.3 s 
2023-10-26 15:36:01.466962:  
2023-10-26 15:36:01.467283: Epoch 143 
2023-10-26 15:36:01.467529: Current learning rate: 0.0087 
2023-10-26 15:36:05.708530: train_loss -0.8723 
2023-10-26 15:36:05.708916: val_loss -0.8231 
2023-10-26 15:36:05.709170: Pseudo dice [0.8476, 0.9233, 0.9689, 0.7069, 0.9254] 
2023-10-26 15:36:05.709406: Epoch time: 4.24 s 
2023-10-26 15:36:05.709613: Yayy! New best EMA pseudo Dice: 0.8382 
2023-10-26 15:36:07.050404:  
2023-10-26 15:36:07.050713: Epoch 144 
2023-10-26 15:36:07.050953: Current learning rate: 0.00869 
2023-10-26 15:36:11.311103: train_loss -0.8657 
2023-10-26 15:36:11.311665: val_loss -0.8203 
2023-10-26 15:36:11.312031: Pseudo dice [0.849, 0.9253, 0.9679, 0.6829, 0.9418] 
2023-10-26 15:36:11.312306: Epoch time: 4.26 s 
2023-10-26 15:36:11.312621: Yayy! New best EMA pseudo Dice: 0.8417 
2023-10-26 15:36:12.477185:  
2023-10-26 15:36:12.477503: Epoch 145 
2023-10-26 15:36:12.477771: Current learning rate: 0.00868 
2023-10-26 15:36:16.772498: train_loss -0.8635 
2023-10-26 15:36:16.772884: val_loss -0.8168 
2023-10-26 15:36:16.773138: Pseudo dice [0.8392, 0.9222, 0.9654, 0.6774, 0.9141] 
2023-10-26 15:36:16.773376: Epoch time: 4.3 s 
2023-10-26 15:36:16.773582: Yayy! New best EMA pseudo Dice: 0.8439 
2023-10-26 15:36:17.931706:  
2023-10-26 15:36:17.932003: Epoch 146 
2023-10-26 15:36:17.932287: Current learning rate: 0.00868 
2023-10-26 15:36:22.233902: train_loss -0.8692 
2023-10-26 15:36:22.234284: val_loss -0.7936 
2023-10-26 15:36:22.234548: Pseudo dice [0.8387, 0.9197, 0.9661, 0.6795, 0.8543] 
2023-10-26 15:36:22.234772: Epoch time: 4.3 s 
2023-10-26 15:36:22.235009: Yayy! New best EMA pseudo Dice: 0.8447 
2023-10-26 15:36:23.410365:  
2023-10-26 15:36:23.410676: Epoch 147 
2023-10-26 15:36:23.411004: Current learning rate: 0.00867 
2023-10-26 15:36:27.742071: train_loss -0.8746 
2023-10-26 15:36:27.742571: val_loss -0.7737 
2023-10-26 15:36:27.743045: Pseudo dice [0.8537, 0.9216, 0.9689, 0.3851, 0.8452] 
2023-10-26 15:36:27.743400: Epoch time: 4.33 s 
2023-10-26 15:36:28.828390:  
2023-10-26 15:36:28.828727: Epoch 148 
2023-10-26 15:36:28.829022: Current learning rate: 0.00866 
2023-10-26 15:36:33.140075: train_loss -0.8744 
2023-10-26 15:36:33.140484: val_loss -0.8021 
2023-10-26 15:36:33.140754: Pseudo dice [0.8406, 0.9206, 0.9693, 0.7239, 0.7676] 
2023-10-26 15:36:33.141016: Epoch time: 4.31 s 
2023-10-26 15:36:34.224238:  
2023-10-26 15:36:34.224539: Epoch 149 
2023-10-26 15:36:34.224779: Current learning rate: 0.00865 
2023-10-26 15:36:38.421135: train_loss -0.8626 
2023-10-26 15:36:38.421522: val_loss -0.8071 
2023-10-26 15:36:38.421797: Pseudo dice [0.842, 0.9184, 0.967, 0.733, 0.8549] 
2023-10-26 15:36:38.422049: Epoch time: 4.2 s 
2023-10-26 15:36:39.599302:  
2023-10-26 15:36:39.599671: Epoch 150 
2023-10-26 15:36:39.599960: Current learning rate: 0.00864 
2023-10-26 15:36:44.129359: train_loss -0.8615 
2023-10-26 15:36:44.129754: val_loss -0.8152 
2023-10-26 15:36:44.130217: Pseudo dice [0.8503, 0.9202, 0.9672, 0.6861, 0.9242] 
2023-10-26 15:36:44.130533: Epoch time: 4.53 s 
2023-10-26 15:36:44.130778: Yayy! New best EMA pseudo Dice: 0.8452 
2023-10-26 15:36:45.303976:  
2023-10-26 15:36:45.304272: Epoch 151 
2023-10-26 15:36:45.304507: Current learning rate: 0.00863 
2023-10-26 15:36:49.989106: train_loss -0.8715 
2023-10-26 15:36:49.989522: val_loss -0.8231 
2023-10-26 15:36:49.990024: Pseudo dice [0.8531, 0.9271, 0.9672, 0.6675, 0.8738] 
2023-10-26 15:36:49.990317: Epoch time: 4.69 s 
2023-10-26 15:36:49.990564: Yayy! New best EMA pseudo Dice: 0.8464 
2023-10-26 15:36:51.144469:  
2023-10-26 15:36:51.144796: Epoch 152 
2023-10-26 15:36:51.145227: Current learning rate: 0.00862 
2023-10-26 15:36:55.490602: train_loss -0.8749 
2023-10-26 15:36:55.491008: val_loss -0.8331 
2023-10-26 15:36:55.491269: Pseudo dice [0.8473, 0.92, 0.9674, 0.7254, 0.9142] 
2023-10-26 15:36:55.491503: Epoch time: 4.35 s 
2023-10-26 15:36:55.491717: Yayy! New best EMA pseudo Dice: 0.8493 
2023-10-26 15:36:56.635029:  
2023-10-26 15:36:56.635336: Epoch 153 
2023-10-26 15:36:56.635609: Current learning rate: 0.00861 
2023-10-26 15:37:00.872974: train_loss -0.8731 
2023-10-26 15:37:00.873372: val_loss -0.8385 
2023-10-26 15:37:00.873634: Pseudo dice [0.8337, 0.9228, 0.9669, 0.7829, 0.9276] 
2023-10-26 15:37:00.873885: Epoch time: 4.24 s 
2023-10-26 15:37:00.874105: Yayy! New best EMA pseudo Dice: 0.853 
2023-10-26 15:37:02.044268:  
2023-10-26 15:37:02.044585: Epoch 154 
2023-10-26 15:37:02.044838: Current learning rate: 0.0086 
2023-10-26 15:37:06.167330: train_loss -0.8593 
2023-10-26 15:37:06.167692: val_loss -0.8287 
2023-10-26 15:37:06.167952: Pseudo dice [0.8424, 0.9194, 0.9644, 0.7799, 0.9221] 
2023-10-26 15:37:06.168169: Epoch time: 4.12 s 
2023-10-26 15:37:06.168361: Yayy! New best EMA pseudo Dice: 0.8563 
2023-10-26 15:37:07.426056:  
2023-10-26 15:37:07.426378: Epoch 155 
2023-10-26 15:37:07.426621: Current learning rate: 0.00859 
2023-10-26 15:37:11.711917: train_loss -0.8731 
2023-10-26 15:37:11.712315: val_loss -0.8338 
2023-10-26 15:37:11.712562: Pseudo dice [0.8593, 0.9222, 0.968, 0.7793, 0.9368] 
2023-10-26 15:37:11.712792: Epoch time: 4.29 s 
2023-10-26 15:37:11.713002: Yayy! New best EMA pseudo Dice: 0.86 
2023-10-26 15:37:12.897245:  
2023-10-26 15:37:12.897550: Epoch 156 
2023-10-26 15:37:12.897802: Current learning rate: 0.00858 
2023-10-26 15:37:17.089584: train_loss -0.8702 
2023-10-26 15:37:17.089942: val_loss -0.8286 
2023-10-26 15:37:17.090197: Pseudo dice [0.8507, 0.9188, 0.9665, 0.7484, 0.857] 
2023-10-26 15:37:17.090438: Epoch time: 4.19 s 
2023-10-26 15:37:17.090677: Yayy! New best EMA pseudo Dice: 0.8608 
2023-10-26 15:37:18.477264:  
2023-10-26 15:37:18.477632: Epoch 157 
2023-10-26 15:37:18.477919: Current learning rate: 0.00858 
2023-10-26 15:37:22.613333: train_loss -0.8747 
2023-10-26 15:37:22.613837: val_loss -0.8194 
2023-10-26 15:37:22.614168: Pseudo dice [0.8438, 0.9219, 0.9683, 0.7939, 0.8554] 
2023-10-26 15:37:22.614586: Epoch time: 4.14 s 
2023-10-26 15:37:22.614892: Yayy! New best EMA pseudo Dice: 0.8624 
2023-10-26 15:37:23.805080:  
2023-10-26 15:37:23.805396: Epoch 158 
2023-10-26 15:37:23.805645: Current learning rate: 0.00857 
2023-10-26 15:37:27.958007: train_loss -0.8776 
2023-10-26 15:37:27.958417: val_loss -0.7856 
2023-10-26 15:37:27.958675: Pseudo dice [0.8367, 0.9122, 0.9672, 0.4545, 0.872] 
2023-10-26 15:37:27.958917: Epoch time: 4.15 s 
2023-10-26 15:37:29.066375:  
2023-10-26 15:37:29.066682: Epoch 159 
2023-10-26 15:37:29.066943: Current learning rate: 0.00856 
2023-10-26 15:37:33.295214: train_loss -0.8613 
2023-10-26 15:37:33.295605: val_loss -0.7199 
2023-10-26 15:37:33.295882: Pseudo dice [0.8196, 0.9096, 0.9674, 0.0, 0.8784] 
2023-10-26 15:37:33.296127: Epoch time: 4.23 s 
2023-10-26 15:37:34.538353:  
2023-10-26 15:37:34.704163: Epoch 160 
2023-10-26 15:37:34.704471: Current learning rate: 0.00855 
2023-10-26 15:37:38.792024: train_loss -0.8325 
2023-10-26 15:37:38.792445: val_loss -0.7553 
2023-10-26 15:37:38.792878: Pseudo dice [0.8088, 0.9213, 0.968, 0.0, 0.9411] 
2023-10-26 15:37:38.793207: Epoch time: 4.25 s 
2023-10-26 15:37:39.894069:  
2023-10-26 15:37:39.894405: Epoch 161 
2023-10-26 15:37:39.894674: Current learning rate: 0.00854 
2023-10-26 15:37:44.216506: train_loss -0.857 
2023-10-26 15:37:44.216949: val_loss -0.7624 
2023-10-26 15:37:44.217235: Pseudo dice [0.8471, 0.9149, 0.9678, 0.1224, 0.927] 
2023-10-26 15:37:44.217523: Epoch time: 4.32 s 
2023-10-26 15:37:45.359055:  
2023-10-26 15:37:45.359352: Epoch 162 
2023-10-26 15:37:45.359725: Current learning rate: 0.00853 
2023-10-26 15:37:49.680726: train_loss -0.8653 
2023-10-26 15:37:49.681105: val_loss -0.7535 
2023-10-26 15:37:49.681373: Pseudo dice [0.8358, 0.9169, 0.9695, 0.0359, 0.9013] 
2023-10-26 15:37:49.681617: Epoch time: 4.32 s 
2023-10-26 15:37:50.812658:  
2023-10-26 15:37:50.812978: Epoch 163 
2023-10-26 15:37:50.813244: Current learning rate: 0.00852 
2023-10-26 15:37:55.098551: train_loss -0.8673 
2023-10-26 15:37:55.098979: val_loss -0.76 
2023-10-26 15:37:55.099261: Pseudo dice [0.8417, 0.9221, 0.9688, 0.2994, 0.7965] 
2023-10-26 15:37:55.099500: Epoch time: 4.29 s 
2023-10-26 15:37:56.235663:  
2023-10-26 15:37:56.235958: Epoch 164 
2023-10-26 15:37:56.236216: Current learning rate: 0.00851 
2023-10-26 15:38:00.538994: train_loss -0.8734 
2023-10-26 15:38:00.539384: val_loss -0.7945 
2023-10-26 15:38:00.539635: Pseudo dice [0.8358, 0.9207, 0.9664, 0.6855, 0.8955] 
2023-10-26 15:38:00.539856: Epoch time: 4.3 s 
2023-10-26 15:38:01.621742:  
2023-10-26 15:38:01.622051: Epoch 165 
2023-10-26 15:38:01.622292: Current learning rate: 0.0085 
2023-10-26 15:38:05.953060: train_loss -0.8764 
2023-10-26 15:38:05.953575: val_loss -0.8022 
2023-10-26 15:38:05.953907: Pseudo dice [0.8389, 0.9217, 0.9668, 0.6617, 0.8657] 
2023-10-26 15:38:05.954169: Epoch time: 4.33 s 
2023-10-26 15:38:07.033144:  
2023-10-26 15:38:07.033451: Epoch 166 
2023-10-26 15:38:07.033686: Current learning rate: 0.00849 
2023-10-26 15:38:11.360707: train_loss -0.8677 
2023-10-26 15:38:11.361078: val_loss -0.8108 
2023-10-26 15:38:11.361332: Pseudo dice [0.8494, 0.9254, 0.9641, 0.677, 0.9247] 
2023-10-26 15:38:11.361551: Epoch time: 4.33 s 
2023-10-26 15:38:12.419053:  
2023-10-26 15:38:12.419350: Epoch 167 
2023-10-26 15:38:12.419591: Current learning rate: 0.00848 
2023-10-26 15:38:16.683625: train_loss -0.8596 
2023-10-26 15:38:16.684046: val_loss -0.8016 
2023-10-26 15:38:16.684552: Pseudo dice [0.8417, 0.9263, 0.9701, 0.721, 0.8971] 
2023-10-26 15:38:16.684799: Epoch time: 4.27 s 
2023-10-26 15:38:17.757272:  
2023-10-26 15:38:17.757587: Epoch 168 
2023-10-26 15:38:17.757981: Current learning rate: 0.00847 
2023-10-26 15:38:22.121488: train_loss -0.87 
2023-10-26 15:38:22.121865: val_loss -0.7626 
2023-10-26 15:38:22.122124: Pseudo dice [0.8387, 0.9189, 0.9669, 0.3405, 0.8196] 
2023-10-26 15:38:22.122358: Epoch time: 4.36 s 
2023-10-26 15:38:23.406701:  
2023-10-26 15:38:23.407003: Epoch 169 
2023-10-26 15:38:23.407291: Current learning rate: 0.00847 
2023-10-26 15:38:27.727364: train_loss -0.8779 
2023-10-26 15:38:27.727753: val_loss -0.8126 
2023-10-26 15:38:27.728012: Pseudo dice [0.8452, 0.9242, 0.9668, 0.7227, 0.8505] 
2023-10-26 15:38:27.728237: Epoch time: 4.32 s 
2023-10-26 15:38:28.925694:  
2023-10-26 15:38:28.926004: Epoch 170 
2023-10-26 15:38:28.926309: Current learning rate: 0.00846 
2023-10-26 15:38:33.142574: train_loss -0.8778 
2023-10-26 15:38:33.142981: val_loss -0.757 
2023-10-26 15:38:33.143247: Pseudo dice [0.8318, 0.9188, 0.9682, 0.2544, 0.7686] 
2023-10-26 15:38:33.143496: Epoch time: 4.22 s 
2023-10-26 15:38:34.272635:  
2023-10-26 15:38:34.273012: Epoch 171 
2023-10-26 15:38:34.273348: Current learning rate: 0.00845 
2023-10-26 15:38:38.429899: train_loss -0.8744 
2023-10-26 15:38:38.430294: val_loss -0.7891 
2023-10-26 15:38:38.430551: Pseudo dice [0.8307, 0.9181, 0.9673, 0.3538, 0.9134] 
2023-10-26 15:38:38.430788: Epoch time: 4.16 s 
2023-10-26 15:38:39.528991:  
2023-10-26 15:38:39.529293: Epoch 172 
2023-10-26 15:38:39.529530: Current learning rate: 0.00844 
2023-10-26 15:38:43.710656: train_loss -0.8747 
2023-10-26 15:38:43.711065: val_loss -0.7833 
2023-10-26 15:38:43.711336: Pseudo dice [0.8394, 0.9207, 0.9661, 0.4071, 0.8331] 
2023-10-26 15:38:43.711575: Epoch time: 4.18 s 
2023-10-26 15:38:44.804566:  
2023-10-26 15:38:44.804863: Epoch 173 
2023-10-26 15:38:44.805113: Current learning rate: 0.00843 
2023-10-26 15:38:49.000541: train_loss -0.881 
2023-10-26 15:38:49.000959: val_loss -0.8131 
2023-10-26 15:38:49.001269: Pseudo dice [0.836, 0.9179, 0.9664, 0.4993, 0.9227] 
2023-10-26 15:38:49.001560: Epoch time: 4.2 s 
2023-10-26 15:38:50.093187:  
2023-10-26 15:38:50.093472: Epoch 174 
2023-10-26 15:38:50.093705: Current learning rate: 0.00842 
2023-10-26 15:38:54.365891: train_loss -0.8811 
2023-10-26 15:38:54.366665: val_loss -0.7914 
2023-10-26 15:38:54.366948: Pseudo dice [0.8355, 0.9219, 0.9689, 0.571, 0.8665] 
2023-10-26 15:38:54.367186: Epoch time: 4.27 s 
2023-10-26 15:38:55.640818:  
2023-10-26 15:38:55.641135: Epoch 175 
2023-10-26 15:38:55.641372: Current learning rate: 0.00841 
2023-10-26 15:38:59.977638: train_loss -0.882 
2023-10-26 15:38:59.978023: val_loss -0.8114 
2023-10-26 15:38:59.978282: Pseudo dice [0.8378, 0.9177, 0.9644, 0.6798, 0.8377] 
2023-10-26 15:38:59.978539: Epoch time: 4.34 s 
2023-10-26 15:39:01.133256:  
2023-10-26 15:39:01.133565: Epoch 176 
2023-10-26 15:39:01.133812: Current learning rate: 0.0084 
2023-10-26 15:39:05.285939: train_loss -0.8712 
2023-10-26 15:39:05.286298: val_loss -0.8049 
2023-10-26 15:39:05.286548: Pseudo dice [0.8454, 0.9206, 0.9696, 0.5954, 0.9349] 
2023-10-26 15:39:05.286771: Epoch time: 4.15 s 
2023-10-26 15:39:06.372478:  
2023-10-26 15:39:06.372796: Epoch 177 
2023-10-26 15:39:06.373053: Current learning rate: 0.00839 
2023-10-26 15:39:10.524153: train_loss -0.8664 
2023-10-26 15:39:10.524548: val_loss -0.775 
2023-10-26 15:39:10.524804: Pseudo dice [0.8468, 0.9191, 0.9662, 0.4038, 0.8826] 
2023-10-26 15:39:10.525050: Epoch time: 4.15 s 
2023-10-26 15:39:11.628285:  
2023-10-26 15:39:11.628587: Epoch 178 
2023-10-26 15:39:11.628839: Current learning rate: 0.00838 
2023-10-26 15:39:15.779611: train_loss -0.8634 
2023-10-26 15:39:15.779980: val_loss -0.8035 
2023-10-26 15:39:15.780222: Pseudo dice [0.8465, 0.9169, 0.9682, 0.7514, 0.8348] 
2023-10-26 15:39:15.780438: Epoch time: 4.15 s 
2023-10-26 15:39:16.940952:  
2023-10-26 15:39:16.941261: Epoch 179 
2023-10-26 15:39:16.941509: Current learning rate: 0.00837 
2023-10-26 15:39:21.181456: train_loss -0.8668 
2023-10-26 15:39:21.181894: val_loss -0.7943 
2023-10-26 15:39:21.182322: Pseudo dice [0.8398, 0.9269, 0.9677, 0.6139, 0.9231] 
2023-10-26 15:39:21.182619: Epoch time: 4.24 s 
2023-10-26 15:39:22.319340:  
2023-10-26 15:39:22.319638: Epoch 180 
2023-10-26 15:39:22.319889: Current learning rate: 0.00836 
2023-10-26 15:39:26.413520: train_loss -0.8665 
2023-10-26 15:39:26.413924: val_loss -0.8135 
2023-10-26 15:39:26.414191: Pseudo dice [0.856, 0.9258, 0.9685, 0.6529, 0.8391] 
2023-10-26 15:39:26.414439: Epoch time: 4.09 s 
2023-10-26 15:39:27.738961:  
2023-10-26 15:39:27.739259: Epoch 181 
2023-10-26 15:39:27.739494: Current learning rate: 0.00836 
2023-10-26 15:39:32.002982: train_loss -0.8776 
2023-10-26 15:39:32.003335: val_loss -0.8062 
2023-10-26 15:39:32.003586: Pseudo dice [0.8531, 0.9239, 0.9668, 0.7511, 0.7266] 
2023-10-26 15:39:32.003812: Epoch time: 4.26 s 
2023-10-26 15:39:33.094886:  
2023-10-26 15:39:33.095188: Epoch 182 
2023-10-26 15:39:33.095433: Current learning rate: 0.00835 
2023-10-26 15:39:37.375576: train_loss -0.875 
2023-10-26 15:39:37.375950: val_loss -0.793 
2023-10-26 15:39:37.376197: Pseudo dice [0.8461, 0.9259, 0.9683, 0.6255, 0.8318] 
2023-10-26 15:39:37.376486: Epoch time: 4.28 s 
2023-10-26 15:39:38.456515:  
2023-10-26 15:39:38.456810: Epoch 183 
2023-10-26 15:39:38.457062: Current learning rate: 0.00834 
2023-10-26 15:39:42.490362: train_loss -0.8793 
2023-10-26 15:39:42.490721: val_loss -0.7985 
2023-10-26 15:39:42.490979: Pseudo dice [0.8432, 0.9231, 0.9644, 0.5304, 0.8681] 
2023-10-26 15:39:42.491204: Epoch time: 4.03 s 
2023-10-26 15:39:43.572155:  
2023-10-26 15:39:43.572468: Epoch 184 
2023-10-26 15:39:43.572707: Current learning rate: 0.00833 
2023-10-26 15:39:47.730557: train_loss -0.8757 
2023-10-26 15:39:47.730933: val_loss -0.8113 
2023-10-26 15:39:47.731193: Pseudo dice [0.8407, 0.9168, 0.9676, 0.688, 0.8998] 
2023-10-26 15:39:47.731487: Epoch time: 4.16 s 
2023-10-26 15:39:48.848573:  
2023-10-26 15:39:48.848880: Epoch 185 
2023-10-26 15:39:48.849149: Current learning rate: 0.00832 
2023-10-26 15:39:53.072331: train_loss -0.8649 
2023-10-26 15:39:53.072763: val_loss -0.8156 
2023-10-26 15:39:53.073026: Pseudo dice [0.8559, 0.9194, 0.9681, 0.6041, 0.9148] 
2023-10-26 15:39:53.073256: Epoch time: 4.22 s 
2023-10-26 15:39:54.166463:  
2023-10-26 15:39:54.166746: Epoch 186 
2023-10-26 15:39:54.166989: Current learning rate: 0.00831 
2023-10-26 15:39:58.516883: train_loss -0.877 
2023-10-26 15:39:58.517291: val_loss -0.716 
2023-10-26 15:39:58.517638: Pseudo dice [0.8334, 0.9115, 0.967, 0.0176, 0.8099] 
2023-10-26 15:39:58.517948: Epoch time: 4.35 s 
2023-10-26 15:39:59.813673:  
2023-10-26 15:39:59.814039: Epoch 187 
2023-10-26 15:39:59.814317: Current learning rate: 0.0083 
2023-10-26 15:40:04.093220: train_loss -0.8705 
2023-10-26 15:40:04.093590: val_loss -0.7444 
2023-10-26 15:40:04.093843: Pseudo dice [0.8483, 0.9249, 0.9676, 0.2979, 0.9219] 
2023-10-26 15:40:04.094067: Epoch time: 4.28 s 
2023-10-26 15:40:05.181502:  
2023-10-26 15:40:05.181812: Epoch 188 
2023-10-26 15:40:05.182056: Current learning rate: 0.00829 
2023-10-26 15:40:09.590492: train_loss -0.8558 
2023-10-26 15:40:09.591116: val_loss -0.81 
2023-10-26 15:40:09.591437: Pseudo dice [0.8442, 0.9259, 0.9662, 0.6323, 0.9287] 
2023-10-26 15:40:09.591721: Epoch time: 4.41 s 
2023-10-26 15:40:10.673840:  
2023-10-26 15:40:10.674228: Epoch 189 
2023-10-26 15:40:10.674562: Current learning rate: 0.00828 
2023-10-26 15:40:14.940123: train_loss -0.8671 
2023-10-26 15:40:14.940507: val_loss -0.8059 
2023-10-26 15:40:14.940763: Pseudo dice [0.8506, 0.9331, 0.9669, 0.6002, 0.9163] 
2023-10-26 15:40:14.941035: Epoch time: 4.27 s 
2023-10-26 15:40:16.021909:  
2023-10-26 15:40:16.022223: Epoch 190 
2023-10-26 15:40:16.022468: Current learning rate: 0.00827 
2023-10-26 15:40:20.252001: train_loss -0.8751 
2023-10-26 15:40:20.252452: val_loss -0.7884 
2023-10-26 15:40:20.252722: Pseudo dice [0.8556, 0.9305, 0.9676, 0.3815, 0.8761] 
2023-10-26 15:40:20.252956: Epoch time: 4.23 s 
2023-10-26 15:40:21.392826:  
2023-10-26 15:40:21.393252: Epoch 191 
2023-10-26 15:40:21.393596: Current learning rate: 0.00826 
2023-10-26 15:40:25.573667: train_loss -0.871 
2023-10-26 15:40:25.574068: val_loss -0.7423 
2023-10-26 15:40:25.574338: Pseudo dice [0.8196, 0.912, 0.9678, 0.0602, 0.9357] 
2023-10-26 15:40:25.574577: Epoch time: 4.18 s 
2023-10-26 15:40:26.679009:  
2023-10-26 15:40:26.679306: Epoch 192 
2023-10-26 15:40:26.679551: Current learning rate: 0.00825 
2023-10-26 15:40:30.893589: train_loss -0.8697 
2023-10-26 15:40:30.893955: val_loss -0.8223 
2023-10-26 15:40:30.894339: Pseudo dice [0.8452, 0.922, 0.9656, 0.6803, 0.9348] 
2023-10-26 15:40:30.894814: Epoch time: 4.22 s 
2023-10-26 15:40:32.185049:  
2023-10-26 15:40:32.185376: Epoch 193 
2023-10-26 15:40:32.185638: Current learning rate: 0.00824 
2023-10-26 15:40:36.235335: train_loss -0.8686 
2023-10-26 15:40:36.235674: val_loss -0.7993 
2023-10-26 15:40:36.235933: Pseudo dice [0.8328, 0.9177, 0.9684, 0.5604, 0.9251] 
2023-10-26 15:40:36.236165: Epoch time: 4.05 s 
2023-10-26 15:40:37.341642:  
2023-10-26 15:40:37.342019: Epoch 194 
2023-10-26 15:40:37.342336: Current learning rate: 0.00824 
2023-10-26 15:40:41.531880: train_loss -0.8703 
2023-10-26 15:40:41.532308: val_loss -0.8142 
2023-10-26 15:40:41.532713: Pseudo dice [0.8606, 0.9264, 0.9667, 0.6667, 0.9178] 
2023-10-26 15:40:41.533082: Epoch time: 4.19 s 
2023-10-26 15:40:42.670516:  
2023-10-26 15:40:42.670822: Epoch 195 
2023-10-26 15:40:42.671072: Current learning rate: 0.00823 
2023-10-26 15:40:46.873340: train_loss -0.872 
2023-10-26 15:40:46.873735: val_loss -0.8031 
2023-10-26 15:40:46.874032: Pseudo dice [0.8311, 0.9238, 0.9669, 0.5905, 0.8702] 
2023-10-26 15:40:46.874266: Epoch time: 4.2 s 
2023-10-26 15:40:48.012665:  
2023-10-26 15:40:48.012987: Epoch 196 
2023-10-26 15:40:48.013263: Current learning rate: 0.00822 
2023-10-26 15:40:52.136495: train_loss -0.8746 
2023-10-26 15:40:52.136895: val_loss -0.7645 
2023-10-26 15:40:52.137144: Pseudo dice [0.8355, 0.9194, 0.9667, 0.396, 0.7773] 
2023-10-26 15:40:52.137383: Epoch time: 4.12 s 
2023-10-26 15:40:53.265931:  
2023-10-26 15:40:53.266217: Epoch 197 
2023-10-26 15:40:53.266452: Current learning rate: 0.00821 
2023-10-26 15:40:57.469704: train_loss -0.8711 
2023-10-26 15:40:57.470149: val_loss -0.7645 
2023-10-26 15:40:57.470543: Pseudo dice [0.8377, 0.9166, 0.965, 0.3257, 0.8624] 
2023-10-26 15:40:57.470803: Epoch time: 4.2 s 
2023-10-26 15:40:58.591001:  
2023-10-26 15:40:58.591298: Epoch 198 
2023-10-26 15:40:58.591538: Current learning rate: 0.0082 
2023-10-26 15:41:02.741878: train_loss -0.8674 
2023-10-26 15:41:02.742236: val_loss -0.7845 
2023-10-26 15:41:02.742497: Pseudo dice [0.8413, 0.9217, 0.9653, 0.4604, 0.8812] 
2023-10-26 15:41:02.742729: Epoch time: 4.15 s 
2023-10-26 15:41:04.106645:  
2023-10-26 15:41:04.107222: Epoch 199 
2023-10-26 15:41:04.107496: Current learning rate: 0.00819 
2023-10-26 15:41:08.214383: train_loss -0.8687 
2023-10-26 15:41:08.214796: val_loss -0.7856 
2023-10-26 15:41:08.215084: Pseudo dice [0.8423, 0.9186, 0.9683, 0.4886, 0.8931] 
2023-10-26 15:41:08.215331: Epoch time: 4.11 s 
2023-10-26 15:41:09.505879:  
2023-10-26 15:41:09.506172: Epoch 200 
2023-10-26 15:41:09.506411: Current learning rate: 0.00818 
2023-10-26 15:41:13.928711: train_loss -0.8717 
2023-10-26 15:41:13.929166: val_loss -0.7647 
2023-10-26 15:41:13.929464: Pseudo dice [0.844, 0.9246, 0.969, 0.3811, 0.8688] 
2023-10-26 15:41:13.929786: Epoch time: 4.42 s 
2023-10-26 15:41:15.057955:  
2023-10-26 15:41:15.058332: Epoch 201 
2023-10-26 15:41:15.058573: Current learning rate: 0.00817 
2023-10-26 15:41:19.248974: train_loss -0.871 
2023-10-26 15:41:19.249326: val_loss -0.7942 
2023-10-26 15:41:19.249582: Pseudo dice [0.8379, 0.922, 0.9666, 0.7419, 0.8072] 
2023-10-26 15:41:19.249816: Epoch time: 4.19 s 
2023-10-26 15:41:20.339613:  
2023-10-26 15:41:20.339918: Epoch 202 
2023-10-26 15:41:20.340174: Current learning rate: 0.00816 
2023-10-26 15:41:24.580122: train_loss -0.8653 
2023-10-26 15:41:24.580505: val_loss -0.7881 
2023-10-26 15:41:24.580762: Pseudo dice [0.8475, 0.9249, 0.9674, 0.4274, 0.9093] 
2023-10-26 15:41:24.581032: Epoch time: 4.24 s 
2023-10-26 15:41:25.705393:  
2023-10-26 15:41:25.705696: Epoch 203 
2023-10-26 15:41:25.705976: Current learning rate: 0.00815 
2023-10-26 15:41:30.001905: train_loss -0.872 
2023-10-26 15:41:30.002267: val_loss -0.7704 
2023-10-26 15:41:30.002525: Pseudo dice [0.8472, 0.9251, 0.9691, 0.5198, 0.8212] 
2023-10-26 15:41:30.002743: Epoch time: 4.3 s 
2023-10-26 15:41:31.108248:  
2023-10-26 15:41:31.108548: Epoch 204 
2023-10-26 15:41:31.108790: Current learning rate: 0.00814 
2023-10-26 15:41:35.396357: train_loss -0.8657 
2023-10-26 15:41:35.396763: val_loss -0.7938 
2023-10-26 15:41:35.397210: Pseudo dice [0.845, 0.9252, 0.968, 0.4837, 0.8606] 
2023-10-26 15:41:35.397470: Epoch time: 4.29 s 
2023-10-26 15:41:36.705041:  
2023-10-26 15:41:36.705362: Epoch 205 
2023-10-26 15:41:36.705601: Current learning rate: 0.00813 
2023-10-26 15:41:40.921978: train_loss -0.8748 
2023-10-26 15:41:40.922385: val_loss -0.7728 
2023-10-26 15:41:40.922647: Pseudo dice [0.8345, 0.9187, 0.9661, 0.3616, 0.8559] 
2023-10-26 15:41:40.922891: Epoch time: 4.22 s 
2023-10-26 15:41:41.985687:  
2023-10-26 15:41:41.985993: Epoch 206 
2023-10-26 15:41:41.986233: Current learning rate: 0.00813 
2023-10-26 15:41:46.203328: train_loss -0.8748 
2023-10-26 15:41:46.203750: val_loss -0.7539 
2023-10-26 15:41:46.204113: Pseudo dice [0.8428, 0.9253, 0.9675, 0.2407, 0.8067] 
2023-10-26 15:41:46.204375: Epoch time: 4.22 s 
2023-10-26 15:41:47.281807:  
2023-10-26 15:41:47.282107: Epoch 207 
2023-10-26 15:41:47.282351: Current learning rate: 0.00812 
2023-10-26 15:41:51.495790: train_loss -0.8759 
2023-10-26 15:41:51.496161: val_loss -0.7621 
2023-10-26 15:41:51.496417: Pseudo dice [0.8466, 0.9275, 0.9685, 0.4921, 0.7258] 
2023-10-26 15:41:51.496638: Epoch time: 4.21 s 
2023-10-26 15:41:52.623236:  
2023-10-26 15:41:52.623583: Epoch 208 
2023-10-26 15:41:52.623899: Current learning rate: 0.00811 
2023-10-26 15:41:56.815735: train_loss -0.8748 
2023-10-26 15:41:56.816193: val_loss -0.7799 
2023-10-26 15:41:56.816584: Pseudo dice [0.8297, 0.9236, 0.9692, 0.3338, 0.9241] 
2023-10-26 15:41:56.816914: Epoch time: 4.19 s 
2023-10-26 15:41:57.886546:  
2023-10-26 15:41:57.886865: Epoch 209 
2023-10-26 15:41:57.887119: Current learning rate: 0.0081 
2023-10-26 15:42:02.060201: train_loss -0.8803 
2023-10-26 15:42:02.060603: val_loss -0.8118 
2023-10-26 15:42:02.060927: Pseudo dice [0.8471, 0.9253, 0.9678, 0.5491, 0.9139] 
2023-10-26 15:42:02.061256: Epoch time: 4.17 s 
2023-10-26 15:42:03.137954:  
2023-10-26 15:42:03.138266: Epoch 210 
2023-10-26 15:42:03.138513: Current learning rate: 0.00809 
2023-10-26 15:42:07.322357: train_loss -0.8688 
2023-10-26 15:42:07.322757: val_loss -0.7946 
2023-10-26 15:42:07.323059: Pseudo dice [0.8535, 0.9221, 0.966, 0.4032, 0.9289] 
2023-10-26 15:42:07.323364: Epoch time: 4.19 s 
2023-10-26 15:42:08.406373:  
2023-10-26 15:42:08.406675: Epoch 211 
2023-10-26 15:42:08.406934: Current learning rate: 0.00808 
2023-10-26 15:42:12.359155: train_loss -0.8656 
2023-10-26 15:42:12.359537: val_loss -0.8077 
2023-10-26 15:42:12.359805: Pseudo dice [0.8622, 0.9266, 0.9681, 0.57, 0.9116] 
2023-10-26 15:42:12.360054: Epoch time: 3.95 s 
2023-10-26 15:42:13.630208:  
2023-10-26 15:42:13.630566: Epoch 212 
2023-10-26 15:42:13.630812: Current learning rate: 0.00807 
2023-10-26 15:42:17.827681: train_loss -0.8712 
2023-10-26 15:42:17.828280: val_loss -0.7707 
2023-10-26 15:42:17.828580: Pseudo dice [0.8316, 0.9225, 0.9671, 0.0881, 0.9214] 
2023-10-26 15:42:17.828845: Epoch time: 4.2 s 
2023-10-26 15:42:18.917466:  
2023-10-26 15:42:18.917843: Epoch 213 
2023-10-26 15:42:18.918198: Current learning rate: 0.00806 
2023-10-26 15:42:23.024943: train_loss -0.8683 
2023-10-26 15:42:23.025295: val_loss -0.7671 
2023-10-26 15:42:23.025547: Pseudo dice [0.829, 0.9206, 0.969, 0.3998, 0.7221] 
2023-10-26 15:42:23.025764: Epoch time: 4.11 s 
2023-10-26 15:42:24.120870:  
2023-10-26 15:42:24.121203: Epoch 214 
2023-10-26 15:42:24.121454: Current learning rate: 0.00805 
2023-10-26 15:42:28.206654: train_loss -0.8711 
2023-10-26 15:42:28.207024: val_loss -0.75 
2023-10-26 15:42:28.207282: Pseudo dice [0.8336, 0.9198, 0.9678, 0.0, 0.9075] 
2023-10-26 15:42:28.207510: Epoch time: 4.09 s 
2023-10-26 15:42:29.281178:  
2023-10-26 15:42:29.281469: Epoch 215 
2023-10-26 15:42:29.281714: Current learning rate: 0.00804 
2023-10-26 15:42:33.387162: train_loss -0.8665 
2023-10-26 15:42:33.387543: val_loss -0.7983 
2023-10-26 15:42:33.387819: Pseudo dice [0.8368, 0.9223, 0.9684, 0.5582, 0.9194] 
2023-10-26 15:42:33.388052: Epoch time: 4.11 s 
2023-10-26 15:42:34.543387:  
2023-10-26 15:42:34.543679: Epoch 216 
2023-10-26 15:42:34.543930: Current learning rate: 0.00803 
2023-10-26 15:42:38.757366: train_loss -0.8654 
2023-10-26 15:42:38.757723: val_loss -0.7743 
2023-10-26 15:42:38.757992: Pseudo dice [0.8475, 0.9159, 0.9645, 0.193, 0.9141] 
2023-10-26 15:42:38.758246: Epoch time: 4.21 s 
2023-10-26 15:42:39.855069:  
2023-10-26 15:42:39.855408: Epoch 217 
2023-10-26 15:42:39.855661: Current learning rate: 0.00802 
2023-10-26 15:42:44.277847: train_loss -0.8714 
2023-10-26 15:42:44.278187: val_loss -0.7938 
2023-10-26 15:42:44.278468: Pseudo dice [0.8377, 0.9229, 0.9672, 0.4926, 0.9021] 
2023-10-26 15:42:44.278784: Epoch time: 4.42 s 
2023-10-26 15:42:45.522631:  
2023-10-26 15:42:45.522925: Epoch 218 
2023-10-26 15:42:45.523173: Current learning rate: 0.00801 
2023-10-26 15:42:49.770054: train_loss -0.8729 
2023-10-26 15:42:49.770457: val_loss -0.7635 
2023-10-26 15:42:49.770728: Pseudo dice [0.8315, 0.9184, 0.9665, 0.1634, 0.9271] 
2023-10-26 15:42:49.770977: Epoch time: 4.25 s 
2023-10-26 15:42:50.879747:  
2023-10-26 15:42:50.880226: Epoch 219 
2023-10-26 15:42:50.880497: Current learning rate: 0.00801 
2023-10-26 15:42:55.236083: train_loss -0.878 
2023-10-26 15:42:55.236511: val_loss -0.7598 
2023-10-26 15:42:55.236780: Pseudo dice [0.8302, 0.9189, 0.9686, 0.1065, 0.8812] 
2023-10-26 15:42:55.237035: Epoch time: 4.36 s 
2023-10-26 15:42:56.317571:  
2023-10-26 15:42:56.317904: Epoch 220 
2023-10-26 15:42:56.318208: Current learning rate: 0.008 
2023-10-26 15:43:00.648814: train_loss -0.8754 
2023-10-26 15:43:00.649232: val_loss -0.7387 
2023-10-26 15:43:00.649492: Pseudo dice [0.8378, 0.9146, 0.9665, 0.0, 0.793] 
2023-10-26 15:43:00.649727: Epoch time: 4.33 s 
2023-10-26 15:43:01.746784:  
2023-10-26 15:43:01.747140: Epoch 221 
2023-10-26 15:43:01.747447: Current learning rate: 0.00799 
2023-10-26 15:43:05.840777: train_loss -0.8575 
2023-10-26 15:43:05.841141: val_loss -0.7967 
2023-10-26 15:43:05.841410: Pseudo dice [0.8361, 0.9232, 0.9691, 0.4202, 0.9024] 
2023-10-26 15:43:05.841640: Epoch time: 4.09 s 
2023-10-26 15:43:06.920108:  
2023-10-26 15:43:06.920409: Epoch 222 
2023-10-26 15:43:06.920672: Current learning rate: 0.00798 
2023-10-26 15:43:11.186459: train_loss -0.8718 
2023-10-26 15:43:11.187087: val_loss -0.7671 
2023-10-26 15:43:11.187535: Pseudo dice [0.8251, 0.925, 0.9663, 0.3306, 0.8238] 
2023-10-26 15:43:11.187888: Epoch time: 4.27 s 
2023-10-26 15:43:12.323778:  
2023-10-26 15:43:12.324096: Epoch 223 
2023-10-26 15:43:12.324414: Current learning rate: 0.00797 
2023-10-26 15:43:16.513794: train_loss -0.8841 
2023-10-26 15:43:16.514199: val_loss -0.7716 
2023-10-26 15:43:16.514465: Pseudo dice [0.829, 0.922, 0.9639, 0.325, 0.8056] 
2023-10-26 15:43:16.514691: Epoch time: 4.19 s 
2023-10-26 15:43:17.649746:  
2023-10-26 15:43:17.650063: Epoch 224 
2023-10-26 15:43:17.650314: Current learning rate: 0.00796 
2023-10-26 15:43:21.813012: train_loss -0.8792 
2023-10-26 15:43:21.813407: val_loss -0.7612 
2023-10-26 15:43:21.813667: Pseudo dice [0.8229, 0.928, 0.9699, 0.2949, 0.809] 
2023-10-26 15:43:21.813899: Epoch time: 4.16 s 
2023-10-26 15:43:23.115171:  
2023-10-26 15:43:23.115480: Epoch 225 
2023-10-26 15:43:23.115818: Current learning rate: 0.00795 
2023-10-26 15:43:27.383585: train_loss -0.8673 
2023-10-26 15:43:27.384002: val_loss -0.8117 
2023-10-26 15:43:27.384267: Pseudo dice [0.853, 0.9236, 0.966, 0.4964, 0.938] 
2023-10-26 15:43:27.384523: Epoch time: 4.27 s 
2023-10-26 15:43:28.447757:  
2023-10-26 15:43:28.448074: Epoch 226 
2023-10-26 15:43:28.448318: Current learning rate: 0.00794 
2023-10-26 15:43:32.655303: train_loss -0.8746 
2023-10-26 15:43:32.655728: val_loss -0.7808 
2023-10-26 15:43:32.656031: Pseudo dice [0.8364, 0.9218, 0.966, 0.313, 0.9313] 
2023-10-26 15:43:32.656285: Epoch time: 4.21 s 
2023-10-26 15:43:33.762462:  
2023-10-26 15:43:33.762816: Epoch 227 
2023-10-26 15:43:33.763073: Current learning rate: 0.00793 
2023-10-26 15:43:37.952342: train_loss -0.8751 
2023-10-26 15:43:37.952856: val_loss -0.8287 
2023-10-26 15:43:37.953173: Pseudo dice [0.8409, 0.9243, 0.9687, 0.6588, 0.925] 
2023-10-26 15:43:37.953486: Epoch time: 4.19 s 
2023-10-26 15:43:39.016944:  
2023-10-26 15:43:39.017248: Epoch 228 
2023-10-26 15:43:39.017505: Current learning rate: 0.00792 
2023-10-26 15:43:43.202310: train_loss -0.8803 
2023-10-26 15:43:43.202702: val_loss -0.7944 
2023-10-26 15:43:43.202955: Pseudo dice [0.8391, 0.9229, 0.9676, 0.5235, 0.8951] 
2023-10-26 15:43:43.203187: Epoch time: 4.19 s 
2023-10-26 15:43:44.268085:  
2023-10-26 15:43:44.268378: Epoch 229 
2023-10-26 15:43:44.268621: Current learning rate: 0.00791 
2023-10-26 15:43:48.534688: train_loss -0.8785 
2023-10-26 15:43:48.535090: val_loss -0.8131 
2023-10-26 15:43:48.535353: Pseudo dice [0.8404, 0.9217, 0.9678, 0.6129, 0.9217] 
2023-10-26 15:43:48.535590: Epoch time: 4.27 s 
2023-10-26 15:43:49.601706:  
2023-10-26 15:43:49.602009: Epoch 230 
2023-10-26 15:43:49.602255: Current learning rate: 0.0079 
2023-10-26 15:43:53.915960: train_loss -0.8819 
2023-10-26 15:43:53.916389: val_loss -0.8124 
2023-10-26 15:43:53.916656: Pseudo dice [0.8495, 0.9281, 0.9682, 0.6419, 0.8154] 
2023-10-26 15:43:53.916903: Epoch time: 4.31 s 
2023-10-26 15:43:54.977162:  
2023-10-26 15:43:54.977440: Epoch 231 
2023-10-26 15:43:54.977665: Current learning rate: 0.00789 
2023-10-26 15:43:59.194542: train_loss -0.877 
2023-10-26 15:43:59.194950: val_loss -0.7886 
2023-10-26 15:43:59.195293: Pseudo dice [0.8531, 0.9225, 0.9699, 0.6916, 0.8202] 
2023-10-26 15:43:59.195585: Epoch time: 4.22 s 
2023-10-26 15:44:00.429899:  
2023-10-26 15:44:00.430200: Epoch 232 
2023-10-26 15:44:00.430440: Current learning rate: 0.00789 
2023-10-26 15:44:04.736859: train_loss -0.8652 
2023-10-26 15:44:04.737222: val_loss -0.8022 
2023-10-26 15:44:04.737475: Pseudo dice [0.8349, 0.9194, 0.9663, 0.5928, 0.8845] 
2023-10-26 15:44:04.737724: Epoch time: 4.31 s 
2023-10-26 15:44:05.782766:  
2023-10-26 15:44:05.783063: Epoch 233 
2023-10-26 15:44:05.783297: Current learning rate: 0.00788 
2023-10-26 15:44:10.114849: train_loss -0.8803 
2023-10-26 15:44:10.115231: val_loss -0.8103 
2023-10-26 15:44:10.115505: Pseudo dice [0.8471, 0.9302, 0.9701, 0.6858, 0.8612] 
2023-10-26 15:44:10.115763: Epoch time: 4.33 s 
2023-10-26 15:44:11.199922:  
2023-10-26 15:44:11.200285: Epoch 234 
2023-10-26 15:44:11.200603: Current learning rate: 0.00787 
2023-10-26 15:44:15.455143: train_loss -0.8753 
2023-10-26 15:44:15.455549: val_loss -0.8189 
2023-10-26 15:44:15.455819: Pseudo dice [0.829, 0.9188, 0.9641, 0.7098, 0.8712] 
2023-10-26 15:44:15.456072: Epoch time: 4.26 s 
2023-10-26 15:44:16.503457:  
2023-10-26 15:44:16.503772: Epoch 235 
2023-10-26 15:44:16.504039: Current learning rate: 0.00786 
2023-10-26 15:44:20.860439: train_loss -0.8816 
2023-10-26 15:44:20.860903: val_loss -0.7821 
2023-10-26 15:44:20.861177: Pseudo dice [0.8326, 0.9212, 0.9665, 0.554, 0.788] 
2023-10-26 15:44:20.861426: Epoch time: 4.36 s 
2023-10-26 15:44:22.022770:  
2023-10-26 15:44:22.023125: Epoch 236 
2023-10-26 15:44:22.023371: Current learning rate: 0.00785 
2023-10-26 15:44:26.148514: train_loss -0.8844 
2023-10-26 15:44:26.148887: val_loss -0.7802 
2023-10-26 15:44:26.149162: Pseudo dice [0.8491, 0.9215, 0.9659, 0.6544, 0.6482] 
2023-10-26 15:44:26.149399: Epoch time: 4.13 s 
2023-10-26 15:44:27.187053:  
2023-10-26 15:44:27.187357: Epoch 237 
2023-10-26 15:44:27.187653: Current learning rate: 0.00784 
2023-10-26 15:44:31.456325: train_loss -0.8782 
2023-10-26 15:44:31.456682: val_loss -0.7956 
2023-10-26 15:44:31.456954: Pseudo dice [0.8541, 0.923, 0.9679, 0.338, 0.8928] 
2023-10-26 15:44:31.457209: Epoch time: 4.27 s 
2023-10-26 15:44:32.721725:  
2023-10-26 15:44:32.722035: Epoch 238 
2023-10-26 15:44:32.722270: Current learning rate: 0.00783 
2023-10-26 15:44:36.887772: train_loss -0.8703 
2023-10-26 15:44:36.888178: val_loss -0.7639 
2023-10-26 15:44:36.888433: Pseudo dice [0.8439, 0.9171, 0.9664, 0.0, 0.9386] 
2023-10-26 15:44:36.888659: Epoch time: 4.17 s 
2023-10-26 15:44:37.945236:  
2023-10-26 15:44:37.945538: Epoch 239 
2023-10-26 15:44:37.945781: Current learning rate: 0.00782 
2023-10-26 15:44:42.195317: train_loss -0.8628 
2023-10-26 15:44:42.195692: val_loss -0.8252 
2023-10-26 15:44:42.195949: Pseudo dice [0.832, 0.9204, 0.9654, 0.7129, 0.9211] 
2023-10-26 15:44:42.196174: Epoch time: 4.25 s 
2023-10-26 15:44:43.275470:  
2023-10-26 15:44:43.275792: Epoch 240 
2023-10-26 15:44:43.276051: Current learning rate: 0.00781 
2023-10-26 15:44:47.515227: train_loss -0.844 
2023-10-26 15:44:47.515591: val_loss -0.8395 
2023-10-26 15:44:47.515836: Pseudo dice [0.8518, 0.9206, 0.9661, 0.7099, 0.9357] 
2023-10-26 15:44:47.516055: Epoch time: 4.24 s 
2023-10-26 15:44:48.593604:  
2023-10-26 15:44:48.593994: Epoch 241 
2023-10-26 15:44:48.594236: Current learning rate: 0.0078 
2023-10-26 15:44:52.812593: train_loss -0.8572 
2023-10-26 15:44:52.813036: val_loss -0.7973 
2023-10-26 15:44:52.813310: Pseudo dice [0.8373, 0.9159, 0.9681, 0.3913, 0.9361] 
2023-10-26 15:44:52.813552: Epoch time: 4.22 s 
2023-10-26 15:44:53.891553:  
2023-10-26 15:44:53.891846: Epoch 242 
2023-10-26 15:44:53.892091: Current learning rate: 0.00779 
2023-10-26 15:44:58.093112: train_loss -0.8563 
2023-10-26 15:44:58.093472: val_loss -0.7643 
2023-10-26 15:44:58.093727: Pseudo dice [0.8321, 0.9197, 0.9672, 0.2179, 0.9338] 
2023-10-26 15:44:58.093951: Epoch time: 4.2 s 
2023-10-26 15:44:59.169869:  
2023-10-26 15:44:59.170175: Epoch 243 
2023-10-26 15:44:59.170414: Current learning rate: 0.00778 
2023-10-26 15:45:03.339372: train_loss -0.8647 
2023-10-26 15:45:03.339715: val_loss -0.7658 
2023-10-26 15:45:03.339964: Pseudo dice [0.8456, 0.9255, 0.9695, 0.1564, 0.9085] 
2023-10-26 15:45:03.340185: Epoch time: 4.17 s 
2023-10-26 15:45:04.446521:  
2023-10-26 15:45:04.446812: Epoch 244 
2023-10-26 15:45:04.447064: Current learning rate: 0.00777 
2023-10-26 15:45:08.747256: train_loss -0.8683 
2023-10-26 15:45:08.747623: val_loss -0.7663 
2023-10-26 15:45:08.747879: Pseudo dice [0.8396, 0.9219, 0.9685, 0.507, 0.9306] 
2023-10-26 15:45:08.748116: Epoch time: 4.3 s 
2023-10-26 15:45:10.017472:  
2023-10-26 15:45:10.017813: Epoch 245 
2023-10-26 15:45:10.018072: Current learning rate: 0.00777 
2023-10-26 15:45:14.233626: train_loss -0.8743 
2023-10-26 15:45:14.234055: val_loss -0.8284 
2023-10-26 15:45:14.234312: Pseudo dice [0.861, 0.9253, 0.9676, 0.6569, 0.9282] 
2023-10-26 15:45:14.234538: Epoch time: 4.22 s 
2023-10-26 15:45:15.313126:  
2023-10-26 15:45:15.313424: Epoch 246 
2023-10-26 15:45:15.313659: Current learning rate: 0.00776 
2023-10-26 15:45:19.532370: train_loss -0.87 
2023-10-26 15:45:19.532732: val_loss -0.8189 
2023-10-26 15:45:19.533019: Pseudo dice [0.8426, 0.925, 0.9655, 0.6801, 0.8857] 
2023-10-26 15:45:19.533255: Epoch time: 4.22 s 
2023-10-26 15:45:20.610097:  
2023-10-26 15:45:20.610412: Epoch 247 
2023-10-26 15:45:20.610657: Current learning rate: 0.00775 
2023-10-26 15:45:24.936604: train_loss -0.8753 
2023-10-26 15:45:24.936985: val_loss -0.8011 
2023-10-26 15:45:24.937245: Pseudo dice [0.8268, 0.9201, 0.9671, 0.7266, 0.7732] 
2023-10-26 15:45:24.937481: Epoch time: 4.33 s 
2023-10-26 15:45:26.003981:  
2023-10-26 15:45:26.004304: Epoch 248 
2023-10-26 15:45:26.004557: Current learning rate: 0.00774 
2023-10-26 15:45:30.374398: train_loss -0.8697 
2023-10-26 15:45:30.374778: val_loss -0.8047 
2023-10-26 15:45:30.375050: Pseudo dice [0.8506, 0.918, 0.9673, 0.5019, 0.9361] 
2023-10-26 15:45:30.375283: Epoch time: 4.37 s 
2023-10-26 15:45:31.492312:  
2023-10-26 15:45:31.492633: Epoch 249 
2023-10-26 15:45:31.492890: Current learning rate: 0.00773 
2023-10-26 15:45:35.705774: train_loss -0.8632 
2023-10-26 15:45:35.706174: val_loss -0.7227 
2023-10-26 15:45:35.706489: Pseudo dice [0.7838, 0.9065, 0.9672, 0.0, 0.878] 
2023-10-26 15:45:35.706742: Epoch time: 4.21 s 
2023-10-26 15:45:36.855982:  
2023-10-26 15:45:36.856313: Epoch 250 
2023-10-26 15:45:36.856564: Current learning rate: 0.00772 
2023-10-26 15:45:41.161115: train_loss -0.837 
2023-10-26 15:45:41.161455: val_loss -0.7595 
2023-10-26 15:45:41.161710: Pseudo dice [0.8445, 0.9207, 0.971, 0.0678, 0.9365] 
2023-10-26 15:45:41.161942: Epoch time: 4.31 s 
2023-10-26 15:45:42.473438:  
2023-10-26 15:45:42.473751: Epoch 251 
2023-10-26 15:45:42.473999: Current learning rate: 0.00771 
2023-10-26 15:45:46.538850: train_loss -0.853 
2023-10-26 15:45:46.539335: val_loss -0.806 
2023-10-26 15:45:46.539643: Pseudo dice [0.8411, 0.9135, 0.9687, 0.6107, 0.9288] 
2023-10-26 15:45:46.539932: Epoch time: 4.07 s 
2023-10-26 15:45:47.632843:  
2023-10-26 15:45:47.633170: Epoch 252 
2023-10-26 15:45:47.633413: Current learning rate: 0.0077 
2023-10-26 15:45:51.943289: train_loss -0.8466 
2023-10-26 15:45:51.943667: val_loss -0.8018 
2023-10-26 15:45:51.943933: Pseudo dice [0.8507, 0.9265, 0.9697, 0.5378, 0.9351] 
2023-10-26 15:45:51.944163: Epoch time: 4.31 s 
2023-10-26 15:45:53.013507:  
2023-10-26 15:45:53.013798: Epoch 253 
2023-10-26 15:45:53.014045: Current learning rate: 0.00769 
2023-10-26 15:45:57.212223: train_loss -0.8652 
2023-10-26 15:45:57.212685: val_loss -0.8233 
2023-10-26 15:45:57.213135: Pseudo dice [0.843, 0.9243, 0.9661, 0.7545, 0.9369] 
2023-10-26 15:45:57.213456: Epoch time: 4.2 s 
2023-10-26 15:45:58.355815:  
2023-10-26 15:45:58.356134: Epoch 254 
2023-10-26 15:45:58.356383: Current learning rate: 0.00768 
2023-10-26 15:46:02.625457: train_loss -0.8603 
2023-10-26 15:46:02.625869: val_loss -0.779 
2023-10-26 15:46:02.626163: Pseudo dice [0.8486, 0.918, 0.9656, 0.4791, 0.9201] 
2023-10-26 15:46:02.626428: Epoch time: 4.27 s 
2023-10-26 15:46:03.725628:  
2023-10-26 15:46:03.725927: Epoch 255 
2023-10-26 15:46:03.726160: Current learning rate: 0.00767 
2023-10-26 15:46:08.108409: train_loss -0.8611 
2023-10-26 15:46:08.108769: val_loss -0.8172 
2023-10-26 15:46:08.109026: Pseudo dice [0.8376, 0.9246, 0.9689, 0.7635, 0.9218] 
2023-10-26 15:46:08.109244: Epoch time: 4.38 s 
2023-10-26 15:46:09.191375:  
2023-10-26 15:46:09.191682: Epoch 256 
2023-10-26 15:46:09.191967: Current learning rate: 0.00766 
2023-10-26 15:46:13.517839: train_loss -0.8638 
2023-10-26 15:46:13.518363: val_loss -0.8235 
2023-10-26 15:46:13.518710: Pseudo dice [0.8406, 0.9241, 0.9666, 0.7436, 0.8986] 
2023-10-26 15:46:13.519025: Epoch time: 4.33 s 
2023-10-26 15:46:14.607359:  
2023-10-26 15:46:14.607649: Epoch 257 
2023-10-26 15:46:14.607898: Current learning rate: 0.00765 
2023-10-26 15:46:18.734635: train_loss -0.879 
2023-10-26 15:46:18.735037: val_loss -0.8054 
2023-10-26 15:46:18.735292: Pseudo dice [0.8485, 0.9259, 0.9672, 0.6438, 0.837] 
2023-10-26 15:46:18.735516: Epoch time: 4.13 s 
2023-10-26 15:46:20.014197:  
2023-10-26 15:46:20.014495: Epoch 258 
2023-10-26 15:46:20.014736: Current learning rate: 0.00764 
2023-10-26 15:46:24.310403: train_loss -0.8702 
2023-10-26 15:46:24.310764: val_loss -0.7403 
2023-10-26 15:46:24.311031: Pseudo dice [0.7812, 0.9002, 0.9654, 0.0206, 0.9047] 
2023-10-26 15:46:24.311264: Epoch time: 4.3 s 
2023-10-26 15:46:25.416645:  
2023-10-26 15:46:25.416955: Epoch 259 
2023-10-26 15:46:25.417201: Current learning rate: 0.00764 
2023-10-26 15:46:29.786971: train_loss -0.8642 
2023-10-26 15:46:29.787382: val_loss -0.8125 
2023-10-26 15:46:29.787645: Pseudo dice [0.8531, 0.9297, 0.9665, 0.7591, 0.8417] 
2023-10-26 15:46:29.787896: Epoch time: 4.37 s 
2023-10-26 15:46:30.874515:  
2023-10-26 15:46:30.874822: Epoch 260 
2023-10-26 15:46:30.875074: Current learning rate: 0.00763 
2023-10-26 15:46:35.160540: train_loss -0.8739 
2023-10-26 15:46:35.160968: val_loss -0.7989 
2023-10-26 15:46:35.161243: Pseudo dice [0.8393, 0.922, 0.9653, 0.6138, 0.8661] 
2023-10-26 15:46:35.161495: Epoch time: 4.29 s 
2023-10-26 15:46:36.252178:  
2023-10-26 15:46:36.252478: Epoch 261 
2023-10-26 15:46:36.252720: Current learning rate: 0.00762 
2023-10-26 15:46:40.625067: train_loss -0.8783 
2023-10-26 15:46:40.625432: val_loss -0.8207 
2023-10-26 15:46:40.625708: Pseudo dice [0.8431, 0.9235, 0.9668, 0.7118, 0.8679] 
2023-10-26 15:46:40.625970: Epoch time: 4.37 s 
2023-10-26 15:46:41.692677:  
2023-10-26 15:46:41.692973: Epoch 262 
2023-10-26 15:46:41.693213: Current learning rate: 0.00761 
2023-10-26 15:46:45.984965: train_loss -0.8764 
2023-10-26 15:46:45.985303: val_loss -0.795 
2023-10-26 15:46:45.985546: Pseudo dice [0.8514, 0.9263, 0.964, 0.4912, 0.8265] 
2023-10-26 15:46:45.985765: Epoch time: 4.29 s 
2023-10-26 15:46:47.037605:  
2023-10-26 15:46:47.037926: Epoch 263 
2023-10-26 15:46:47.038184: Current learning rate: 0.0076 
2023-10-26 15:46:51.310747: train_loss -0.879 
2023-10-26 15:46:51.311139: val_loss -0.8241 
2023-10-26 15:46:51.311409: Pseudo dice [0.8493, 0.9249, 0.9666, 0.7209, 0.877] 
2023-10-26 15:46:51.311644: Epoch time: 4.27 s 
2023-10-26 15:46:52.367726:  
2023-10-26 15:46:52.368033: Epoch 264 
2023-10-26 15:46:52.368268: Current learning rate: 0.00759 
2023-10-26 15:46:56.604072: train_loss -0.8789 
2023-10-26 15:46:56.604423: val_loss -0.7754 
2023-10-26 15:46:56.604681: Pseudo dice [0.8396, 0.9202, 0.967, 0.231, 0.9355] 
2023-10-26 15:46:56.604916: Epoch time: 4.24 s 
2023-10-26 15:46:57.828621:  
2023-10-26 15:46:57.828939: Epoch 265 
2023-10-26 15:46:57.829190: Current learning rate: 0.00758 
2023-10-26 15:47:02.036325: train_loss -0.8737 
2023-10-26 15:47:02.036716: val_loss -0.7459 
2023-10-26 15:47:02.036971: Pseudo dice [0.7445, 0.9016, 0.9602, 0.1474, 0.8653] 
2023-10-26 15:47:02.037219: Epoch time: 4.21 s 
2023-10-26 15:47:03.119338:  
2023-10-26 15:47:03.119630: Epoch 266 
2023-10-26 15:47:03.119885: Current learning rate: 0.00757 
2023-10-26 15:47:07.340215: train_loss -0.8607 
2023-10-26 15:47:07.340596: val_loss -0.7691 
2023-10-26 15:47:07.340853: Pseudo dice [0.8408, 0.922, 0.9679, 0.2452, 0.8472] 
2023-10-26 15:47:07.341096: Epoch time: 4.22 s 
2023-10-26 15:47:08.446015:  
2023-10-26 15:47:08.446319: Epoch 267 
2023-10-26 15:47:08.446565: Current learning rate: 0.00756 
2023-10-26 15:47:12.619742: train_loss -0.8689 
2023-10-26 15:47:12.620101: val_loss -0.7935 
2023-10-26 15:47:12.620359: Pseudo dice [0.8478, 0.9249, 0.9675, 0.5295, 0.8623] 
2023-10-26 15:47:12.620586: Epoch time: 4.17 s 
2023-10-26 15:47:13.724195:  
2023-10-26 15:47:13.724481: Epoch 268 
2023-10-26 15:47:13.724722: Current learning rate: 0.00755 
2023-10-26 15:47:17.953512: train_loss -0.861 
2023-10-26 15:47:17.953915: val_loss -0.8192 
2023-10-26 15:47:17.954236: Pseudo dice [0.8553, 0.9258, 0.9668, 0.7167, 0.8704] 
2023-10-26 15:47:17.954614: Epoch time: 4.23 s 
2023-10-26 15:47:19.057470:  
2023-10-26 15:47:19.057778: Epoch 269 
2023-10-26 15:47:19.058032: Current learning rate: 0.00754 
2023-10-26 15:47:23.342451: train_loss -0.8758 
2023-10-26 15:47:23.342897: val_loss -0.8049 
2023-10-26 15:47:23.343301: Pseudo dice [0.8513, 0.9244, 0.9663, 0.6011, 0.8578] 
2023-10-26 15:47:23.343551: Epoch time: 4.29 s 
2023-10-26 15:47:24.490455:  
2023-10-26 15:47:24.490766: Epoch 270 
2023-10-26 15:47:24.491013: Current learning rate: 0.00753 
2023-10-26 15:47:28.656496: train_loss -0.8814 
2023-10-26 15:47:28.656891: val_loss -0.8186 
2023-10-26 15:47:28.657166: Pseudo dice [0.8425, 0.9224, 0.9684, 0.6831, 0.8916] 
2023-10-26 15:47:28.657407: Epoch time: 4.17 s 
2023-10-26 15:47:30.082621:  
2023-10-26 15:47:30.082959: Epoch 271 
2023-10-26 15:47:30.083209: Current learning rate: 0.00752 
2023-10-26 15:47:34.376804: train_loss -0.8807 
2023-10-26 15:47:34.377224: val_loss -0.8231 
2023-10-26 15:47:34.377487: Pseudo dice [0.8485, 0.9216, 0.9664, 0.6778, 0.9058] 
2023-10-26 15:47:34.377761: Epoch time: 4.29 s 
2023-10-26 15:47:35.503493:  
2023-10-26 15:47:35.503867: Epoch 272 
2023-10-26 15:47:35.504129: Current learning rate: 0.00751 
2023-10-26 15:47:39.689802: train_loss -0.8793 
2023-10-26 15:47:39.690470: val_loss -0.8103 
2023-10-26 15:47:39.690827: Pseudo dice [0.8424, 0.9246, 0.9678, 0.6476, 0.893] 
2023-10-26 15:47:39.691179: Epoch time: 4.19 s 
2023-10-26 15:47:40.782590:  
2023-10-26 15:47:40.782918: Epoch 273 
2023-10-26 15:47:40.783174: Current learning rate: 0.00751 
2023-10-26 15:47:45.080277: train_loss -0.8804 
2023-10-26 15:47:45.080676: val_loss -0.806 
2023-10-26 15:47:45.080944: Pseudo dice [0.8356, 0.922, 0.9654, 0.6888, 0.8765] 
2023-10-26 15:47:45.081189: Epoch time: 4.3 s 
2023-10-26 15:47:46.203862:  
2023-10-26 15:47:46.204474: Epoch 274 
2023-10-26 15:47:46.204736: Current learning rate: 0.0075 
2023-10-26 15:47:50.424739: train_loss -0.8812 
2023-10-26 15:47:50.425138: val_loss -0.7986 
2023-10-26 15:47:50.425432: Pseudo dice [0.8466, 0.9225, 0.9685, 0.5848, 0.8484] 
2023-10-26 15:47:50.425673: Epoch time: 4.22 s 
2023-10-26 15:47:51.510470:  
2023-10-26 15:47:51.510772: Epoch 275 
2023-10-26 15:47:51.511019: Current learning rate: 0.00749 
2023-10-26 15:47:55.852463: train_loss -0.8757 
2023-10-26 15:47:55.852880: val_loss -0.7928 
2023-10-26 15:47:55.853155: Pseudo dice [0.8406, 0.9271, 0.9679, 0.6974, 0.6822] 
2023-10-26 15:47:55.853410: Epoch time: 4.34 s 
2023-10-26 15:47:56.945173:  
2023-10-26 15:47:56.945465: Epoch 276 
2023-10-26 15:47:56.945700: Current learning rate: 0.00748 
2023-10-26 15:48:01.319710: train_loss -0.8753 
2023-10-26 15:48:01.320135: val_loss -0.817 
2023-10-26 15:48:01.320410: Pseudo dice [0.851, 0.9272, 0.9688, 0.6775, 0.8648] 
2023-10-26 15:48:01.320658: Epoch time: 4.38 s 
2023-10-26 15:48:02.487564:  
2023-10-26 15:48:02.487888: Epoch 277 
2023-10-26 15:48:02.488169: Current learning rate: 0.00747 
2023-10-26 15:48:06.820310: train_loss -0.8796 
2023-10-26 15:48:06.820718: val_loss -0.8026 
2023-10-26 15:48:06.820996: Pseudo dice [0.8531, 0.9244, 0.966, 0.6092, 0.7855] 
2023-10-26 15:48:06.821227: Epoch time: 4.33 s 
2023-10-26 15:48:08.081390:  
2023-10-26 15:48:08.081712: Epoch 278 
2023-10-26 15:48:08.081973: Current learning rate: 0.00746 
2023-10-26 15:48:12.436170: train_loss -0.8789 
2023-10-26 15:48:12.436589: val_loss -0.7778 
2023-10-26 15:48:12.436850: Pseudo dice [0.8405, 0.9201, 0.9656, 0.4681, 0.851] 
2023-10-26 15:48:12.437126: Epoch time: 4.36 s 
2023-10-26 15:48:13.553547:  
2023-10-26 15:48:13.553883: Epoch 279 
2023-10-26 15:48:13.554160: Current learning rate: 0.00745 
2023-10-26 15:48:17.916581: train_loss -0.8776 
2023-10-26 15:48:17.916993: val_loss -0.8261 
2023-10-26 15:48:17.917286: Pseudo dice [0.8497, 0.9268, 0.9673, 0.7739, 0.9116] 
2023-10-26 15:48:17.917545: Epoch time: 4.36 s 
2023-10-26 15:48:19.011112:  
2023-10-26 15:48:19.011446: Epoch 280 
2023-10-26 15:48:19.011697: Current learning rate: 0.00744 
2023-10-26 15:48:23.277907: train_loss -0.8838 
2023-10-26 15:48:23.278283: val_loss -0.8107 
2023-10-26 15:48:23.278538: Pseudo dice [0.8384, 0.923, 0.9669, 0.7079, 0.8976] 
2023-10-26 15:48:23.278774: Epoch time: 4.27 s 
2023-10-26 15:48:24.380920:  
2023-10-26 15:48:24.381216: Epoch 281 
2023-10-26 15:48:24.381463: Current learning rate: 0.00743 
2023-10-26 15:48:28.557376: train_loss -0.888 
2023-10-26 15:48:28.557764: val_loss -0.8068 
2023-10-26 15:48:28.558050: Pseudo dice [0.8394, 0.9241, 0.9674, 0.7209, 0.8028] 
2023-10-26 15:48:28.558284: Epoch time: 4.18 s 
2023-10-26 15:48:29.650868:  
2023-10-26 15:48:29.651198: Epoch 282 
2023-10-26 15:48:29.651445: Current learning rate: 0.00742 
2023-10-26 15:48:33.876618: train_loss -0.8841 
2023-10-26 15:48:33.876976: val_loss -0.7976 
2023-10-26 15:48:33.877239: Pseudo dice [0.8501, 0.9251, 0.9659, 0.6393, 0.8246] 
2023-10-26 15:48:33.877482: Epoch time: 4.23 s 
2023-10-26 15:48:35.004450:  
2023-10-26 15:48:35.004753: Epoch 283 
2023-10-26 15:48:35.005015: Current learning rate: 0.00741 
2023-10-26 15:48:39.307353: train_loss -0.8869 
2023-10-26 15:48:39.307750: val_loss -0.8021 
2023-10-26 15:48:39.308014: Pseudo dice [0.8474, 0.9268, 0.9675, 0.6269, 0.8748] 
2023-10-26 15:48:39.308248: Epoch time: 4.3 s 
2023-10-26 15:48:40.604135:  
2023-10-26 15:48:40.604460: Epoch 284 
2023-10-26 15:48:40.604718: Current learning rate: 0.0074 
2023-10-26 15:48:44.807158: train_loss -0.8777 
2023-10-26 15:48:44.807588: val_loss -0.7801 
2023-10-26 15:48:44.807848: Pseudo dice [0.8473, 0.9117, 0.967, 0.6224, 0.765] 
2023-10-26 15:48:44.808103: Epoch time: 4.2 s 
2023-10-26 15:48:45.934216:  
2023-10-26 15:48:45.934510: Epoch 285 
2023-10-26 15:48:45.934760: Current learning rate: 0.00739 
2023-10-26 15:48:50.149292: train_loss -0.876 
2023-10-26 15:48:50.149670: val_loss -0.7438 
2023-10-26 15:48:50.149946: Pseudo dice [0.8479, 0.9193, 0.966, 0.0347, 0.7583] 
2023-10-26 15:48:50.150218: Epoch time: 4.22 s 
2023-10-26 15:48:51.226357:  
2023-10-26 15:48:51.226657: Epoch 286 
2023-10-26 15:48:51.226920: Current learning rate: 0.00738 
2023-10-26 15:48:55.471776: train_loss -0.8752 
2023-10-26 15:48:55.472146: val_loss -0.787 
2023-10-26 15:48:55.472420: Pseudo dice [0.8448, 0.9305, 0.97, 0.4413, 0.8857] 
2023-10-26 15:48:55.472646: Epoch time: 4.25 s 
2023-10-26 15:48:56.569486:  
2023-10-26 15:48:56.569785: Epoch 287 
2023-10-26 15:48:56.570038: Current learning rate: 0.00738 
2023-10-26 15:49:00.754447: train_loss -0.8826 
2023-10-26 15:49:00.754868: val_loss -0.7687 
2023-10-26 15:49:00.755239: Pseudo dice [0.8354, 0.9244, 0.9666, 0.382, 0.8762] 
2023-10-26 15:49:00.755515: Epoch time: 4.19 s 
2023-10-26 15:49:01.860109:  
2023-10-26 15:49:01.860396: Epoch 288 
2023-10-26 15:49:01.860632: Current learning rate: 0.00737 
2023-10-26 15:49:06.054305: train_loss -0.8827 
2023-10-26 15:49:06.054656: val_loss -0.8037 
2023-10-26 15:49:06.054918: Pseudo dice [0.8567, 0.9287, 0.9687, 0.6859, 0.8967] 
2023-10-26 15:49:06.055177: Epoch time: 4.19 s 
2023-10-26 15:49:07.138257:  
2023-10-26 15:49:07.138600: Epoch 289 
2023-10-26 15:49:07.138834: Current learning rate: 0.00736 
2023-10-26 15:49:11.328022: train_loss -0.8763 
2023-10-26 15:49:11.328419: val_loss -0.8103 
2023-10-26 15:49:11.328687: Pseudo dice [0.8364, 0.9203, 0.9671, 0.7362, 0.8821] 
2023-10-26 15:49:11.328962: Epoch time: 4.19 s 
2023-10-26 15:49:12.426363:  
2023-10-26 15:49:12.426654: Epoch 290 
2023-10-26 15:49:12.426899: Current learning rate: 0.00735 
2023-10-26 15:49:16.538565: train_loss -0.8851 
2023-10-26 15:49:16.539085: val_loss -0.8194 
2023-10-26 15:49:16.539595: Pseudo dice [0.8526, 0.9245, 0.9667, 0.6917, 0.877] 
2023-10-26 15:49:16.539926: Epoch time: 4.11 s 
2023-10-26 15:49:17.833261:  
2023-10-26 15:49:17.833561: Epoch 291 
2023-10-26 15:49:17.833821: Current learning rate: 0.00734 
2023-10-26 15:49:22.116685: train_loss -0.8817 
2023-10-26 15:49:22.117109: val_loss -0.7776 
2023-10-26 15:49:22.117368: Pseudo dice [0.8338, 0.927, 0.9682, 0.6264, 0.734] 
2023-10-26 15:49:22.117607: Epoch time: 4.28 s 
2023-10-26 15:49:23.226750:  
2023-10-26 15:49:23.227046: Epoch 292 
2023-10-26 15:49:23.227286: Current learning rate: 0.00733 
2023-10-26 15:49:27.483991: train_loss -0.8829 
2023-10-26 15:49:27.484603: val_loss -0.7614 
2023-10-26 15:49:27.484885: Pseudo dice [0.8369, 0.9267, 0.9649, 0.5, 0.698] 
2023-10-26 15:49:27.485123: Epoch time: 4.26 s 
2023-10-26 15:49:28.596095:  
2023-10-26 15:49:28.596389: Epoch 293 
2023-10-26 15:49:28.596615: Current learning rate: 0.00732 
2023-10-26 15:49:32.909412: train_loss -0.8781 
2023-10-26 15:49:32.909809: val_loss -0.7638 
2023-10-26 15:49:32.910132: Pseudo dice [0.8426, 0.9264, 0.9673, 0.2295, 0.7958] 
2023-10-26 15:49:32.910387: Epoch time: 4.31 s 
2023-10-26 15:49:34.056622:  
2023-10-26 15:49:34.056916: Epoch 294 
2023-10-26 15:49:34.057153: Current learning rate: 0.00731 
2023-10-26 15:49:38.212042: train_loss -0.884 
2023-10-26 15:49:38.212431: val_loss -0.7678 
2023-10-26 15:49:38.212697: Pseudo dice [0.8294, 0.9191, 0.9642, 0.3065, 0.8096] 
2023-10-26 15:49:38.213055: Epoch time: 4.16 s 
2023-10-26 15:49:39.328567:  
2023-10-26 15:49:39.328915: Epoch 295 
2023-10-26 15:49:39.329156: Current learning rate: 0.0073 
2023-10-26 15:49:43.674018: train_loss -0.8854 
2023-10-26 15:49:43.674370: val_loss -0.8087 
2023-10-26 15:49:43.674630: Pseudo dice [0.854, 0.925, 0.9673, 0.6792, 0.8892] 
2023-10-26 15:49:43.674852: Epoch time: 4.35 s 
2023-10-26 15:49:44.794276:  
2023-10-26 15:49:44.794616: Epoch 296 
2023-10-26 15:49:44.794894: Current learning rate: 0.00729 
2023-10-26 15:49:49.106943: train_loss -0.8833 
2023-10-26 15:49:49.107337: val_loss -0.7982 
2023-10-26 15:49:49.107589: Pseudo dice [0.848, 0.925, 0.9654, 0.5717, 0.8295] 
2023-10-26 15:49:49.107817: Epoch time: 4.31 s 
2023-10-26 15:49:50.355853:  
2023-10-26 15:49:50.356146: Epoch 297 
2023-10-26 15:49:50.356372: Current learning rate: 0.00728 
2023-10-26 15:49:54.830366: train_loss -0.8794 
2023-10-26 15:49:54.830720: val_loss -0.8227 
2023-10-26 15:49:54.830968: Pseudo dice [0.8562, 0.9275, 0.9679, 0.7023, 0.8766] 
2023-10-26 15:49:54.831198: Epoch time: 4.48 s 
2023-10-26 15:49:55.948071:  
2023-10-26 15:49:55.948418: Epoch 298 
2023-10-26 15:49:55.948668: Current learning rate: 0.00727 
2023-10-26 15:50:00.248542: train_loss -0.8796 
2023-10-26 15:50:00.248945: val_loss -0.8117 
2023-10-26 15:50:00.249207: Pseudo dice [0.8371, 0.9248, 0.9664, 0.7097, 0.8318] 
2023-10-26 15:50:00.249444: Epoch time: 4.3 s 
2023-10-26 15:50:01.417916:  
2023-10-26 15:50:01.418249: Epoch 299 
2023-10-26 15:50:01.418520: Current learning rate: 0.00726 
2023-10-26 15:50:05.631295: train_loss -0.8318 
2023-10-26 15:50:05.631663: val_loss -0.7392 
2023-10-26 15:50:05.631923: Pseudo dice [0.8231, 0.9178, 0.9682, 0.0, 0.9146] 
2023-10-26 15:50:05.632153: Epoch time: 4.21 s 
2023-10-26 15:50:06.811397:  
2023-10-26 15:50:06.811723: Epoch 300 
2023-10-26 15:50:06.811969: Current learning rate: 0.00725 
2023-10-26 15:50:11.104109: train_loss -0.8329 
2023-10-26 15:50:11.104466: val_loss -0.7209 
2023-10-26 15:50:11.104717: Pseudo dice [0.8284, 0.9179, 0.9682, 0.0288, 0.746] 
2023-10-26 15:50:11.104949: Epoch time: 4.29 s 
2023-10-26 15:50:12.219841:  
2023-10-26 15:50:12.220152: Epoch 301 
2023-10-26 15:50:12.220409: Current learning rate: 0.00724 
2023-10-26 15:50:16.530707: train_loss -0.8425 
2023-10-26 15:50:16.531126: val_loss -0.7451 
2023-10-26 15:50:16.531380: Pseudo dice [0.8418, 0.914, 0.9628, 0.1141, 0.8674] 
2023-10-26 15:50:16.531614: Epoch time: 4.31 s 
2023-10-26 15:50:17.640047:  
2023-10-26 15:50:17.640336: Epoch 302 
2023-10-26 15:50:17.640578: Current learning rate: 0.00724 
2023-10-26 15:50:21.877036: train_loss -0.8306 
2023-10-26 15:50:21.877445: val_loss -0.7446 
2023-10-26 15:50:21.877708: Pseudo dice [0.8525, 0.9219, 0.9683, 0.0969, 0.9288] 
2023-10-26 15:50:21.877960: Epoch time: 4.24 s 
2023-10-26 15:50:23.255539:  
2023-10-26 15:50:23.255839: Epoch 303 
2023-10-26 15:50:23.256086: Current learning rate: 0.00723 
2023-10-26 15:50:27.332947: train_loss -0.8312 
2023-10-26 15:50:27.333330: val_loss -0.7637 
2023-10-26 15:50:27.333577: Pseudo dice [0.8409, 0.9124, 0.9643, 0.2384, 0.8015] 
2023-10-26 15:50:27.333810: Epoch time: 4.08 s 
2023-10-26 15:50:28.445718:  
2023-10-26 15:50:28.446019: Epoch 304 
2023-10-26 15:50:28.446268: Current learning rate: 0.00722 
2023-10-26 15:50:32.677510: train_loss -0.8583 
2023-10-26 15:50:32.677931: val_loss -0.8059 
2023-10-26 15:50:32.678205: Pseudo dice [0.853, 0.9154, 0.9651, 0.5198, 0.9325] 
2023-10-26 15:50:32.678452: Epoch time: 4.23 s 
2023-10-26 15:50:33.809991:  
2023-10-26 15:50:33.810277: Epoch 305 
2023-10-26 15:50:33.810518: Current learning rate: 0.00721 
2023-10-26 15:50:37.909735: train_loss -0.8617 
2023-10-26 15:50:37.910146: val_loss -0.7655 
2023-10-26 15:50:37.910403: Pseudo dice [0.8176, 0.9226, 0.9652, 0.2141, 0.9115] 
2023-10-26 15:50:37.910629: Epoch time: 4.1 s 
2023-10-26 15:50:39.023905:  
2023-10-26 15:50:39.024204: Epoch 306 
2023-10-26 15:50:39.024451: Current learning rate: 0.0072 
2023-10-26 15:50:43.285187: train_loss -0.8684 
2023-10-26 15:50:43.285567: val_loss -0.7828 
2023-10-26 15:50:43.285843: Pseudo dice [0.8438, 0.9155, 0.9652, 0.384, 0.9257] 
2023-10-26 15:50:43.286069: Epoch time: 4.26 s 
2023-10-26 15:50:44.527425:  
2023-10-26 15:50:44.527815: Epoch 307 
2023-10-26 15:50:44.528210: Current learning rate: 0.00719 
2023-10-26 15:50:48.734361: train_loss -0.8683 
2023-10-26 15:50:48.734777: val_loss -0.8112 
2023-10-26 15:50:48.735057: Pseudo dice [0.8532, 0.9228, 0.9674, 0.4023, 0.9235] 
2023-10-26 15:50:48.735373: Epoch time: 4.21 s 
2023-10-26 15:50:49.840310:  
2023-10-26 15:50:49.840586: Epoch 308 
2023-10-26 15:50:49.840822: Current learning rate: 0.00718 
2023-10-26 15:50:53.994043: train_loss -0.8663 
2023-10-26 15:50:53.994406: val_loss -0.7976 
2023-10-26 15:50:53.994658: Pseudo dice [0.8615, 0.9301, 0.9669, 0.4843, 0.82] 
2023-10-26 15:50:53.994885: Epoch time: 4.15 s 
2023-10-26 15:50:55.108640:  
2023-10-26 15:50:55.108946: Epoch 309 
2023-10-26 15:50:55.109196: Current learning rate: 0.00717 
2023-10-26 15:50:59.353773: train_loss -0.8717 
2023-10-26 15:50:59.354211: val_loss -0.745 
2023-10-26 15:50:59.354504: Pseudo dice [0.8404, 0.9217, 0.9667, 0.0, 0.8826] 
2023-10-26 15:50:59.354750: Epoch time: 4.25 s 
2023-10-26 15:51:00.657739:  
2023-10-26 15:51:00.658057: Epoch 310 
2023-10-26 15:51:00.658305: Current learning rate: 0.00716 
2023-10-26 15:51:04.973515: train_loss -0.8781 
2023-10-26 15:51:04.973924: val_loss -0.7818 
2023-10-26 15:51:04.974200: Pseudo dice [0.8461, 0.9213, 0.967, 0.3161, 0.8624] 
2023-10-26 15:51:04.974437: Epoch time: 4.32 s 
2023-10-26 15:51:06.065840:  
2023-10-26 15:51:06.066172: Epoch 311 
2023-10-26 15:51:06.066433: Current learning rate: 0.00715 
2023-10-26 15:51:10.427841: train_loss -0.8806 
2023-10-26 15:51:10.428273: val_loss -0.8085 
2023-10-26 15:51:10.428550: Pseudo dice [0.8597, 0.9245, 0.9669, 0.4685, 0.8156] 
2023-10-26 15:51:10.428792: Epoch time: 4.36 s 
2023-10-26 15:51:11.530603:  
2023-10-26 15:51:11.530904: Epoch 312 
2023-10-26 15:51:11.531147: Current learning rate: 0.00714 
2023-10-26 15:51:15.790505: train_loss -0.8795 
2023-10-26 15:51:15.790901: val_loss -0.7852 
2023-10-26 15:51:15.791179: Pseudo dice [0.833, 0.9219, 0.9653, 0.5222, 0.8223] 
2023-10-26 15:51:15.791416: Epoch time: 4.26 s 
2023-10-26 15:51:16.881133:  
2023-10-26 15:51:16.881435: Epoch 313 
2023-10-26 15:51:16.881686: Current learning rate: 0.00713 
2023-10-26 15:51:21.165628: train_loss -0.8837 
2023-10-26 15:51:21.165997: val_loss -0.8086 
2023-10-26 15:51:21.166251: Pseudo dice [0.8451, 0.9264, 0.9656, 0.6697, 0.8351] 
2023-10-26 15:51:21.166500: Epoch time: 4.29 s 
2023-10-26 15:51:22.252692:  
2023-10-26 15:51:22.253000: Epoch 314 
2023-10-26 15:51:22.253246: Current learning rate: 0.00712 
2023-10-26 15:51:26.523500: train_loss -0.8698 
2023-10-26 15:51:26.523957: val_loss -0.7903 
2023-10-26 15:51:26.524304: Pseudo dice [0.8303, 0.9254, 0.966, 0.4709, 0.8505] 
2023-10-26 15:51:26.524575: Epoch time: 4.27 s 
2023-10-26 15:51:27.647986:  
2023-10-26 15:51:27.648353: Epoch 315 
2023-10-26 15:51:27.648611: Current learning rate: 0.00711 
2023-10-26 15:51:31.832415: train_loss -0.8523 
2023-10-26 15:51:31.832809: val_loss -0.7797 
2023-10-26 15:51:31.833086: Pseudo dice [0.8356, 0.9187, 0.9647, 0.3062, 0.9251] 
2023-10-26 15:51:31.833327: Epoch time: 4.19 s 
2023-10-26 15:51:33.093627:  
2023-10-26 15:51:33.093943: Epoch 316 
2023-10-26 15:51:33.094214: Current learning rate: 0.0071 
2023-10-26 15:51:37.464470: train_loss -0.8562 
2023-10-26 15:51:37.464864: val_loss -0.8076 
2023-10-26 15:51:37.465129: Pseudo dice [0.8454, 0.9217, 0.9646, 0.5431, 0.8601] 
2023-10-26 15:51:37.465396: Epoch time: 4.37 s 
2023-10-26 15:51:38.639564:  
2023-10-26 15:51:38.639899: Epoch 317 
2023-10-26 15:51:38.640140: Current learning rate: 0.0071 
2023-10-26 15:51:42.939595: train_loss -0.8698 
2023-10-26 15:51:42.939984: val_loss -0.7555 
2023-10-26 15:51:42.940252: Pseudo dice [0.8252, 0.916, 0.9671, 0.1944, 0.8552] 
2023-10-26 15:51:42.940482: Epoch time: 4.3 s 
2023-10-26 15:51:44.063843:  
2023-10-26 15:51:44.064162: Epoch 318 
2023-10-26 15:51:44.064421: Current learning rate: 0.00709 
2023-10-26 15:51:48.354371: train_loss -0.8761 
2023-10-26 15:51:48.354767: val_loss -0.8039 
2023-10-26 15:51:48.355030: Pseudo dice [0.8463, 0.9257, 0.9645, 0.6633, 0.7303] 
2023-10-26 15:51:48.355270: Epoch time: 4.29 s 
2023-10-26 15:51:49.467075:  
2023-10-26 15:51:49.467366: Epoch 319 
2023-10-26 15:51:49.467602: Current learning rate: 0.00708 
2023-10-26 15:51:53.656718: train_loss -0.8736 
2023-10-26 15:51:53.657082: val_loss -0.7919 
2023-10-26 15:51:53.657339: Pseudo dice [0.8518, 0.9207, 0.9665, 0.5057, 0.8233] 
2023-10-26 15:51:53.657573: Epoch time: 4.19 s 
2023-10-26 15:51:54.783249:  
2023-10-26 15:51:54.783543: Epoch 320 
2023-10-26 15:51:54.783771: Current learning rate: 0.00707 
2023-10-26 15:51:58.978657: train_loss -0.876 
2023-10-26 15:51:58.979140: val_loss -0.763 
2023-10-26 15:51:58.979470: Pseudo dice [0.8423, 0.9243, 0.9673, 0.2448, 0.8672] 
2023-10-26 15:51:58.979927: Epoch time: 4.2 s 
2023-10-26 15:52:00.101819:  
2023-10-26 15:52:00.102166: Epoch 321 
2023-10-26 15:52:00.102414: Current learning rate: 0.00706 
2023-10-26 15:52:04.340513: train_loss -0.8675 
2023-10-26 15:52:04.340929: val_loss -0.8108 
2023-10-26 15:52:04.341198: Pseudo dice [0.856, 0.9242, 0.965, 0.555, 0.865] 
2023-10-26 15:52:04.341437: Epoch time: 4.24 s 
2023-10-26 15:52:05.666819:  
2023-10-26 15:52:05.667133: Epoch 322 
2023-10-26 15:52:05.667376: Current learning rate: 0.00705 
2023-10-26 15:52:10.010734: train_loss -0.8643 
2023-10-26 15:52:10.011143: val_loss -0.8042 
2023-10-26 15:52:10.011415: Pseudo dice [0.8307, 0.9227, 0.9668, 0.6189, 0.8851] 
2023-10-26 15:52:10.011682: Epoch time: 4.34 s 
2023-10-26 15:52:11.121495:  
2023-10-26 15:52:11.121843: Epoch 323 
2023-10-26 15:52:11.122150: Current learning rate: 0.00704 
2023-10-26 15:52:15.463773: train_loss -0.8711 
2023-10-26 15:52:15.464138: val_loss -0.8081 
2023-10-26 15:52:15.464393: Pseudo dice [0.8285, 0.9258, 0.9637, 0.6231, 0.9107] 
2023-10-26 15:52:15.464625: Epoch time: 4.34 s 
2023-10-26 15:52:16.563919:  
2023-10-26 15:52:16.564217: Epoch 324 
2023-10-26 15:52:16.564464: Current learning rate: 0.00703 
2023-10-26 15:52:20.925710: train_loss -0.8755 
2023-10-26 15:52:20.926104: val_loss -0.8159 
2023-10-26 15:52:20.926364: Pseudo dice [0.8551, 0.9256, 0.9666, 0.547, 0.8695] 
2023-10-26 15:52:20.926611: Epoch time: 4.36 s 
2023-10-26 15:52:22.090323:  
2023-10-26 15:52:22.090611: Epoch 325 
2023-10-26 15:52:22.090878: Current learning rate: 0.00702 
2023-10-26 15:52:26.358274: train_loss -0.8812 
2023-10-26 15:52:26.358689: val_loss -0.803 
2023-10-26 15:52:26.358949: Pseudo dice [0.852, 0.9243, 0.9677, 0.5936, 0.7754] 
2023-10-26 15:52:26.359189: Epoch time: 4.27 s 
2023-10-26 15:52:27.476225:  
2023-10-26 15:52:27.476506: Epoch 326 
2023-10-26 15:52:27.476737: Current learning rate: 0.00701 
2023-10-26 15:52:31.779548: train_loss -0.8847 
2023-10-26 15:52:31.779963: val_loss -0.8017 
2023-10-26 15:52:31.780229: Pseudo dice [0.828, 0.9201, 0.9658, 0.4981, 0.8736] 
2023-10-26 15:52:31.780462: Epoch time: 4.3 s 
2023-10-26 15:52:32.895942:  
2023-10-26 15:52:32.896243: Epoch 327 
2023-10-26 15:52:32.896487: Current learning rate: 0.007 
2023-10-26 15:52:37.205538: train_loss -0.8843 
2023-10-26 15:52:37.205929: val_loss -0.7733 
2023-10-26 15:52:37.206219: Pseudo dice [0.8428, 0.9232, 0.9676, 0.3872, 0.8273] 
2023-10-26 15:52:37.206456: Epoch time: 4.31 s 
2023-10-26 15:52:38.319555:  
2023-10-26 15:52:38.319904: Epoch 328 
2023-10-26 15:52:38.320156: Current learning rate: 0.00699 
2023-10-26 15:52:42.744502: train_loss -0.8789 
2023-10-26 15:52:42.744922: val_loss -0.8112 
2023-10-26 15:52:42.745204: Pseudo dice [0.8401, 0.9182, 0.9671, 0.6986, 0.8717] 
2023-10-26 15:52:42.745449: Epoch time: 4.43 s 
2023-10-26 15:52:44.036113:  
2023-10-26 15:52:44.036422: Epoch 329 
2023-10-26 15:52:44.036663: Current learning rate: 0.00698 
2023-10-26 15:52:48.372790: train_loss -0.8777 
2023-10-26 15:52:48.373127: val_loss -0.8024 
2023-10-26 15:52:48.373384: Pseudo dice [0.8345, 0.9227, 0.9644, 0.587, 0.8473] 
2023-10-26 15:52:48.373608: Epoch time: 4.34 s 
2023-10-26 15:52:49.462043:  
2023-10-26 15:52:49.462340: Epoch 330 
2023-10-26 15:52:49.462579: Current learning rate: 0.00697 
2023-10-26 15:52:53.797827: train_loss -0.8729 
2023-10-26 15:52:53.798400: val_loss -0.7733 
2023-10-26 15:52:53.798650: Pseudo dice [0.8443, 0.9232, 0.9654, 0.3982, 0.8941] 
2023-10-26 15:52:53.798964: Epoch time: 4.34 s 
2023-10-26 15:52:54.908303:  
2023-10-26 15:52:54.908608: Epoch 331 
2023-10-26 15:52:54.908855: Current learning rate: 0.00696 
2023-10-26 15:52:59.051049: train_loss -0.8775 
2023-10-26 15:52:59.051666: val_loss -0.7841 
2023-10-26 15:52:59.052163: Pseudo dice [0.8409, 0.923, 0.968, 0.2754, 0.9291] 
2023-10-26 15:52:59.052518: Epoch time: 4.14 s 
2023-10-26 15:53:00.208928:  
2023-10-26 15:53:00.209270: Epoch 332 
2023-10-26 15:53:00.209540: Current learning rate: 0.00696 
2023-10-26 15:53:04.407296: train_loss -0.8872 
2023-10-26 15:53:04.407694: val_loss -0.7907 
2023-10-26 15:53:04.409472: Pseudo dice [0.8589, 0.9268, 0.9665, 0.4129, 0.762] 
2023-10-26 15:53:04.410024: Epoch time: 4.2 s 
2023-10-26 15:53:05.524441:  
2023-10-26 15:53:05.524758: Epoch 333 
2023-10-26 15:53:05.525020: Current learning rate: 0.00695 
2023-10-26 15:53:09.730788: train_loss -0.8812 
2023-10-26 15:53:09.731258: val_loss -0.8105 
2023-10-26 15:53:09.731662: Pseudo dice [0.8388, 0.9223, 0.9682, 0.6016, 0.8669] 
2023-10-26 15:53:09.731990: Epoch time: 4.21 s 
2023-10-26 15:53:10.859583:  
2023-10-26 15:53:10.859897: Epoch 334 
2023-10-26 15:53:10.860150: Current learning rate: 0.00694 
2023-10-26 15:53:14.995726: train_loss -0.8789 
2023-10-26 15:53:14.996126: val_loss -0.7558 
2023-10-26 15:53:14.996392: Pseudo dice [0.8262, 0.919, 0.9676, 0.0724, 0.8777] 
2023-10-26 15:53:14.996766: Epoch time: 4.14 s 
2023-10-26 15:53:16.325293:  
2023-10-26 15:53:16.325635: Epoch 335 
2023-10-26 15:53:16.325882: Current learning rate: 0.00693 
2023-10-26 15:53:20.594590: train_loss -0.8836 
2023-10-26 15:53:20.595014: val_loss -0.8056 
2023-10-26 15:53:20.595292: Pseudo dice [0.851, 0.9255, 0.9672, 0.605, 0.7927] 
2023-10-26 15:53:20.595546: Epoch time: 4.27 s 
2023-10-26 15:53:21.717295:  
2023-10-26 15:53:21.717610: Epoch 336 
2023-10-26 15:53:21.717854: Current learning rate: 0.00692 
2023-10-26 15:53:25.831259: train_loss -0.8789 
2023-10-26 15:53:25.831666: val_loss -0.7852 
2023-10-26 15:53:25.831932: Pseudo dice [0.8422, 0.9209, 0.9653, 0.4478, 0.7664] 
2023-10-26 15:53:25.832209: Epoch time: 4.11 s 
2023-10-26 15:53:27.037774:  
2023-10-26 15:53:27.038138: Epoch 337 
2023-10-26 15:53:27.038455: Current learning rate: 0.00691 
2023-10-26 15:53:31.090230: train_loss -0.8768 
2023-10-26 15:53:31.090609: val_loss -0.7911 
2023-10-26 15:53:31.090861: Pseudo dice [0.8553, 0.922, 0.9673, 0.444, 0.7782] 
2023-10-26 15:53:31.091114: Epoch time: 4.05 s 
2023-10-26 15:53:32.216191:  
2023-10-26 15:53:32.216570: Epoch 338 
2023-10-26 15:53:32.216927: Current learning rate: 0.0069 
2023-10-26 15:53:36.494990: train_loss -0.8881 
2023-10-26 15:53:36.495441: val_loss -0.8184 
2023-10-26 15:53:36.495902: Pseudo dice [0.845, 0.9271, 0.9678, 0.6992, 0.9016] 
2023-10-26 15:53:36.496234: Epoch time: 4.28 s 
2023-10-26 15:53:37.669250:  
2023-10-26 15:53:37.669571: Epoch 339 
2023-10-26 15:53:37.669841: Current learning rate: 0.00689 
2023-10-26 15:53:41.779499: train_loss -0.8826 
2023-10-26 15:53:41.779895: val_loss -0.7218 
2023-10-26 15:53:41.780148: Pseudo dice [0.7735, 0.9097, 0.964, 0.0, 0.9012] 
2023-10-26 15:53:41.780366: Epoch time: 4.11 s 
2023-10-26 15:53:42.916555:  
2023-10-26 15:53:42.916854: Epoch 340 
2023-10-26 15:53:42.917112: Current learning rate: 0.00688 
2023-10-26 15:53:46.903357: train_loss -0.8174 
2023-10-26 15:53:46.903720: val_loss -0.7366 
2023-10-26 15:53:46.904002: Pseudo dice [0.8493, 0.922, 0.9661, 0.0, 0.8429] 
2023-10-26 15:53:46.904235: Epoch time: 3.99 s 
2023-10-26 15:53:48.272810:  
2023-10-26 15:53:48.273109: Epoch 341 
2023-10-26 15:53:48.273359: Current learning rate: 0.00687 
2023-10-26 15:53:52.413109: train_loss -0.8418 
2023-10-26 15:53:52.413510: val_loss -0.7361 
2023-10-26 15:53:52.413767: Pseudo dice [0.8217, 0.9118, 0.9657, 0.0, 0.7579] 
2023-10-26 15:53:52.414013: Epoch time: 4.14 s 
2023-10-26 15:53:53.538985:  
2023-10-26 15:53:53.539271: Epoch 342 
2023-10-26 15:53:53.539507: Current learning rate: 0.00686 
2023-10-26 15:53:57.778093: train_loss -0.863 
2023-10-26 15:53:57.778460: val_loss -0.8185 
2023-10-26 15:53:57.778718: Pseudo dice [0.844, 0.9219, 0.9672, 0.6848, 0.8953] 
2023-10-26 15:53:57.778945: Epoch time: 4.24 s 
2023-10-26 15:53:58.982531:  
2023-10-26 15:53:58.982836: Epoch 343 
2023-10-26 15:53:58.983091: Current learning rate: 0.00685 
2023-10-26 15:54:03.274820: train_loss -0.8715 
2023-10-26 15:54:03.275208: val_loss -0.8152 
2023-10-26 15:54:03.275481: Pseudo dice [0.8533, 0.9233, 0.9654, 0.5745, 0.8808] 
2023-10-26 15:54:03.275740: Epoch time: 4.29 s 
2023-10-26 15:54:04.431395:  
2023-10-26 15:54:04.431697: Epoch 344 
2023-10-26 15:54:04.431947: Current learning rate: 0.00684 
2023-10-26 15:54:08.698604: train_loss -0.8728 
2023-10-26 15:54:08.699041: val_loss -0.8143 
2023-10-26 15:54:08.699312: Pseudo dice [0.8527, 0.9227, 0.9673, 0.707, 0.8217] 
2023-10-26 15:54:08.699555: Epoch time: 4.27 s 
2023-10-26 15:54:09.858240:  
2023-10-26 15:54:09.858544: Epoch 345 
2023-10-26 15:54:09.858824: Current learning rate: 0.00683 
2023-10-26 15:54:14.143036: train_loss -0.8489 
2023-10-26 15:54:14.143390: val_loss -0.7499 
2023-10-26 15:54:14.143652: Pseudo dice [0.839, 0.9078, 0.9616, 0.3225, 0.7298] 
2023-10-26 15:54:14.143885: Epoch time: 4.29 s 
2023-10-26 15:54:15.273160:  
2023-10-26 15:54:15.273448: Epoch 346 
2023-10-26 15:54:15.273681: Current learning rate: 0.00682 
2023-10-26 15:54:19.474588: train_loss -0.8622 
2023-10-26 15:54:19.475166: val_loss -0.8105 
2023-10-26 15:54:19.475631: Pseudo dice [0.8454, 0.9232, 0.9689, 0.5999, 0.8363] 
2023-10-26 15:54:19.475935: Epoch time: 4.2 s 
2023-10-26 15:54:20.845942:  
2023-10-26 15:54:20.846262: Epoch 347 
2023-10-26 15:54:20.846536: Current learning rate: 0.00681 
2023-10-26 15:54:25.094977: train_loss -0.8776 
2023-10-26 15:54:25.095438: val_loss -0.7836 
2023-10-26 15:54:25.095726: Pseudo dice [0.8448, 0.9228, 0.9657, 0.5836, 0.9055] 
2023-10-26 15:54:25.096016: Epoch time: 4.25 s 
2023-10-26 15:54:26.239894:  
2023-10-26 15:54:26.240237: Epoch 348 
2023-10-26 15:54:26.240499: Current learning rate: 0.0068 
2023-10-26 15:54:30.401622: train_loss -0.8759 
2023-10-26 15:54:30.402053: val_loss -0.7678 
2023-10-26 15:54:30.402328: Pseudo dice [0.8444, 0.9246, 0.9676, 0.3904, 0.7568] 
2023-10-26 15:54:30.402573: Epoch time: 4.16 s 
2023-10-26 15:54:31.545693:  
2023-10-26 15:54:31.546020: Epoch 349 
2023-10-26 15:54:31.546286: Current learning rate: 0.0068 
2023-10-26 15:54:35.853923: train_loss -0.8794 
2023-10-26 15:54:35.854314: val_loss -0.7719 
2023-10-26 15:54:35.854570: Pseudo dice [0.8505, 0.9269, 0.966, 0.2601, 0.848] 
2023-10-26 15:54:35.854810: Epoch time: 4.31 s 
2023-10-26 15:54:37.099534:  
2023-10-26 15:54:37.099837: Epoch 350 
2023-10-26 15:54:37.100126: Current learning rate: 0.00679 
2023-10-26 15:54:41.283103: train_loss -0.8768 
2023-10-26 15:54:41.283588: val_loss -0.7657 
2023-10-26 15:54:41.283967: Pseudo dice [0.8421, 0.915, 0.9644, 0.5178, 0.6469] 
2023-10-26 15:54:41.284319: Epoch time: 4.18 s 
2023-10-26 15:54:42.407409:  
2023-10-26 15:54:42.407718: Epoch 351 
2023-10-26 15:54:42.407966: Current learning rate: 0.00678 
2023-10-26 15:54:46.589661: train_loss -0.8751 
2023-10-26 15:54:46.590107: val_loss -0.8004 
2023-10-26 15:54:46.590429: Pseudo dice [0.8435, 0.9203, 0.9671, 0.5302, 0.8958] 
2023-10-26 15:54:46.590700: Epoch time: 4.18 s 
2023-10-26 15:54:47.760972:  
2023-10-26 15:54:47.761311: Epoch 352 
2023-10-26 15:54:47.761562: Current learning rate: 0.00677 
2023-10-26 15:54:51.981097: train_loss -0.8757 
2023-10-26 15:54:51.981475: val_loss -0.8023 
2023-10-26 15:54:51.981734: Pseudo dice [0.846, 0.9223, 0.9652, 0.398, 0.9087] 
2023-10-26 15:54:51.981986: Epoch time: 4.22 s 
2023-10-26 15:54:53.103623:  
2023-10-26 15:54:53.103926: Epoch 353 
2023-10-26 15:54:53.104184: Current learning rate: 0.00676 
2023-10-26 15:54:57.434176: train_loss -0.8756 
2023-10-26 15:54:57.434551: val_loss -0.7782 
2023-10-26 15:54:57.434800: Pseudo dice [0.8346, 0.9216, 0.9625, 0.3682, 0.8421] 
2023-10-26 15:54:57.435049: Epoch time: 4.33 s 
2023-10-26 15:54:58.560097:  
2023-10-26 15:54:58.560396: Epoch 354 
2023-10-26 15:54:58.560643: Current learning rate: 0.00675 
2023-10-26 15:55:02.781862: train_loss -0.8841 
2023-10-26 15:55:02.782263: val_loss -0.789 
2023-10-26 15:55:02.782531: Pseudo dice [0.8466, 0.9272, 0.9656, 0.4566, 0.7622] 
2023-10-26 15:55:02.782756: Epoch time: 4.22 s 
2023-10-26 15:55:03.976919:  
2023-10-26 15:55:03.977215: Epoch 355 
2023-10-26 15:55:03.977457: Current learning rate: 0.00674 
2023-10-26 15:55:08.195921: train_loss -0.8878 
2023-10-26 15:55:08.196343: val_loss -0.799 
2023-10-26 15:55:08.196613: Pseudo dice [0.8499, 0.9287, 0.9664, 0.4787, 0.8968] 
2023-10-26 15:55:08.196859: Epoch time: 4.22 s 
2023-10-26 15:55:09.326777:  
2023-10-26 15:55:09.327084: Epoch 356 
2023-10-26 15:55:09.327325: Current learning rate: 0.00673 
2023-10-26 15:55:13.466576: train_loss -0.8764 
2023-10-26 15:55:13.466996: val_loss -0.7914 
2023-10-26 15:55:13.467253: Pseudo dice [0.8307, 0.926, 0.9626, 0.3107, 0.9241] 
2023-10-26 15:55:13.467487: Epoch time: 4.14 s 
2023-10-26 15:55:14.650570:  
2023-10-26 15:55:14.650876: Epoch 357 
2023-10-26 15:55:14.651121: Current learning rate: 0.00672 
2023-10-26 15:55:18.953919: train_loss -0.8794 
2023-10-26 15:55:18.954326: val_loss -0.7815 
2023-10-26 15:55:18.954602: Pseudo dice [0.8352, 0.9186, 0.9653, 0.4636, 0.8691] 
2023-10-26 15:55:18.954842: Epoch time: 4.3 s 
2023-10-26 15:55:20.136298:  
2023-10-26 15:55:20.136607: Epoch 358 
2023-10-26 15:55:20.136855: Current learning rate: 0.00671 
2023-10-26 15:55:24.376010: train_loss -0.8835 
2023-10-26 15:55:24.376399: val_loss -0.737 
2023-10-26 15:55:24.376806: Pseudo dice [0.8455, 0.9248, 0.9664, 0.1734, 0.6787] 
2023-10-26 15:55:24.377234: Epoch time: 4.24 s 
2023-10-26 15:55:25.535278:  
2023-10-26 15:55:25.535585: Epoch 359 
2023-10-26 15:55:25.535834: Current learning rate: 0.0067 
2023-10-26 15:55:29.708429: train_loss -0.8772 
2023-10-26 15:55:29.708841: val_loss -0.748 
2023-10-26 15:55:29.709097: Pseudo dice [0.84, 0.9141, 0.966, 0.0752, 0.8023] 
2023-10-26 15:55:29.709339: Epoch time: 4.17 s 
2023-10-26 15:55:31.031979:  
2023-10-26 15:55:31.032287: Epoch 360 
2023-10-26 15:55:31.032545: Current learning rate: 0.00669 
2023-10-26 15:55:35.254944: train_loss -0.8825 
2023-10-26 15:55:35.255331: val_loss -0.796 
2023-10-26 15:55:35.255585: Pseudo dice [0.8511, 0.9232, 0.9679, 0.5179, 0.8193] 
2023-10-26 15:55:35.255826: Epoch time: 4.22 s 
2023-10-26 15:55:36.377637:  
2023-10-26 15:55:36.377923: Epoch 361 
2023-10-26 15:55:36.378169: Current learning rate: 0.00668 
2023-10-26 15:55:40.709606: train_loss -0.8821 
2023-10-26 15:55:40.710004: val_loss -0.7893 
2023-10-26 15:55:40.710413: Pseudo dice [0.8492, 0.9224, 0.9686, 0.428, 0.8565] 
2023-10-26 15:55:40.710892: Epoch time: 4.33 s 
2023-10-26 15:55:41.820779:  
2023-10-26 15:55:41.821064: Epoch 362 
2023-10-26 15:55:41.821293: Current learning rate: 0.00667 
2023-10-26 15:55:46.099905: train_loss -0.8851 
2023-10-26 15:55:46.100309: val_loss -0.7975 
2023-10-26 15:55:46.100570: Pseudo dice [0.845, 0.9233, 0.9667, 0.4748, 0.852] 
2023-10-26 15:55:46.100812: Epoch time: 4.28 s 
2023-10-26 15:55:47.209272:  
2023-10-26 15:55:47.209558: Epoch 363 
2023-10-26 15:55:47.209788: Current learning rate: 0.00666 
2023-10-26 15:55:51.529113: train_loss -0.8873 
2023-10-26 15:55:51.529468: val_loss -0.7869 
2023-10-26 15:55:51.529723: Pseudo dice [0.844, 0.9202, 0.9682, 0.4985, 0.7721] 
2023-10-26 15:55:51.530110: Epoch time: 4.32 s 
2023-10-26 15:55:52.661506:  
2023-10-26 15:55:52.661795: Epoch 364 
2023-10-26 15:55:52.662042: Current learning rate: 0.00665 
2023-10-26 15:55:57.043325: train_loss -0.8782 
2023-10-26 15:55:57.043665: val_loss -0.8006 
2023-10-26 15:55:57.043923: Pseudo dice [0.8581, 0.9252, 0.9689, 0.2803, 0.9035] 
2023-10-26 15:55:57.044141: Epoch time: 4.38 s 
2023-10-26 15:55:58.148313:  
2023-10-26 15:55:58.148610: Epoch 365 
2023-10-26 15:55:58.148849: Current learning rate: 0.00665 
2023-10-26 15:56:02.433607: train_loss -0.8779 
2023-10-26 15:56:02.434009: val_loss -0.804 
2023-10-26 15:56:02.434283: Pseudo dice [0.853, 0.9205, 0.9663, 0.5493, 0.8389] 
2023-10-26 15:56:02.434516: Epoch time: 4.29 s 
2023-10-26 15:56:03.729397:  
2023-10-26 15:56:03.729698: Epoch 366 
2023-10-26 15:56:03.729961: Current learning rate: 0.00664 
2023-10-26 15:56:08.006553: train_loss -0.8875 
2023-10-26 15:56:08.006919: val_loss -0.7524 
2023-10-26 15:56:08.007175: Pseudo dice [0.844, 0.9239, 0.9667, 0.3263, 0.7092] 
2023-10-26 15:56:08.007402: Epoch time: 4.28 s 
2023-10-26 15:56:09.134550:  
2023-10-26 15:56:09.134849: Epoch 367 
2023-10-26 15:56:09.135106: Current learning rate: 0.00663 
2023-10-26 15:56:13.437066: train_loss -0.8859 
2023-10-26 15:56:13.437421: val_loss -0.7911 
2023-10-26 15:56:13.437694: Pseudo dice [0.8488, 0.9235, 0.9659, 0.4872, 0.8246] 
2023-10-26 15:56:13.437927: Epoch time: 4.3 s 
2023-10-26 15:56:14.635548:  
2023-10-26 15:56:14.635885: Epoch 368 
2023-10-26 15:56:14.636181: Current learning rate: 0.00662 
2023-10-26 15:56:18.661761: train_loss -0.8858 
2023-10-26 15:56:18.662164: val_loss -0.7891 
2023-10-26 15:56:18.662433: Pseudo dice [0.8372, 0.9266, 0.9706, 0.593, 0.8343] 
2023-10-26 15:56:18.662672: Epoch time: 4.03 s 
2023-10-26 15:56:19.795537:  
2023-10-26 15:56:19.795841: Epoch 369 
2023-10-26 15:56:19.796084: Current learning rate: 0.00661 
2023-10-26 15:56:23.968569: train_loss -0.8814 
2023-10-26 15:56:23.969270: val_loss -0.7974 
2023-10-26 15:56:23.969556: Pseudo dice [0.8512, 0.9144, 0.9651, 0.4965, 0.8811] 
2023-10-26 15:56:23.969800: Epoch time: 4.17 s 
2023-10-26 15:56:25.115350:  
2023-10-26 15:56:25.115664: Epoch 370 
2023-10-26 15:56:25.115922: Current learning rate: 0.0066 
2023-10-26 15:56:29.458321: train_loss -0.8735 
2023-10-26 15:56:29.458711: val_loss -0.7902 
2023-10-26 15:56:29.458960: Pseudo dice [0.8447, 0.9211, 0.9642, 0.4564, 0.8162] 
2023-10-26 15:56:29.459209: Epoch time: 4.34 s 
2023-10-26 15:56:30.619160:  
2023-10-26 15:56:30.619467: Epoch 371 
2023-10-26 15:56:30.619717: Current learning rate: 0.00659 
2023-10-26 15:56:34.905754: train_loss -0.8837 
2023-10-26 15:56:34.906171: val_loss -0.7852 
2023-10-26 15:56:34.906430: Pseudo dice [0.8238, 0.9216, 0.9667, 0.5896, 0.8508] 
2023-10-26 15:56:34.906676: Epoch time: 4.29 s 
2023-10-26 15:56:36.260719:  
2023-10-26 15:56:36.261045: Epoch 372 
2023-10-26 15:56:36.261320: Current learning rate: 0.00658 
2023-10-26 15:56:40.523905: train_loss -0.886 
2023-10-26 15:56:40.524288: val_loss -0.7517 
2023-10-26 15:56:40.524557: Pseudo dice [0.8349, 0.9211, 0.9682, 0.1734, 0.7647] 
2023-10-26 15:56:40.524812: Epoch time: 4.26 s 
2023-10-26 15:56:41.721416:  
2023-10-26 15:56:41.721720: Epoch 373 
2023-10-26 15:56:41.721964: Current learning rate: 0.00657 
2023-10-26 15:56:45.959201: train_loss -0.889 
2023-10-26 15:56:45.959578: val_loss -0.7741 
2023-10-26 15:56:45.959826: Pseudo dice [0.8403, 0.9243, 0.9685, 0.3986, 0.8211] 
2023-10-26 15:56:45.960077: Epoch time: 4.24 s 
2023-10-26 15:56:47.117308:  
2023-10-26 15:56:47.117622: Epoch 374 
2023-10-26 15:56:47.117885: Current learning rate: 0.00656 
2023-10-26 15:56:51.356655: train_loss -0.8885 
2023-10-26 15:56:51.357078: val_loss -0.8049 
2023-10-26 15:56:51.357341: Pseudo dice [0.8486, 0.9266, 0.9679, 0.5687, 0.8634] 
2023-10-26 15:56:51.357578: Epoch time: 4.24 s 
2023-10-26 15:56:52.601408:  
2023-10-26 15:56:52.601729: Epoch 375 
2023-10-26 15:56:52.601968: Current learning rate: 0.00655 
2023-10-26 15:56:56.769917: train_loss -0.8844 
2023-10-26 15:56:56.770300: val_loss -0.7821 
2023-10-26 15:56:56.770562: Pseudo dice [0.8382, 0.9236, 0.9674, 0.4065, 0.8283] 
2023-10-26 15:56:56.770800: Epoch time: 4.17 s 
2023-10-26 15:56:57.941797:  
2023-10-26 15:56:57.942101: Epoch 376 
2023-10-26 15:56:57.942358: Current learning rate: 0.00654 
2023-10-26 15:57:02.155608: train_loss -0.8924 
2023-10-26 15:57:02.156011: val_loss -0.7838 
2023-10-26 15:57:02.156266: Pseudo dice [0.8379, 0.9205, 0.9663, 0.4094, 0.8453] 
2023-10-26 15:57:02.156533: Epoch time: 4.21 s 
2023-10-26 15:57:03.295149:  
2023-10-26 15:57:03.295433: Epoch 377 
2023-10-26 15:57:03.295677: Current learning rate: 0.00653 
2023-10-26 15:57:07.453167: train_loss -0.8854 
2023-10-26 15:57:07.453529: val_loss -0.7587 
2023-10-26 15:57:07.453786: Pseudo dice [0.8377, 0.9247, 0.969, 0.2928, 0.7229] 
2023-10-26 15:57:07.454013: Epoch time: 4.16 s 
2023-10-26 15:57:08.778682:  
2023-10-26 15:57:08.778980: Epoch 378 
2023-10-26 15:57:08.779227: Current learning rate: 0.00652 
2023-10-26 15:57:13.157418: train_loss -0.8824 
2023-10-26 15:57:13.157824: val_loss -0.7761 
2023-10-26 15:57:13.158152: Pseudo dice [0.8439, 0.9278, 0.9666, 0.3705, 0.9164] 
2023-10-26 15:57:13.158473: Epoch time: 4.38 s 
2023-10-26 15:57:14.291389:  
2023-10-26 15:57:14.291685: Epoch 379 
2023-10-26 15:57:14.291929: Current learning rate: 0.00651 
2023-10-26 15:57:18.456974: train_loss -0.8816 
2023-10-26 15:57:18.457323: val_loss -0.7843 
2023-10-26 15:57:18.457575: Pseudo dice [0.8524, 0.9262, 0.9675, 0.6561, 0.8448] 
2023-10-26 15:57:18.457791: Epoch time: 4.17 s 
2023-10-26 15:57:19.587387:  
2023-10-26 15:57:19.587677: Epoch 380 
2023-10-26 15:57:19.587917: Current learning rate: 0.0065 
2023-10-26 15:57:23.966975: train_loss -0.885 
2023-10-26 15:57:23.967343: val_loss -0.791 
2023-10-26 15:57:23.967593: Pseudo dice [0.837, 0.9178, 0.967, 0.4193, 0.8454] 
2023-10-26 15:57:23.967830: Epoch time: 4.38 s 
2023-10-26 15:57:25.087351:  
2023-10-26 15:57:25.087645: Epoch 381 
2023-10-26 15:57:25.087895: Current learning rate: 0.00649 
2023-10-26 15:57:29.390711: train_loss -0.8869 
2023-10-26 15:57:29.391111: val_loss -0.7999 
2023-10-26 15:57:29.391372: Pseudo dice [0.8411, 0.9276, 0.9629, 0.4441, 0.8973] 
2023-10-26 15:57:29.391625: Epoch time: 4.3 s 
2023-10-26 15:57:30.514856:  
2023-10-26 15:57:30.515192: Epoch 382 
2023-10-26 15:57:30.515450: Current learning rate: 0.00648 
2023-10-26 15:57:34.928330: train_loss -0.8844 
2023-10-26 15:57:34.928669: val_loss -0.776 
2023-10-26 15:57:34.928940: Pseudo dice [0.8447, 0.9244, 0.9684, 0.309, 0.8614] 
2023-10-26 15:57:34.929170: Epoch time: 4.41 s 
2023-10-26 15:57:36.067545:  
2023-10-26 15:57:36.067848: Epoch 383 
2023-10-26 15:57:36.068115: Current learning rate: 0.00648 
2023-10-26 15:57:40.419702: train_loss -0.883 
2023-10-26 15:57:40.420107: val_loss -0.8015 
2023-10-26 15:57:40.420378: Pseudo dice [0.8358, 0.924, 0.9674, 0.6875, 0.7961] 
2023-10-26 15:57:40.420620: Epoch time: 4.35 s 
2023-10-26 15:57:41.736443:  
2023-10-26 15:57:41.736777: Epoch 384 
2023-10-26 15:57:41.737062: Current learning rate: 0.00647 
2023-10-26 15:57:46.033125: train_loss -0.8843 
2023-10-26 15:57:46.033451: val_loss -0.8051 
2023-10-26 15:57:46.033690: Pseudo dice [0.8445, 0.9267, 0.966, 0.586, 0.8601] 
2023-10-26 15:57:46.033908: Epoch time: 4.3 s 
2023-10-26 15:57:47.233141:  
2023-10-26 15:57:47.233443: Epoch 385 
2023-10-26 15:57:47.233678: Current learning rate: 0.00646 
2023-10-26 15:57:51.477049: train_loss -0.8781 
2023-10-26 15:57:51.477479: val_loss -0.7727 
2023-10-26 15:57:51.477760: Pseudo dice [0.8368, 0.9193, 0.9666, 0.3902, 0.7595] 
2023-10-26 15:57:51.478012: Epoch time: 4.24 s 
2023-10-26 15:57:52.621885:  
2023-10-26 15:57:52.622223: Epoch 386 
2023-10-26 15:57:52.622466: Current learning rate: 0.00645 
2023-10-26 15:57:56.662321: train_loss -0.8746 
2023-10-26 15:57:56.662707: val_loss -0.7966 
2023-10-26 15:57:56.662997: Pseudo dice [0.8303, 0.9238, 0.9692, 0.4494, 0.9149] 
2023-10-26 15:57:56.663239: Epoch time: 4.04 s 
2023-10-26 15:57:57.888027:  
2023-10-26 15:57:57.888375: Epoch 387 
2023-10-26 15:57:57.888647: Current learning rate: 0.00644 
2023-10-26 15:58:02.095912: train_loss -0.884 
2023-10-26 15:58:02.096501: val_loss -0.7314 
2023-10-26 15:58:02.096789: Pseudo dice [0.835, 0.9203, 0.9645, 0.6202, 0.7365] 
2023-10-26 15:58:02.097033: Epoch time: 4.21 s 
2023-10-26 15:58:03.232719:  
2023-10-26 15:58:03.233042: Epoch 388 
2023-10-26 15:58:03.233287: Current learning rate: 0.00643 
2023-10-26 15:58:07.358272: train_loss -0.873 
2023-10-26 15:58:07.358670: val_loss -0.826 
2023-10-26 15:58:07.358970: Pseudo dice [0.8416, 0.9214, 0.967, 0.711, 0.9144] 
2023-10-26 15:58:07.359221: Epoch time: 4.13 s 
2023-10-26 15:58:08.533023:  
2023-10-26 15:58:08.533395: Epoch 389 
2023-10-26 15:58:08.533657: Current learning rate: 0.00642 
2023-10-26 15:58:12.716647: train_loss -0.8742 
2023-10-26 15:58:12.717014: val_loss -0.7988 
2023-10-26 15:58:12.717270: Pseudo dice [0.8509, 0.922, 0.9622, 0.4849, 0.9183] 
2023-10-26 15:58:12.717501: Epoch time: 4.18 s 
2023-10-26 15:58:14.050454:  
2023-10-26 15:58:14.050752: Epoch 390 
2023-10-26 15:58:14.051003: Current learning rate: 0.00641 
2023-10-26 15:58:18.227339: train_loss -0.8738 
2023-10-26 15:58:18.227752: val_loss -0.7915 
2023-10-26 15:58:18.228023: Pseudo dice [0.8381, 0.9225, 0.9654, 0.4307, 0.91] 
2023-10-26 15:58:18.228274: Epoch time: 4.18 s 
2023-10-26 15:58:19.365079:  
2023-10-26 15:58:19.365375: Epoch 391 
2023-10-26 15:58:19.365628: Current learning rate: 0.0064 
2023-10-26 15:58:23.601147: train_loss -0.8753 
2023-10-26 15:58:23.601509: val_loss -0.8156 
2023-10-26 15:58:23.601770: Pseudo dice [0.8418, 0.9288, 0.9679, 0.6239, 0.8678] 
2023-10-26 15:58:23.602006: Epoch time: 4.24 s 
2023-10-26 15:58:24.755564:  
2023-10-26 15:58:24.755853: Epoch 392 
2023-10-26 15:58:24.756095: Current learning rate: 0.00639 
2023-10-26 15:58:28.864981: train_loss -0.877 
2023-10-26 15:58:28.865393: val_loss -0.8229 
2023-10-26 15:58:28.865659: Pseudo dice [0.8252, 0.92, 0.9656, 0.7563, 0.8841] 
2023-10-26 15:58:28.865904: Epoch time: 4.11 s 
2023-10-26 15:58:30.010269:  
2023-10-26 15:58:30.010589: Epoch 393 
2023-10-26 15:58:30.010829: Current learning rate: 0.00638 
2023-10-26 15:58:34.321783: train_loss -0.886 
2023-10-26 15:58:34.322200: val_loss -0.7807 
2023-10-26 15:58:34.322461: Pseudo dice [0.8523, 0.9224, 0.9677, 0.2181, 0.8307] 
2023-10-26 15:58:34.322681: Epoch time: 4.31 s 
2023-10-26 15:58:35.464516:  
2023-10-26 15:58:35.464884: Epoch 394 
2023-10-26 15:58:35.465195: Current learning rate: 0.00637 
2023-10-26 15:58:39.602271: train_loss -0.8807 
2023-10-26 15:58:39.602768: val_loss -0.7544 
2023-10-26 15:58:39.603072: Pseudo dice [0.8298, 0.92, 0.9658, 0.0, 0.9254] 
2023-10-26 15:58:39.603421: Epoch time: 4.14 s 
2023-10-26 15:58:40.756720:  
2023-10-26 15:58:40.757044: Epoch 395 
2023-10-26 15:58:40.757303: Current learning rate: 0.00636 
2023-10-26 15:58:45.108006: train_loss -0.8712 
2023-10-26 15:58:45.108396: val_loss -0.8063 
2023-10-26 15:58:45.108683: Pseudo dice [0.8463, 0.9284, 0.9652, 0.5872, 0.9297] 
2023-10-26 15:58:45.108937: Epoch time: 4.35 s 
2023-10-26 15:58:46.426668:  
2023-10-26 15:58:46.426964: Epoch 396 
2023-10-26 15:58:46.427212: Current learning rate: 0.00635 
2023-10-26 15:58:50.732975: train_loss -0.8782 
2023-10-26 15:58:50.733373: val_loss -0.7783 
2023-10-26 15:58:50.733616: Pseudo dice [0.8284, 0.9219, 0.9651, 0.4193, 0.8896] 
2023-10-26 15:58:50.733849: Epoch time: 4.31 s 
2023-10-26 15:58:51.860919:  
2023-10-26 15:58:51.861235: Epoch 397 
2023-10-26 15:58:51.861481: Current learning rate: 0.00634 
2023-10-26 15:58:56.279212: train_loss -0.8737 
2023-10-26 15:58:56.279548: val_loss -0.7583 
2023-10-26 15:58:56.279795: Pseudo dice [0.8384, 0.9215, 0.9597, 0.3517, 0.9278] 
2023-10-26 15:58:56.280022: Epoch time: 4.42 s 
2023-10-26 15:58:57.412480:  
2023-10-26 15:58:57.412776: Epoch 398 
2023-10-26 15:58:57.413038: Current learning rate: 0.00633 
2023-10-26 15:59:01.669310: train_loss -0.8773 
2023-10-26 15:59:01.669695: val_loss -0.7241 
2023-10-26 15:59:01.669960: Pseudo dice [0.8445, 0.924, 0.9635, 0.0159, 0.781] 
2023-10-26 15:59:01.670186: Epoch time: 4.26 s 
2023-10-26 15:59:02.799367:  
2023-10-26 15:59:02.799719: Epoch 399 
2023-10-26 15:59:02.800037: Current learning rate: 0.00632 
2023-10-26 15:59:07.089658: train_loss -0.871 
2023-10-26 15:59:07.090014: val_loss -0.8039 
2023-10-26 15:59:07.090264: Pseudo dice [0.8449, 0.9306, 0.9682, 0.67, 0.8439] 
2023-10-26 15:59:07.090493: Epoch time: 4.29 s 
2023-10-26 15:59:08.337168:  
2023-10-26 15:59:08.337481: Epoch 400 
2023-10-26 15:59:08.337767: Current learning rate: 0.00631 
2023-10-26 15:59:12.590885: train_loss -0.8854 
2023-10-26 15:59:12.591320: val_loss -0.734 
2023-10-26 15:59:12.591675: Pseudo dice [0.8278, 0.9243, 0.9643, 0.0903, 0.7282] 
2023-10-26 15:59:12.591993: Epoch time: 4.25 s 
2023-10-26 15:59:13.765652:  
2023-10-26 15:59:13.766016: Epoch 401 
2023-10-26 15:59:13.766269: Current learning rate: 0.0063 
2023-10-26 15:59:17.941091: train_loss -0.8804 
2023-10-26 15:59:17.941439: val_loss -0.7838 
2023-10-26 15:59:17.941706: Pseudo dice [0.8324, 0.9212, 0.9642, 0.4311, 0.8909] 
2023-10-26 15:59:17.941941: Epoch time: 4.18 s 
2023-10-26 15:59:19.373646:  
2023-10-26 15:59:19.373965: Epoch 402 
2023-10-26 15:59:19.374221: Current learning rate: 0.0063 
2023-10-26 15:59:23.656250: train_loss -0.8839 
2023-10-26 15:59:23.656616: val_loss -0.7698 
2023-10-26 15:59:23.656857: Pseudo dice [0.8434, 0.921, 0.9673, 0.4888, 0.746] 
2023-10-26 15:59:23.657093: Epoch time: 4.28 s 
2023-10-26 15:59:24.804143:  
2023-10-26 15:59:24.804443: Epoch 403 
2023-10-26 15:59:24.804686: Current learning rate: 0.00629 
2023-10-26 15:59:29.085737: train_loss -0.882 
2023-10-26 15:59:29.086163: val_loss -0.7351 
2023-10-26 15:59:29.086467: Pseudo dice [0.8228, 0.918, 0.9677, 0.0577, 0.9198] 
2023-10-26 15:59:29.086767: Epoch time: 4.28 s 
2023-10-26 15:59:30.267467:  
2023-10-26 15:59:30.267761: Epoch 404 
2023-10-26 15:59:30.268039: Current learning rate: 0.00628 
2023-10-26 15:59:34.383775: train_loss -0.8829 
2023-10-26 15:59:34.384189: val_loss -0.8014 
2023-10-26 15:59:34.384629: Pseudo dice [0.8571, 0.9286, 0.9664, 0.4807, 0.9217] 
2023-10-26 15:59:34.385012: Epoch time: 4.12 s 
2023-10-26 15:59:35.528378:  
2023-10-26 15:59:35.528686: Epoch 405 
2023-10-26 15:59:35.528935: Current learning rate: 0.00627 
2023-10-26 15:59:39.665272: train_loss -0.8831 
2023-10-26 15:59:39.665629: val_loss -0.7633 
2023-10-26 15:59:39.665888: Pseudo dice [0.8219, 0.9135, 0.9641, 0.4673, 0.8052] 
2023-10-26 15:59:39.666115: Epoch time: 4.14 s 
2023-10-26 15:59:40.833771:  
2023-10-26 15:59:40.834110: Epoch 406 
2023-10-26 15:59:40.834358: Current learning rate: 0.00626 
2023-10-26 15:59:45.044438: train_loss -0.8802 
2023-10-26 15:59:45.044913: val_loss -0.7782 
2023-10-26 15:59:45.045229: Pseudo dice [0.8216, 0.9217, 0.9662, 0.5904, 0.8403] 
2023-10-26 15:59:45.045495: Epoch time: 4.21 s 
2023-10-26 15:59:46.210164:  
2023-10-26 15:59:46.210465: Epoch 407 
2023-10-26 15:59:46.210801: Current learning rate: 0.00625 
2023-10-26 15:59:50.464257: train_loss -0.8847 
2023-10-26 15:59:50.464664: val_loss -0.7147 
2023-10-26 15:59:50.464935: Pseudo dice [0.8478, 0.9298, 0.9674, 0.6684, 0.699] 
2023-10-26 15:59:50.465173: Epoch time: 4.26 s 
2023-10-26 15:59:51.821264:  
2023-10-26 15:59:51.821559: Epoch 408 
2023-10-26 15:59:51.821802: Current learning rate: 0.00624 
2023-10-26 15:59:56.049877: train_loss -0.8771 
2023-10-26 15:59:56.050265: val_loss -0.7996 
2023-10-26 15:59:56.050515: Pseudo dice [0.8503, 0.93, 0.9673, 0.5663, 0.8797] 
2023-10-26 15:59:56.050733: Epoch time: 4.23 s 
2023-10-26 15:59:57.251030:  
2023-10-26 15:59:57.251319: Epoch 409 
2023-10-26 15:59:57.251550: Current learning rate: 0.00623 
2023-10-26 16:00:01.500378: train_loss -0.8855 
2023-10-26 16:00:01.500761: val_loss -0.7939 
2023-10-26 16:00:01.501024: Pseudo dice [0.8473, 0.929, 0.9659, 0.4085, 0.8806] 
2023-10-26 16:00:01.501259: Epoch time: 4.25 s 
2023-10-26 16:00:02.660023:  
2023-10-26 16:00:02.660300: Epoch 410 
2023-10-26 16:00:02.660533: Current learning rate: 0.00622 
2023-10-26 16:00:06.967816: train_loss -0.886 
2023-10-26 16:00:06.968193: val_loss -0.7805 
2023-10-26 16:00:06.968446: Pseudo dice [0.8532, 0.9223, 0.9678, 0.5044, 0.8037] 
2023-10-26 16:00:06.968668: Epoch time: 4.31 s 
2023-10-26 16:00:08.056100:  
2023-10-26 16:00:08.056412: Epoch 411 
2023-10-26 16:00:08.056660: Current learning rate: 0.00621 
2023-10-26 16:00:12.297159: train_loss -0.8781 
2023-10-26 16:00:12.297534: val_loss -0.7779 
2023-10-26 16:00:12.297792: Pseudo dice [0.8343, 0.9206, 0.9656, 0.3401, 0.8593] 
2023-10-26 16:00:12.298037: Epoch time: 4.24 s 
2023-10-26 16:00:13.385382:  
2023-10-26 16:00:13.385670: Epoch 412 
2023-10-26 16:00:13.385913: Current learning rate: 0.0062 
2023-10-26 16:00:17.550759: train_loss -0.8774 
2023-10-26 16:00:17.551157: val_loss -0.8087 
2023-10-26 16:00:17.551415: Pseudo dice [0.8478, 0.9249, 0.9646, 0.5781, 0.8523] 
2023-10-26 16:00:17.551638: Epoch time: 4.17 s 
2023-10-26 16:00:18.677078:  
2023-10-26 16:00:18.677390: Epoch 413 
2023-10-26 16:00:18.677646: Current learning rate: 0.00619 
2023-10-26 16:00:22.876772: train_loss -0.8859 
2023-10-26 16:00:22.877155: val_loss -0.8057 
2023-10-26 16:00:22.877427: Pseudo dice [0.8584, 0.9311, 0.9664, 0.4287, 0.903] 
2023-10-26 16:00:22.877666: Epoch time: 4.2 s 
2023-10-26 16:00:24.155922:  
2023-10-26 16:00:24.156225: Epoch 414 
2023-10-26 16:00:24.156463: Current learning rate: 0.00618 
2023-10-26 16:00:28.295515: train_loss -0.8803 
2023-10-26 16:00:28.295965: val_loss -0.7817 
2023-10-26 16:00:28.296331: Pseudo dice [0.8568, 0.9294, 0.9666, 0.4842, 0.7435] 
2023-10-26 16:00:28.296657: Epoch time: 4.14 s 
2023-10-26 16:00:29.418732:  
2023-10-26 16:00:29.419053: Epoch 415 
2023-10-26 16:00:29.419295: Current learning rate: 0.00617 
2023-10-26 16:00:33.493903: train_loss -0.8789 
2023-10-26 16:00:33.494346: val_loss -0.7235 
2023-10-26 16:00:33.494625: Pseudo dice [0.8392, 0.9184, 0.9668, 0.1165, 0.7071] 
2023-10-26 16:00:33.494880: Epoch time: 4.08 s 
2023-10-26 16:00:34.609900:  
2023-10-26 16:00:34.610190: Epoch 416 
2023-10-26 16:00:34.610432: Current learning rate: 0.00616 
2023-10-26 16:00:38.867584: train_loss -0.8864 
2023-10-26 16:00:38.868012: val_loss -0.7602 
2023-10-26 16:00:38.868274: Pseudo dice [0.8493, 0.9197, 0.9675, 0.2353, 0.8834] 
2023-10-26 16:00:38.868514: Epoch time: 4.26 s 
2023-10-26 16:00:39.969810:  
2023-10-26 16:00:39.970125: Epoch 417 
2023-10-26 16:00:39.970364: Current learning rate: 0.00615 
2023-10-26 16:00:44.235514: train_loss -0.8645 
2023-10-26 16:00:44.235931: val_loss -0.8062 
2023-10-26 16:00:44.236203: Pseudo dice [0.8458, 0.9143, 0.9677, 0.5844, 0.9352] 
2023-10-26 16:00:44.236449: Epoch time: 4.27 s 
2023-10-26 16:00:45.342572:  
2023-10-26 16:00:45.342888: Epoch 418 
2023-10-26 16:00:45.343142: Current learning rate: 0.00614 
2023-10-26 16:00:49.568350: train_loss -0.865 
2023-10-26 16:00:49.568717: val_loss -0.7921 
2023-10-26 16:00:49.568970: Pseudo dice [0.8575, 0.9238, 0.9693, 0.403, 0.922] 
2023-10-26 16:00:49.569299: Epoch time: 4.23 s 
2023-10-26 16:00:50.761168:  
2023-10-26 16:00:50.761485: Epoch 419 
2023-10-26 16:00:50.761740: Current learning rate: 0.00613 
2023-10-26 16:00:54.774725: train_loss -0.8671 
2023-10-26 16:00:54.775123: val_loss -0.7747 
2023-10-26 16:00:54.775372: Pseudo dice [0.8339, 0.9147, 0.9665, 0.4637, 0.9101] 
2023-10-26 16:00:54.775614: Epoch time: 4.01 s 
2023-10-26 16:00:55.884802:  
2023-10-26 16:00:55.885103: Epoch 420 
2023-10-26 16:00:55.885334: Current learning rate: 0.00612 
2023-10-26 16:01:00.112626: train_loss -0.8695 
2023-10-26 16:01:00.112995: val_loss -0.774 
2023-10-26 16:01:00.113253: Pseudo dice [0.8372, 0.9249, 0.9665, 0.1695, 0.9294] 
2023-10-26 16:01:00.113504: Epoch time: 4.23 s 
2023-10-26 16:01:01.475419:  
2023-10-26 16:01:01.475737: Epoch 421 
2023-10-26 16:01:01.476004: Current learning rate: 0.00612 
2023-10-26 16:01:05.617136: train_loss -0.8796 
2023-10-26 16:01:05.617541: val_loss -0.7862 
2023-10-26 16:01:05.617807: Pseudo dice [0.8478, 0.9245, 0.9673, 0.2419, 0.89] 
2023-10-26 16:01:05.618059: Epoch time: 4.14 s 
2023-10-26 16:01:06.750949:  
2023-10-26 16:01:06.751242: Epoch 422 
2023-10-26 16:01:06.751491: Current learning rate: 0.00611 
2023-10-26 16:01:10.915721: train_loss -0.8795 
2023-10-26 16:01:10.916211: val_loss -0.7292 
2023-10-26 16:01:10.916592: Pseudo dice [0.8485, 0.9254, 0.9659, 0.0218, 0.7705] 
2023-10-26 16:01:10.916884: Epoch time: 4.17 s 
2023-10-26 16:01:12.073697:  
2023-10-26 16:01:12.074017: Epoch 423 
2023-10-26 16:01:12.074273: Current learning rate: 0.0061 
2023-10-26 16:01:16.234066: train_loss -0.8809 
2023-10-26 16:01:16.234460: val_loss -0.7796 
2023-10-26 16:01:16.234719: Pseudo dice [0.8334, 0.9241, 0.9641, 0.5512, 0.7572] 
2023-10-26 16:01:16.234974: Epoch time: 4.16 s 
2023-10-26 16:01:17.355886:  
2023-10-26 16:01:17.356183: Epoch 424 
2023-10-26 16:01:17.356432: Current learning rate: 0.00609 
2023-10-26 16:01:21.576527: train_loss -0.8906 
2023-10-26 16:01:21.576962: val_loss -0.8071 
2023-10-26 16:01:21.577273: Pseudo dice [0.849, 0.9263, 0.9668, 0.5378, 0.8179] 
2023-10-26 16:01:21.577573: Epoch time: 4.22 s 
2023-10-26 16:01:22.715852:  
2023-10-26 16:01:22.716155: Epoch 425 
2023-10-26 16:01:22.716396: Current learning rate: 0.00608 
2023-10-26 16:01:27.003647: train_loss -0.8894 
2023-10-26 16:01:27.004059: val_loss -0.8058 
2023-10-26 16:01:27.004322: Pseudo dice [0.8457, 0.9272, 0.9691, 0.6436, 0.8024] 
2023-10-26 16:01:27.004557: Epoch time: 4.29 s 
2023-10-26 16:01:28.130795:  
2023-10-26 16:01:28.131091: Epoch 426 
2023-10-26 16:01:28.131335: Current learning rate: 0.00607 
2023-10-26 16:01:32.446806: train_loss -0.8825 
2023-10-26 16:01:32.447137: val_loss -0.768 
2023-10-26 16:01:32.447382: Pseudo dice [0.8391, 0.9242, 0.9622, 0.6392, 0.7478] 
2023-10-26 16:01:32.447601: Epoch time: 4.32 s 
2023-10-26 16:01:33.708992:  
2023-10-26 16:01:33.709301: Epoch 427 
2023-10-26 16:01:33.709548: Current learning rate: 0.00606 
2023-10-26 16:01:38.032535: train_loss -0.8816 
2023-10-26 16:01:38.032923: val_loss -0.817 
2023-10-26 16:01:38.033172: Pseudo dice [0.8504, 0.9281, 0.9626, 0.7143, 0.8259] 
2023-10-26 16:01:38.033402: Epoch time: 4.32 s 
2023-10-26 16:01:39.124473:  
2023-10-26 16:01:39.124789: Epoch 428 
2023-10-26 16:01:39.125068: Current learning rate: 0.00605 
2023-10-26 16:01:43.436738: train_loss -0.885 
2023-10-26 16:01:43.437150: val_loss -0.7785 
2023-10-26 16:01:43.437423: Pseudo dice [0.8486, 0.9274, 0.9652, 0.5289, 0.7124] 
2023-10-26 16:01:43.437668: Epoch time: 4.31 s 
2023-10-26 16:01:44.531869:  
2023-10-26 16:01:44.532171: Epoch 429 
2023-10-26 16:01:44.532405: Current learning rate: 0.00604 
2023-10-26 16:01:48.959924: train_loss -0.8792 
2023-10-26 16:01:48.960320: val_loss -0.7935 
2023-10-26 16:01:48.960635: Pseudo dice [0.8425, 0.9263, 0.9669, 0.6437, 0.7522] 
2023-10-26 16:01:48.960937: Epoch time: 4.43 s 
2023-10-26 16:01:50.057567:  
2023-10-26 16:01:50.057884: Epoch 430 
2023-10-26 16:01:50.058120: Current learning rate: 0.00603 
2023-10-26 16:01:54.384603: train_loss -0.8847 
2023-10-26 16:01:54.385023: val_loss -0.8122 
2023-10-26 16:01:54.385295: Pseudo dice [0.8486, 0.9278, 0.9631, 0.612, 0.8378] 
2023-10-26 16:01:54.385545: Epoch time: 4.33 s 
2023-10-26 16:01:55.499422:  
2023-10-26 16:01:55.499720: Epoch 431 
2023-10-26 16:01:55.499948: Current learning rate: 0.00602 
2023-10-26 16:01:59.686246: train_loss -0.8884 
2023-10-26 16:01:59.686628: val_loss -0.7679 
2023-10-26 16:01:59.686886: Pseudo dice [0.8465, 0.9215, 0.9666, 0.5739, 0.691] 
2023-10-26 16:01:59.687124: Epoch time: 4.19 s 
2023-10-26 16:02:00.798194:  
2023-10-26 16:02:00.798497: Epoch 432 
2023-10-26 16:02:00.798739: Current learning rate: 0.00601 
2023-10-26 16:02:04.923614: train_loss -0.8914 
2023-10-26 16:02:04.923991: val_loss -0.805 
2023-10-26 16:02:04.924250: Pseudo dice [0.8486, 0.9263, 0.9661, 0.6127, 0.868] 
2023-10-26 16:02:04.924484: Epoch time: 4.13 s 
2023-10-26 16:02:06.060661:  
2023-10-26 16:02:06.061106: Epoch 433 
2023-10-26 16:02:06.061430: Current learning rate: 0.006 
2023-10-26 16:02:10.303606: train_loss -0.8873 
2023-10-26 16:02:10.304121: val_loss -0.708 
2023-10-26 16:02:10.304395: Pseudo dice [0.8326, 0.921, 0.9664, 0.3226, 0.7383] 
2023-10-26 16:02:10.304647: Epoch time: 4.24 s 
2023-10-26 16:02:11.638893:  
2023-10-26 16:02:11.639208: Epoch 434 
2023-10-26 16:02:11.639467: Current learning rate: 0.00599 
2023-10-26 16:02:15.831917: train_loss -0.8776 
2023-10-26 16:02:15.832494: val_loss -0.7741 
2023-10-26 16:02:15.832864: Pseudo dice [0.8317, 0.9239, 0.9675, 0.3529, 0.8272] 
2023-10-26 16:02:15.833169: Epoch time: 4.19 s 
2023-10-26 16:02:16.942075:  
2023-10-26 16:02:16.942372: Epoch 435 
2023-10-26 16:02:16.942615: Current learning rate: 0.00598 
2023-10-26 16:02:21.157688: train_loss -0.879 
2023-10-26 16:02:21.158106: val_loss -0.7894 
2023-10-26 16:02:21.158369: Pseudo dice [0.8421, 0.9241, 0.9652, 0.3697, 0.8168] 
2023-10-26 16:02:21.158602: Epoch time: 4.22 s 
2023-10-26 16:02:22.267721:  
2023-10-26 16:02:22.268030: Epoch 436 
2023-10-26 16:02:22.268264: Current learning rate: 0.00597 
2023-10-26 16:02:26.395294: train_loss -0.8826 
2023-10-26 16:02:26.395721: val_loss -0.7952 
2023-10-26 16:02:26.395999: Pseudo dice [0.8234, 0.9199, 0.9658, 0.3889, 0.9307] 
2023-10-26 16:02:26.396255: Epoch time: 4.13 s 
2023-10-26 16:02:27.491264:  
2023-10-26 16:02:27.491547: Epoch 437 
2023-10-26 16:02:27.491781: Current learning rate: 0.00596 
2023-10-26 16:02:31.698805: train_loss -0.8654 
2023-10-26 16:02:31.699171: val_loss -0.7916 
2023-10-26 16:02:31.699424: Pseudo dice [0.8474, 0.926, 0.9677, 0.4325, 0.9327] 
2023-10-26 16:02:31.699651: Epoch time: 4.21 s 
2023-10-26 16:02:32.807118:  
2023-10-26 16:02:32.807402: Epoch 438 
2023-10-26 16:02:32.807633: Current learning rate: 0.00595 
2023-10-26 16:02:36.916440: train_loss -0.8647 
2023-10-26 16:02:36.916804: val_loss -0.8161 
2023-10-26 16:02:36.917072: Pseudo dice [0.8518, 0.9204, 0.9662, 0.5287, 0.927] 
2023-10-26 16:02:36.917348: Epoch time: 4.11 s 
2023-10-26 16:02:38.058206:  
2023-10-26 16:02:38.058506: Epoch 439 
2023-10-26 16:02:38.058733: Current learning rate: 0.00594 
2023-10-26 16:02:42.426987: train_loss -0.8747 
2023-10-26 16:02:42.427388: val_loss -0.818 
2023-10-26 16:02:42.427648: Pseudo dice [0.8494, 0.925, 0.9658, 0.6939, 0.86] 
2023-10-26 16:02:42.427882: Epoch time: 4.37 s 
2023-10-26 16:02:43.522953:  
2023-10-26 16:02:43.523253: Epoch 440 
2023-10-26 16:02:43.523515: Current learning rate: 0.00593 
2023-10-26 16:02:47.804551: train_loss -0.8732 
2023-10-26 16:02:47.805070: val_loss -0.7908 
2023-10-26 16:02:47.805449: Pseudo dice [0.8379, 0.9203, 0.9672, 0.4373, 0.8701] 
2023-10-26 16:02:47.805801: Epoch time: 4.28 s 
2023-10-26 16:02:49.159272:  
2023-10-26 16:02:49.159629: Epoch 441 
2023-10-26 16:02:49.159959: Current learning rate: 0.00592 
2023-10-26 16:02:53.499395: train_loss -0.8781 
2023-10-26 16:02:53.499739: val_loss -0.801 
2023-10-26 16:02:53.500000: Pseudo dice [0.833, 0.9203, 0.9651, 0.6511, 0.8309] 
2023-10-26 16:02:53.500227: Epoch time: 4.34 s 
2023-10-26 16:02:54.581048:  
2023-10-26 16:02:54.581346: Epoch 442 
2023-10-26 16:02:54.581593: Current learning rate: 0.00592 
2023-10-26 16:02:58.909015: train_loss -0.8831 
2023-10-26 16:02:58.909358: val_loss -0.7746 
2023-10-26 16:02:58.909614: Pseudo dice [0.8491, 0.9233, 0.966, 0.4037, 0.761] 
2023-10-26 16:02:58.909853: Epoch time: 4.33 s 
2023-10-26 16:03:00.007627:  
2023-10-26 16:03:00.008010: Epoch 443 
2023-10-26 16:03:00.008339: Current learning rate: 0.00591 
2023-10-26 16:03:04.268147: train_loss -0.8883 
2023-10-26 16:03:04.268532: val_loss -0.799 
2023-10-26 16:03:04.268877: Pseudo dice [0.8357, 0.9225, 0.968, 0.5442, 0.8311] 
2023-10-26 16:03:04.269205: Epoch time: 4.26 s 
2023-10-26 16:03:05.412205:  
2023-10-26 16:03:05.412504: Epoch 444 
2023-10-26 16:03:05.412745: Current learning rate: 0.0059 
2023-10-26 16:03:09.637760: train_loss -0.888 
2023-10-26 16:03:09.638129: val_loss -0.8015 
2023-10-26 16:03:09.638390: Pseudo dice [0.8377, 0.9248, 0.9664, 0.5627, 0.8709] 
2023-10-26 16:03:09.638615: Epoch time: 4.23 s 
2023-10-26 16:03:10.756896:  
2023-10-26 16:03:10.757265: Epoch 445 
2023-10-26 16:03:10.757596: Current learning rate: 0.00589 
2023-10-26 16:03:14.979057: train_loss -0.8824 
2023-10-26 16:03:14.979462: val_loss -0.7949 
2023-10-26 16:03:14.979774: Pseudo dice [0.8466, 0.9196, 0.9655, 0.6839, 0.7194] 
2023-10-26 16:03:14.980034: Epoch time: 4.22 s 
2023-10-26 16:03:16.105246:  
2023-10-26 16:03:16.105554: Epoch 446 
2023-10-26 16:03:16.105800: Current learning rate: 0.00588 
2023-10-26 16:03:20.312474: train_loss -0.8894 
2023-10-26 16:03:20.312892: val_loss -0.7993 
2023-10-26 16:03:20.313152: Pseudo dice [0.8404, 0.92, 0.9681, 0.6397, 0.7942] 
2023-10-26 16:03:20.313386: Epoch time: 4.21 s 
2023-10-26 16:03:21.655217:  
2023-10-26 16:03:21.655527: Epoch 447 
2023-10-26 16:03:21.655777: Current learning rate: 0.00587 
2023-10-26 16:03:25.807891: train_loss -0.8894 
2023-10-26 16:03:25.808281: val_loss -0.7415 
2023-10-26 16:03:25.808550: Pseudo dice [0.8296, 0.9148, 0.9682, 0.0412, 0.8336] 
2023-10-26 16:03:25.808784: Epoch time: 4.15 s 
2023-10-26 16:03:26.904255:  
2023-10-26 16:03:26.904583: Epoch 448 
2023-10-26 16:03:26.904845: Current learning rate: 0.00586 
2023-10-26 16:03:31.060351: train_loss -0.8728 
2023-10-26 16:03:31.060744: val_loss -0.7543 
2023-10-26 16:03:31.061005: Pseudo dice [0.834, 0.9212, 0.9668, 0.3369, 0.7421] 
2023-10-26 16:03:31.061240: Epoch time: 4.16 s 
2023-10-26 16:03:32.187060:  
2023-10-26 16:03:32.187388: Epoch 449 
2023-10-26 16:03:32.187702: Current learning rate: 0.00585 
2023-10-26 16:03:36.210508: train_loss -0.8769 
2023-10-26 16:03:36.210897: val_loss -0.7794 
2023-10-26 16:03:36.211158: Pseudo dice [0.8429, 0.9192, 0.9672, 0.5424, 0.7967] 
2023-10-26 16:03:36.211397: Epoch time: 4.02 s 
2023-10-26 16:03:37.401651:  
2023-10-26 16:03:37.401953: Epoch 450 
2023-10-26 16:03:37.402191: Current learning rate: 0.00584 
2023-10-26 16:03:41.383269: train_loss -0.8869 
2023-10-26 16:03:41.383693: val_loss -0.7686 
2023-10-26 16:03:41.384065: Pseudo dice [0.8408, 0.9262, 0.9632, 0.4247, 0.8154] 
2023-10-26 16:03:41.384530: Epoch time: 3.98 s 
2023-10-26 16:03:42.519171:  
2023-10-26 16:03:42.519544: Epoch 451 
2023-10-26 16:03:42.519856: Current learning rate: 0.00583 
2023-10-26 16:03:46.642841: train_loss -0.8814 
2023-10-26 16:03:46.643235: val_loss -0.7774 
2023-10-26 16:03:46.643495: Pseudo dice [0.8463, 0.9221, 0.9658, 0.4733, 0.6694] 
2023-10-26 16:03:46.643724: Epoch time: 4.12 s 
2023-10-26 16:03:47.733855:  
2023-10-26 16:03:47.734167: Epoch 452 
2023-10-26 16:03:47.734514: Current learning rate: 0.00582 
2023-10-26 16:03:51.835181: train_loss -0.8866 
2023-10-26 16:03:51.835571: val_loss -0.7639 
2023-10-26 16:03:51.835830: Pseudo dice [0.828, 0.921, 0.9646, 0.3259, 0.7746] 
2023-10-26 16:03:51.836110: Epoch time: 4.1 s 
2023-10-26 16:03:52.930038:  
2023-10-26 16:03:52.930388: Epoch 453 
2023-10-26 16:03:52.930721: Current learning rate: 0.00581 
2023-10-26 16:03:57.137710: train_loss -0.8846 
2023-10-26 16:03:57.138120: val_loss -0.7736 
2023-10-26 16:03:57.138515: Pseudo dice [0.8333, 0.9218, 0.9678, 0.4728, 0.8049] 
2023-10-26 16:03:57.138821: Epoch time: 4.21 s 
2023-10-26 16:03:58.453172:  
2023-10-26 16:03:58.453474: Epoch 454 
2023-10-26 16:03:58.453743: Current learning rate: 0.0058 
2023-10-26 16:04:02.614000: train_loss -0.8848 
2023-10-26 16:04:02.614480: val_loss -0.7816 
2023-10-26 16:04:02.614819: Pseudo dice [0.8328, 0.9178, 0.9628, 0.5363, 0.7591] 
2023-10-26 16:04:02.615105: Epoch time: 4.16 s 
2023-10-26 16:04:03.726977:  
2023-10-26 16:04:03.727292: Epoch 455 
2023-10-26 16:04:03.727540: Current learning rate: 0.00579 
2023-10-26 16:04:08.041033: train_loss -0.889 
2023-10-26 16:04:08.041446: val_loss -0.8063 
2023-10-26 16:04:08.041704: Pseudo dice [0.8427, 0.9227, 0.9669, 0.5371, 0.8718] 
2023-10-26 16:04:08.042028: Epoch time: 4.31 s 
2023-10-26 16:04:09.184948:  
2023-10-26 16:04:09.185272: Epoch 456 
2023-10-26 16:04:09.185509: Current learning rate: 0.00578 
2023-10-26 16:04:13.432895: train_loss -0.8952 
2023-10-26 16:04:13.433305: val_loss -0.7628 
2023-10-26 16:04:13.433568: Pseudo dice [0.8226, 0.9229, 0.9668, 0.3156, 0.8939] 
2023-10-26 16:04:13.433805: Epoch time: 4.25 s 
2023-10-26 16:04:14.571868:  
2023-10-26 16:04:14.572170: Epoch 457 
2023-10-26 16:04:14.572409: Current learning rate: 0.00577 
2023-10-26 16:04:18.758384: train_loss -0.8898 
2023-10-26 16:04:18.758727: val_loss -0.7946 
2023-10-26 16:04:18.758987: Pseudo dice [0.8267, 0.9227, 0.9659, 0.5915, 0.8581] 
2023-10-26 16:04:18.759208: Epoch time: 4.19 s 
2023-10-26 16:04:19.846539:  
2023-10-26 16:04:19.846878: Epoch 458 
2023-10-26 16:04:19.847183: Current learning rate: 0.00576 
2023-10-26 16:04:24.056228: train_loss -0.8906 
2023-10-26 16:04:24.056684: val_loss -0.7663 
2023-10-26 16:04:24.057233: Pseudo dice [0.8292, 0.9238, 0.9667, 0.3365, 0.7981] 
2023-10-26 16:04:24.057554: Epoch time: 4.21 s 
2023-10-26 16:04:25.162395:  
2023-10-26 16:04:25.162689: Epoch 459 
2023-10-26 16:04:25.162916: Current learning rate: 0.00575 
2023-10-26 16:04:29.301500: train_loss -0.8888 
2023-10-26 16:04:29.301837: val_loss -0.7607 
2023-10-26 16:04:29.302076: Pseudo dice [0.8309, 0.9242, 0.9647, 0.1754, 0.8539] 
2023-10-26 16:04:29.302297: Epoch time: 4.14 s 
2023-10-26 16:04:30.389346:  
2023-10-26 16:04:30.389653: Epoch 460 
2023-10-26 16:04:30.389898: Current learning rate: 0.00574 
2023-10-26 16:04:34.751434: train_loss -0.8756 
2023-10-26 16:04:34.751844: val_loss -0.813 
2023-10-26 16:04:34.752118: Pseudo dice [0.845, 0.9225, 0.9675, 0.71, 0.8166] 
2023-10-26 16:04:34.752378: Epoch time: 4.36 s 
2023-10-26 16:04:36.022821:  
2023-10-26 16:04:36.023203: Epoch 461 
2023-10-26 16:04:36.023521: Current learning rate: 0.00573 
2023-10-26 16:04:40.436817: train_loss -0.8822 
2023-10-26 16:04:40.437190: val_loss -0.7739 
2023-10-26 16:04:40.437446: Pseudo dice [0.8419, 0.9216, 0.9661, 0.3147, 0.7978] 
2023-10-26 16:04:40.437672: Epoch time: 4.41 s 
2023-10-26 16:04:41.542922:  
2023-10-26 16:04:41.543231: Epoch 462 
2023-10-26 16:04:41.543476: Current learning rate: 0.00572 
2023-10-26 16:04:45.843673: train_loss -0.8785 
2023-10-26 16:04:45.844074: val_loss -0.7689 
2023-10-26 16:04:45.844327: Pseudo dice [0.8282, 0.9214, 0.9672, 0.2558, 0.8715] 
2023-10-26 16:04:45.844558: Epoch time: 4.3 s 
2023-10-26 16:04:47.005513:  
2023-10-26 16:04:47.005875: Epoch 463 
2023-10-26 16:04:47.006182: Current learning rate: 0.00571 
2023-10-26 16:04:51.257334: train_loss -0.8714 
2023-10-26 16:04:51.257702: val_loss -0.7932 
2023-10-26 16:04:51.257960: Pseudo dice [0.8436, 0.9178, 0.9652, 0.4785, 0.8837] 
2023-10-26 16:04:51.258196: Epoch time: 4.25 s 
2023-10-26 16:04:52.358676:  
2023-10-26 16:04:52.358991: Epoch 464 
2023-10-26 16:04:52.359248: Current learning rate: 0.0057 
2023-10-26 16:04:56.515973: train_loss -0.8748 
2023-10-26 16:04:56.516360: val_loss -0.7681 
2023-10-26 16:04:56.516624: Pseudo dice [0.8411, 0.9244, 0.9656, 0.2325, 0.9013] 
2023-10-26 16:04:56.516842: Epoch time: 4.16 s 
2023-10-26 16:04:57.687774:  
2023-10-26 16:04:57.688104: Epoch 465 
2023-10-26 16:04:57.688378: Current learning rate: 0.0057 
2023-10-26 16:05:02.022587: train_loss -0.8757 
2023-10-26 16:05:02.022994: val_loss -0.7563 
2023-10-26 16:05:02.023258: Pseudo dice [0.845, 0.9278, 0.967, 0.3193, 0.7322] 
2023-10-26 16:05:02.023506: Epoch time: 4.34 s 
2023-10-26 16:05:03.131963:  
2023-10-26 16:05:03.132273: Epoch 466 
2023-10-26 16:05:03.132520: Current learning rate: 0.00569 
2023-10-26 16:05:07.159818: train_loss -0.8763 
2023-10-26 16:05:07.160232: val_loss -0.756 
2023-10-26 16:05:07.160497: Pseudo dice [0.8313, 0.9209, 0.9678, 0.439, 0.7325] 
2023-10-26 16:05:07.160733: Epoch time: 4.03 s 
2023-10-26 16:05:08.267504:  
2023-10-26 16:05:08.267794: Epoch 467 
2023-10-26 16:05:08.268242: Current learning rate: 0.00568 
2023-10-26 16:05:12.240503: train_loss -0.8652 
2023-10-26 16:05:12.240898: val_loss -0.7624 
2023-10-26 16:05:12.241149: Pseudo dice [0.8494, 0.9249, 0.966, 0.2791, 0.741] 
2023-10-26 16:05:12.241384: Epoch time: 3.97 s 
2023-10-26 16:05:13.586202:  
2023-10-26 16:05:13.586556: Epoch 468 
2023-10-26 16:05:13.586802: Current learning rate: 0.00567 
2023-10-26 16:05:17.676327: train_loss -0.875 
2023-10-26 16:05:17.676769: val_loss -0.8096 
2023-10-26 16:05:17.677046: Pseudo dice [0.832, 0.9251, 0.9668, 0.6712, 0.8496] 
2023-10-26 16:05:17.677296: Epoch time: 4.09 s 
2023-10-26 16:05:18.768146:  
2023-10-26 16:05:18.768436: Epoch 469 
2023-10-26 16:05:18.768676: Current learning rate: 0.00566 
2023-10-26 16:05:22.966142: train_loss -0.887 
2023-10-26 16:05:22.966491: val_loss -0.7695 
2023-10-26 16:05:22.966746: Pseudo dice [0.821, 0.922, 0.9677, 0.3023, 0.8784] 
2023-10-26 16:05:22.966991: Epoch time: 4.2 s 
2023-10-26 16:05:24.060979:  
2023-10-26 16:05:24.061284: Epoch 470 
2023-10-26 16:05:24.061524: Current learning rate: 0.00565 
2023-10-26 16:05:28.281975: train_loss -0.8827 
2023-10-26 16:05:28.282416: val_loss -0.7892 
2023-10-26 16:05:28.282805: Pseudo dice [0.8414, 0.9235, 0.9663, 0.5431, 0.7712] 
2023-10-26 16:05:28.283102: Epoch time: 4.22 s 
2023-10-26 16:05:29.387310:  
2023-10-26 16:05:29.387646: Epoch 471 
2023-10-26 16:05:29.387898: Current learning rate: 0.00564 
2023-10-26 16:05:33.799187: train_loss -0.8789 
2023-10-26 16:05:33.799588: val_loss -0.7792 
2023-10-26 16:05:33.799948: Pseudo dice [0.8294, 0.9251, 0.9665, 0.3496, 0.8534] 
2023-10-26 16:05:33.800387: Epoch time: 4.41 s 
2023-10-26 16:05:34.945754:  
2023-10-26 16:05:34.946071: Epoch 472 
2023-10-26 16:05:34.946315: Current learning rate: 0.00563 
2023-10-26 16:05:39.294001: train_loss -0.8861 
2023-10-26 16:05:39.294475: val_loss -0.8171 
2023-10-26 16:05:39.294754: Pseudo dice [0.8461, 0.9267, 0.9671, 0.4996, 0.9295] 
2023-10-26 16:05:39.295014: Epoch time: 4.35 s 
2023-10-26 16:05:40.475661:  
2023-10-26 16:05:40.475967: Epoch 473 
2023-10-26 16:05:40.476219: Current learning rate: 0.00562 
2023-10-26 16:05:44.682085: train_loss -0.8843 
2023-10-26 16:05:44.682475: val_loss -0.7509 
2023-10-26 16:05:44.682729: Pseudo dice [0.8343, 0.9269, 0.9657, 0.3386, 0.6874] 
2023-10-26 16:05:44.682968: Epoch time: 4.21 s 
2023-10-26 16:05:45.988889:  
2023-10-26 16:05:45.989193: Epoch 474 
2023-10-26 16:05:45.989455: Current learning rate: 0.00561 
2023-10-26 16:05:50.198978: train_loss -0.8914 
2023-10-26 16:05:50.199359: val_loss -0.7988 
2023-10-26 16:05:50.199622: Pseudo dice [0.8372, 0.9262, 0.9659, 0.4867, 0.8903] 
2023-10-26 16:05:50.199861: Epoch time: 4.21 s 
2023-10-26 16:05:51.380361:  
2023-10-26 16:05:51.380711: Epoch 475 
2023-10-26 16:05:51.381021: Current learning rate: 0.0056 
2023-10-26 16:05:55.721692: train_loss -0.8883 
2023-10-26 16:05:55.722081: val_loss -0.7861 
2023-10-26 16:05:55.722337: Pseudo dice [0.8455, 0.927, 0.9641, 0.4358, 0.8001] 
2023-10-26 16:05:55.722577: Epoch time: 4.34 s 
2023-10-26 16:05:56.799821:  
2023-10-26 16:05:56.800172: Epoch 476 
2023-10-26 16:05:56.800444: Current learning rate: 0.00559 
2023-10-26 16:06:01.115667: train_loss -0.893 
2023-10-26 16:06:01.116047: val_loss -0.78 
2023-10-26 16:06:01.116308: Pseudo dice [0.8402, 0.928, 0.9663, 0.4854, 0.7735] 
2023-10-26 16:06:01.116562: Epoch time: 4.32 s 
2023-10-26 16:06:02.247634:  
2023-10-26 16:06:02.247962: Epoch 477 
2023-10-26 16:06:02.248228: Current learning rate: 0.00558 
2023-10-26 16:06:06.473407: train_loss -0.8751 
2023-10-26 16:06:06.473773: val_loss -0.7176 
2023-10-26 16:06:06.474028: Pseudo dice [0.8239, 0.918, 0.9675, 0.0422, 0.7742] 
2023-10-26 16:06:06.474297: Epoch time: 4.23 s 
2023-10-26 16:06:07.615595:  
2023-10-26 16:06:07.615900: Epoch 478 
2023-10-26 16:06:07.616167: Current learning rate: 0.00557 
2023-10-26 16:06:11.755829: train_loss -0.8812 
2023-10-26 16:06:11.756313: val_loss -0.767 
2023-10-26 16:06:11.756657: Pseudo dice [0.8504, 0.9283, 0.9664, 0.3919, 0.7293] 
2023-10-26 16:06:11.756903: Epoch time: 4.14 s 
2023-10-26 16:06:12.863789:  
2023-10-26 16:06:12.864094: Epoch 479 
2023-10-26 16:06:12.864354: Current learning rate: 0.00556 
2023-10-26 16:06:16.980253: train_loss -0.8834 
2023-10-26 16:06:16.980601: val_loss -0.8026 
2023-10-26 16:06:16.980857: Pseudo dice [0.845, 0.9293, 0.9659, 0.6224, 0.8046] 
2023-10-26 16:06:16.981090: Epoch time: 4.12 s 
2023-10-26 16:06:18.111312:  
2023-10-26 16:06:18.111604: Epoch 480 
2023-10-26 16:06:18.111842: Current learning rate: 0.00555 
2023-10-26 16:06:22.377493: train_loss -0.8856 
2023-10-26 16:06:22.377912: val_loss -0.81 
2023-10-26 16:06:22.378190: Pseudo dice [0.839, 0.9269, 0.968, 0.6667, 0.8306] 
2023-10-26 16:06:22.378437: Epoch time: 4.27 s 
2023-10-26 16:06:23.718275:  
2023-10-26 16:06:23.718623: Epoch 481 
2023-10-26 16:06:23.718925: Current learning rate: 0.00554 
2023-10-26 16:06:27.858251: train_loss -0.8866 
2023-10-26 16:06:27.858624: val_loss -0.8067 
2023-10-26 16:06:27.858890: Pseudo dice [0.839, 0.9271, 0.9669, 0.6829, 0.8597] 
2023-10-26 16:06:27.859161: Epoch time: 4.14 s 
2023-10-26 16:06:28.983587:  
2023-10-26 16:06:28.983895: Epoch 482 
2023-10-26 16:06:28.984145: Current learning rate: 0.00553 
2023-10-26 16:06:33.111028: train_loss -0.8955 
2023-10-26 16:06:33.111666: val_loss -0.7759 
2023-10-26 16:06:33.111953: Pseudo dice [0.851, 0.9259, 0.9681, 0.298, 0.8] 
2023-10-26 16:06:33.112196: Epoch time: 4.13 s 
2023-10-26 16:06:34.240416:  
2023-10-26 16:06:34.240747: Epoch 483 
2023-10-26 16:06:34.241178: Current learning rate: 0.00552 
2023-10-26 16:06:38.450975: train_loss -0.8821 
2023-10-26 16:06:38.451396: val_loss -0.8135 
2023-10-26 16:06:38.451869: Pseudo dice [0.8385, 0.9228, 0.9648, 0.6251, 0.8783] 
2023-10-26 16:06:38.452179: Epoch time: 4.21 s 
2023-10-26 16:06:39.627521:  
2023-10-26 16:06:39.627827: Epoch 484 
2023-10-26 16:06:39.628071: Current learning rate: 0.00551 
2023-10-26 16:06:43.870635: train_loss -0.8888 
2023-10-26 16:06:43.871154: val_loss -0.7593 
2023-10-26 16:06:43.871421: Pseudo dice [0.8207, 0.9268, 0.9652, 0.3607, 0.8476] 
2023-10-26 16:06:43.871664: Epoch time: 4.24 s 
2023-10-26 16:06:44.993271:  
2023-10-26 16:06:44.993608: Epoch 485 
2023-10-26 16:06:44.993853: Current learning rate: 0.0055 
2023-10-26 16:06:49.100653: train_loss -0.8859 
2023-10-26 16:06:49.101056: val_loss -0.7552 
2023-10-26 16:06:49.101307: Pseudo dice [0.8231, 0.919, 0.9649, 0.3631, 0.8286] 
2023-10-26 16:06:49.101547: Epoch time: 4.11 s 
2023-10-26 16:06:50.266994:  
2023-10-26 16:06:50.267302: Epoch 486 
2023-10-26 16:06:50.267549: Current learning rate: 0.00549 
2023-10-26 16:06:54.446368: train_loss -0.8849 
2023-10-26 16:06:54.446736: val_loss -0.7418 
2023-10-26 16:06:54.446998: Pseudo dice [0.8343, 0.923, 0.9671, 0.3942, 0.7923] 
2023-10-26 16:06:54.447235: Epoch time: 4.18 s 
2023-10-26 16:06:55.555813:  
2023-10-26 16:06:55.556109: Epoch 487 
2023-10-26 16:06:55.556347: Current learning rate: 0.00548 
2023-10-26 16:06:59.830034: train_loss -0.8896 
2023-10-26 16:06:59.830476: val_loss -0.7977 
2023-10-26 16:06:59.831106: Pseudo dice [0.8363, 0.9243, 0.9664, 0.5886, 0.8735] 
2023-10-26 16:06:59.831453: Epoch time: 4.27 s 
2023-10-26 16:07:01.174629:  
2023-10-26 16:07:01.174923: Epoch 488 
2023-10-26 16:07:01.175184: Current learning rate: 0.00547 
2023-10-26 16:07:05.605346: train_loss -0.8892 
2023-10-26 16:07:05.605760: val_loss -0.7568 
2023-10-26 16:07:05.606030: Pseudo dice [0.8468, 0.9306, 0.9661, 0.5164, 0.8039] 
2023-10-26 16:07:05.606261: Epoch time: 4.43 s 
2023-10-26 16:07:06.717279:  
2023-10-26 16:07:06.717627: Epoch 489 
2023-10-26 16:07:06.717925: Current learning rate: 0.00546 
2023-10-26 16:07:11.100993: train_loss -0.8869 
2023-10-26 16:07:11.101390: val_loss -0.7657 
2023-10-26 16:07:11.101653: Pseudo dice [0.8276, 0.9228, 0.964, 0.4266, 0.8065] 
2023-10-26 16:07:11.101903: Epoch time: 4.38 s 
2023-10-26 16:07:12.213668:  
2023-10-26 16:07:12.213984: Epoch 490 
2023-10-26 16:07:12.214237: Current learning rate: 0.00546 
2023-10-26 16:07:16.538558: train_loss -0.8939 
2023-10-26 16:07:16.539051: val_loss -0.7515 
2023-10-26 16:07:16.539632: Pseudo dice [0.8304, 0.923, 0.9655, 0.2848, 0.8031] 
2023-10-26 16:07:16.540071: Epoch time: 4.33 s 
2023-10-26 16:07:17.684274:  
2023-10-26 16:07:17.684595: Epoch 491 
2023-10-26 16:07:17.684865: Current learning rate: 0.00545 
2023-10-26 16:07:21.905811: train_loss -0.8861 
2023-10-26 16:07:21.906197: val_loss -0.8258 
2023-10-26 16:07:21.906455: Pseudo dice [0.8423, 0.929, 0.9682, 0.6085, 0.9245] 
2023-10-26 16:07:21.906693: Epoch time: 4.22 s 
2023-10-26 16:07:23.015590:  
2023-10-26 16:07:23.015944: Epoch 492 
2023-10-26 16:07:23.016213: Current learning rate: 0.00544 
2023-10-26 16:07:27.214490: train_loss -0.8882 
2023-10-26 16:07:27.214907: val_loss -0.7785 
2023-10-26 16:07:27.215176: Pseudo dice [0.8325, 0.9205, 0.9641, 0.5326, 0.7394] 
2023-10-26 16:07:27.215440: Epoch time: 4.2 s 
2023-10-26 16:07:28.361888:  
2023-10-26 16:07:28.362199: Epoch 493 
2023-10-26 16:07:28.362455: Current learning rate: 0.00543 
2023-10-26 16:07:32.585648: train_loss -0.8915 
2023-10-26 16:07:32.586088: val_loss -0.7521 
2023-10-26 16:07:32.586379: Pseudo dice [0.8325, 0.9236, 0.9649, 0.5169, 0.7536] 
2023-10-26 16:07:32.586638: Epoch time: 4.22 s 
2023-10-26 16:07:33.993052:  
2023-10-26 16:07:33.993356: Epoch 494 
2023-10-26 16:07:33.993621: Current learning rate: 0.00542 
2023-10-26 16:07:38.197461: train_loss -0.8925 
2023-10-26 16:07:38.197842: val_loss -0.7276 
2023-10-26 16:07:38.198137: Pseudo dice [0.8372, 0.9265, 0.964, 0.3846, 0.6865] 
2023-10-26 16:07:38.198375: Epoch time: 4.21 s 
2023-10-26 16:07:39.323835:  
2023-10-26 16:07:39.324159: Epoch 495 
2023-10-26 16:07:39.324405: Current learning rate: 0.00541 
2023-10-26 16:07:43.572110: train_loss -0.8831 
2023-10-26 16:07:43.572505: val_loss -0.7352 
2023-10-26 16:07:43.572795: Pseudo dice [0.835, 0.925, 0.9652, 0.3229, 0.8205] 
2023-10-26 16:07:43.573053: Epoch time: 4.25 s 
2023-10-26 16:07:44.708554:  
2023-10-26 16:07:44.708853: Epoch 496 
2023-10-26 16:07:44.709103: Current learning rate: 0.0054 
2023-10-26 16:07:48.940422: train_loss -0.8868 
2023-10-26 16:07:48.940775: val_loss -0.7074 
2023-10-26 16:07:48.941057: Pseudo dice [0.8261, 0.9198, 0.964, 0.3563, 0.768] 
2023-10-26 16:07:48.941299: Epoch time: 4.23 s 
2023-10-26 16:07:50.060922:  
2023-10-26 16:07:50.061234: Epoch 497 
2023-10-26 16:07:50.061500: Current learning rate: 0.00539 
2023-10-26 16:07:54.248517: train_loss -0.8895 
2023-10-26 16:07:54.248922: val_loss -0.7469 
2023-10-26 16:07:54.249193: Pseudo dice [0.8382, 0.9269, 0.9669, 0.4876, 0.7349] 
2023-10-26 16:07:54.249438: Epoch time: 4.19 s 
2023-10-26 16:07:55.425702:  
2023-10-26 16:07:55.426002: Epoch 498 
2023-10-26 16:07:55.426241: Current learning rate: 0.00538 
2023-10-26 16:07:59.570064: train_loss -0.8901 
2023-10-26 16:07:59.570410: val_loss -0.6861 
2023-10-26 16:07:59.570656: Pseudo dice [0.8348, 0.9247, 0.9663, 0.5218, 0.7191] 
2023-10-26 16:07:59.570880: Epoch time: 4.14 s 
2023-10-26 16:08:00.692746:  
2023-10-26 16:08:00.693464: Epoch 499 
2023-10-26 16:08:00.693712: Current learning rate: 0.00537 
2023-10-26 16:08:04.978672: train_loss -0.8825 
2023-10-26 16:08:04.979094: val_loss -0.7803 
2023-10-26 16:08:04.979357: Pseudo dice [0.8443, 0.9214, 0.966, 0.5358, 0.7635] 
2023-10-26 16:08:04.979588: Epoch time: 4.29 s 
2023-10-26 16:08:06.281092:  
2023-10-26 16:08:06.281388: Epoch 500 
2023-10-26 16:08:06.281635: Current learning rate: 0.00536 
2023-10-26 16:08:10.440217: train_loss -0.8948 
2023-10-26 16:08:10.440648: val_loss -0.7656 
2023-10-26 16:08:10.440917: Pseudo dice [0.8406, 0.9288, 0.9659, 0.5541, 0.8004] 
2023-10-26 16:08:10.441160: Epoch time: 4.16 s 
2023-10-26 16:08:11.751626:  
2023-10-26 16:08:11.751948: Epoch 501 
2023-10-26 16:08:11.752186: Current learning rate: 0.00535 
2023-10-26 16:08:15.941093: train_loss -0.8926 
2023-10-26 16:08:15.941514: val_loss -0.776 
2023-10-26 16:08:15.941796: Pseudo dice [0.8395, 0.928, 0.9655, 0.2522, 0.928] 
2023-10-26 16:08:15.942073: Epoch time: 4.19 s 
2023-10-26 16:08:17.064631:  
2023-10-26 16:08:17.064924: Epoch 502 
2023-10-26 16:08:17.065168: Current learning rate: 0.00534 
2023-10-26 16:08:21.287723: train_loss -0.8848 
2023-10-26 16:08:21.288122: val_loss -0.7753 
2023-10-26 16:08:21.288375: Pseudo dice [0.8334, 0.9222, 0.9681, 0.2145, 0.923] 
2023-10-26 16:08:21.288612: Epoch time: 4.22 s 
2023-10-26 16:08:22.396022:  
2023-10-26 16:08:22.396312: Epoch 503 
2023-10-26 16:08:22.396546: Current learning rate: 0.00533 
2023-10-26 16:08:26.654497: train_loss -0.8792 
2023-10-26 16:08:26.654897: val_loss -0.7939 
2023-10-26 16:08:26.655164: Pseudo dice [0.8567, 0.9236, 0.9675, 0.6023, 0.8489] 
2023-10-26 16:08:26.655414: Epoch time: 4.26 s 
2023-10-26 16:08:27.770252:  
2023-10-26 16:08:27.770563: Epoch 504 
2023-10-26 16:08:27.770813: Current learning rate: 0.00532 
2023-10-26 16:08:32.165087: train_loss -0.8896 
2023-10-26 16:08:32.165426: val_loss -0.7868 
2023-10-26 16:08:32.165690: Pseudo dice [0.8399, 0.9215, 0.9677, 0.6286, 0.8073] 
2023-10-26 16:08:32.165926: Epoch time: 4.4 s 
2023-10-26 16:08:33.307276:  
2023-10-26 16:08:33.307650: Epoch 505 
2023-10-26 16:08:33.308037: Current learning rate: 0.00531 
2023-10-26 16:08:37.602571: train_loss -0.8952 
2023-10-26 16:08:37.602928: val_loss -0.7577 
2023-10-26 16:08:37.603185: Pseudo dice [0.8256, 0.9239, 0.9648, 0.1644, 0.8279] 
2023-10-26 16:08:37.603415: Epoch time: 4.3 s 
2023-10-26 16:08:38.750092:  
2023-10-26 16:08:38.750421: Epoch 506 
2023-10-26 16:08:38.750793: Current learning rate: 0.0053 
2023-10-26 16:08:43.074271: train_loss -0.8795 
2023-10-26 16:08:43.074733: val_loss -0.7224 
2023-10-26 16:08:43.074998: Pseudo dice [0.8264, 0.9213, 0.9627, 0.0, 0.8311] 
2023-10-26 16:08:43.075238: Epoch time: 4.32 s 
2023-10-26 16:08:44.411239:  
2023-10-26 16:08:44.411545: Epoch 507 
2023-10-26 16:08:44.411839: Current learning rate: 0.00529 
2023-10-26 16:08:48.822957: train_loss -0.8841 
2023-10-26 16:08:48.823364: val_loss -0.7622 
2023-10-26 16:08:48.823640: Pseudo dice [0.8248, 0.9267, 0.964, 0.2701, 0.7961] 
2023-10-26 16:08:48.823879: Epoch time: 4.41 s 
2023-10-26 16:08:49.957719:  
2023-10-26 16:08:49.958061: Epoch 508 
2023-10-26 16:08:49.958399: Current learning rate: 0.00528 
2023-10-26 16:08:54.524596: train_loss -0.8887 
2023-10-26 16:08:54.525022: val_loss -0.766 
2023-10-26 16:08:54.525289: Pseudo dice [0.8392, 0.9242, 0.9663, 0.2998, 0.9001] 
2023-10-26 16:08:54.525542: Epoch time: 4.57 s 
2023-10-26 16:08:55.690079:  
2023-10-26 16:08:55.690405: Epoch 509 
2023-10-26 16:08:55.690649: Current learning rate: 0.00527 
2023-10-26 16:08:59.952482: train_loss -0.8892 
2023-10-26 16:08:59.952839: val_loss -0.7252 
2023-10-26 16:08:59.953099: Pseudo dice [0.8192, 0.9266, 0.9661, 0.0, 0.833] 
2023-10-26 16:08:59.953325: Epoch time: 4.26 s 
2023-10-26 16:09:01.077197:  
2023-10-26 16:09:01.077509: Epoch 510 
2023-10-26 16:09:01.077760: Current learning rate: 0.00526 
2023-10-26 16:09:05.178692: train_loss -0.8781 
2023-10-26 16:09:05.179108: val_loss -0.7294 
2023-10-26 16:09:05.179382: Pseudo dice [0.8311, 0.9206, 0.9647, 0.1386, 0.758] 
2023-10-26 16:09:05.179627: Epoch time: 4.1 s 
2023-10-26 16:09:06.340712:  
2023-10-26 16:09:06.341920: Epoch 511 
2023-10-26 16:09:06.342230: Current learning rate: 0.00525 
2023-10-26 16:09:10.603482: train_loss -0.8742 
2023-10-26 16:09:10.603850: val_loss -0.7606 
2023-10-26 16:09:10.604123: Pseudo dice [0.8479, 0.926, 0.9672, 0.1052, 0.9061] 
2023-10-26 16:09:10.604367: Epoch time: 4.26 s 
2023-10-26 16:09:11.775496:  
2023-10-26 16:09:11.775860: Epoch 512 
2023-10-26 16:09:11.776158: Current learning rate: 0.00524 
2023-10-26 16:09:16.010259: train_loss -0.8813 
2023-10-26 16:09:16.011173: val_loss -0.794 
2023-10-26 16:09:16.011455: Pseudo dice [0.8536, 0.9329, 0.9679, 0.6534, 0.7914] 
2023-10-26 16:09:16.011753: Epoch time: 4.24 s 
2023-10-26 16:09:17.244008:  
2023-10-26 16:09:17.244317: Epoch 513 
2023-10-26 16:09:17.244570: Current learning rate: 0.00523 
2023-10-26 16:09:21.441298: train_loss -0.8858 
2023-10-26 16:09:21.441950: val_loss -0.7485 
2023-10-26 16:09:21.442227: Pseudo dice [0.8357, 0.9246, 0.9633, 0.5602, 0.8177] 
2023-10-26 16:09:21.442487: Epoch time: 4.2 s 
2023-10-26 16:09:22.827202:  
2023-10-26 16:09:22.827502: Epoch 514 
2023-10-26 16:09:22.827761: Current learning rate: 0.00522 
2023-10-26 16:09:27.005343: train_loss -0.8844 
2023-10-26 16:09:27.006402: val_loss -0.7791 
2023-10-26 16:09:27.006725: Pseudo dice [0.8571, 0.9273, 0.9681, 0.1167, 0.9083] 
2023-10-26 16:09:27.007035: Epoch time: 4.18 s 
2023-10-26 16:09:28.134226:  
2023-10-26 16:09:28.134553: Epoch 515 
2023-10-26 16:09:28.134827: Current learning rate: 0.00521 
2023-10-26 16:09:32.437373: train_loss -0.8876 
2023-10-26 16:09:32.437797: val_loss -0.7807 
2023-10-26 16:09:32.438087: Pseudo dice [0.8465, 0.9292, 0.9649, 0.3251, 0.8402] 
2023-10-26 16:09:32.438380: Epoch time: 4.3 s 
2023-10-26 16:09:33.625272:  
2023-10-26 16:09:33.625599: Epoch 516 
2023-10-26 16:09:33.625896: Current learning rate: 0.0052 
2023-10-26 16:09:37.821242: train_loss -0.8928 
2023-10-26 16:09:37.822750: val_loss -0.7608 
2023-10-26 16:09:37.823054: Pseudo dice [0.8432, 0.9281, 0.9656, 0.4315, 0.748] 
2023-10-26 16:09:37.823401: Epoch time: 4.2 s 
2023-10-26 16:09:38.988187:  
2023-10-26 16:09:38.988755: Epoch 517 
2023-10-26 16:09:38.989130: Current learning rate: 0.00519 
2023-10-26 16:09:43.283850: train_loss -0.8933 
2023-10-26 16:09:43.284274: val_loss -0.6998 
2023-10-26 16:09:43.284532: Pseudo dice [0.8348, 0.9275, 0.9678, 0.4711, 0.6485] 
2023-10-26 16:09:43.284796: Epoch time: 4.3 s 
2023-10-26 16:09:44.405307:  
2023-10-26 16:09:44.405614: Epoch 518 
2023-10-26 16:09:44.405860: Current learning rate: 0.00518 
2023-10-26 16:09:48.676991: train_loss -0.8905 
2023-10-26 16:09:48.677399: val_loss -0.769 
2023-10-26 16:09:48.677658: Pseudo dice [0.8392, 0.9269, 0.9676, 0.637, 0.8222] 
2023-10-26 16:09:48.677897: Epoch time: 4.27 s 
2023-10-26 16:09:49.808669:  
2023-10-26 16:09:49.808991: Epoch 519 
2023-10-26 16:09:49.809246: Current learning rate: 0.00518 
2023-10-26 16:09:54.020265: train_loss -0.8934 
2023-10-26 16:09:54.020651: val_loss -0.7395 
2023-10-26 16:09:54.020917: Pseudo dice [0.8369, 0.9233, 0.9652, 0.5089, 0.7778] 
2023-10-26 16:09:54.021153: Epoch time: 4.21 s 
2023-10-26 16:09:55.182784:  
2023-10-26 16:09:55.183159: Epoch 520 
2023-10-26 16:09:55.183484: Current learning rate: 0.00517 
2023-10-26 16:09:59.480448: train_loss -0.8938 
2023-10-26 16:09:59.480834: val_loss -0.7254 
2023-10-26 16:09:59.481096: Pseudo dice [0.8508, 0.9219, 0.9625, 0.3777, 0.7205] 
2023-10-26 16:09:59.481334: Epoch time: 4.3 s 
2023-10-26 16:10:00.822215:  
2023-10-26 16:10:00.822514: Epoch 521 
2023-10-26 16:10:00.822760: Current learning rate: 0.00516 
2023-10-26 16:10:05.018209: train_loss -0.8786 
2023-10-26 16:10:05.018609: val_loss -0.779 
2023-10-26 16:10:05.018869: Pseudo dice [0.853, 0.9249, 0.9686, 0.6362, 0.8357] 
2023-10-26 16:10:05.019126: Epoch time: 4.2 s 
2023-10-26 16:10:06.220640:  
2023-10-26 16:10:06.220930: Epoch 522 
2023-10-26 16:10:06.221160: Current learning rate: 0.00515 
2023-10-26 16:10:10.388171: train_loss -0.8892 
2023-10-26 16:10:10.388576: val_loss -0.8126 
2023-10-26 16:10:10.388839: Pseudo dice [0.8602, 0.9285, 0.9661, 0.6473, 0.8155] 
2023-10-26 16:10:10.389102: Epoch time: 4.17 s 
2023-10-26 16:10:11.660431:  
2023-10-26 16:10:11.660727: Epoch 523 
2023-10-26 16:10:11.660971: Current learning rate: 0.00514 
2023-10-26 16:10:15.902298: train_loss -0.8943 
2023-10-26 16:10:15.902770: val_loss -0.7798 
2023-10-26 16:10:15.903185: Pseudo dice [0.8475, 0.926, 0.9657, 0.5571, 0.8238] 
2023-10-26 16:10:15.903527: Epoch time: 4.24 s 
2023-10-26 16:10:17.049779:  
2023-10-26 16:10:17.050068: Epoch 524 
2023-10-26 16:10:17.050304: Current learning rate: 0.00513 
2023-10-26 16:10:21.314766: train_loss -0.8881 
2023-10-26 16:10:21.315273: val_loss -0.6685 
2023-10-26 16:10:21.315598: Pseudo dice [0.835, 0.9238, 0.9641, 0.2031, 0.7406] 
2023-10-26 16:10:21.315902: Epoch time: 4.27 s 
2023-10-26 16:10:22.551246:  
2023-10-26 16:10:22.551557: Epoch 525 
2023-10-26 16:10:22.551817: Current learning rate: 0.00512 
2023-10-26 16:10:26.716591: train_loss -0.8886 
2023-10-26 16:10:26.717008: val_loss -0.813 
2023-10-26 16:10:26.717504: Pseudo dice [0.8443, 0.9205, 0.966, 0.5931, 0.9244] 
2023-10-26 16:10:26.717970: Epoch time: 4.17 s 
2023-10-26 16:10:27.887103:  
2023-10-26 16:10:27.887433: Epoch 526 
2023-10-26 16:10:27.887673: Current learning rate: 0.00511 
2023-10-26 16:10:32.128620: train_loss -0.8875 
2023-10-26 16:10:32.129045: val_loss -0.7177 
2023-10-26 16:10:32.129303: Pseudo dice [0.8294, 0.922, 0.9657, 0.4073, 0.7495] 
2023-10-26 16:10:32.129545: Epoch time: 4.24 s 
2023-10-26 16:10:33.471237:  
2023-10-26 16:10:33.471541: Epoch 527 
2023-10-26 16:10:33.471791: Current learning rate: 0.0051 
2023-10-26 16:10:37.788128: train_loss -0.8942 
2023-10-26 16:10:37.788648: val_loss -0.7857 
2023-10-26 16:10:37.789051: Pseudo dice [0.8477, 0.927, 0.9656, 0.5942, 0.8279] 
2023-10-26 16:10:37.789376: Epoch time: 4.32 s 
2023-10-26 16:10:38.928353:  
2023-10-26 16:10:38.928642: Epoch 528 
2023-10-26 16:10:38.928883: Current learning rate: 0.00509 
2023-10-26 16:10:43.112944: train_loss -0.8929 
2023-10-26 16:10:43.113312: val_loss -0.7336 
2023-10-26 16:10:43.113579: Pseudo dice [0.8264, 0.9201, 0.9673, 0.0218, 0.8592] 
2023-10-26 16:10:43.113855: Epoch time: 4.19 s 
2023-10-26 16:10:44.279898:  
2023-10-26 16:10:44.280187: Epoch 529 
2023-10-26 16:10:44.280451: Current learning rate: 0.00508 
2023-10-26 16:10:48.408745: train_loss -0.8949 
2023-10-26 16:10:48.409135: val_loss -0.7889 
2023-10-26 16:10:48.409395: Pseudo dice [0.8612, 0.9276, 0.9666, 0.2797, 0.9439] 
2023-10-26 16:10:48.409827: Epoch time: 4.13 s 
2023-10-26 16:10:49.534048:  
2023-10-26 16:10:49.534343: Epoch 530 
2023-10-26 16:10:49.534585: Current learning rate: 0.00507 
2023-10-26 16:10:53.842802: train_loss -0.8802 
2023-10-26 16:10:53.843189: val_loss -0.782 
2023-10-26 16:10:53.843468: Pseudo dice [0.856, 0.9261, 0.9688, 0.0894, 0.9426] 
2023-10-26 16:10:53.843708: Epoch time: 4.31 s 
2023-10-26 16:10:54.961006:  
2023-10-26 16:10:54.961294: Epoch 531 
2023-10-26 16:10:54.961522: Current learning rate: 0.00506 
2023-10-26 16:10:59.296815: train_loss -0.8828 
2023-10-26 16:10:59.297192: val_loss -0.7504 
2023-10-26 16:10:59.297446: Pseudo dice [0.821, 0.9202, 0.965, 0.5406, 0.7543] 
2023-10-26 16:10:59.297684: Epoch time: 4.34 s 
2023-10-26 16:11:00.403781:  
2023-10-26 16:11:00.404087: Epoch 532 
2023-10-26 16:11:00.404329: Current learning rate: 0.00505 
2023-10-26 16:11:04.861587: train_loss -0.889 
2023-10-26 16:11:04.862048: val_loss -0.7531 
2023-10-26 16:11:04.862304: Pseudo dice [0.8592, 0.9258, 0.9666, 0.4913, 0.8227] 
2023-10-26 16:11:04.862545: Epoch time: 4.46 s 
2023-10-26 16:11:06.017597:  
2023-10-26 16:11:06.017901: Epoch 533 
2023-10-26 16:11:06.018139: Current learning rate: 0.00504 
2023-10-26 16:11:10.140275: train_loss -0.8905 
2023-10-26 16:11:10.140648: val_loss -0.7529 
2023-10-26 16:11:10.140924: Pseudo dice [0.8265, 0.9193, 0.9657, 0.4433, 0.7754] 
2023-10-26 16:11:10.141156: Epoch time: 4.12 s 
2023-10-26 16:11:11.422239:  
2023-10-26 16:11:11.422584: Epoch 534 
2023-10-26 16:11:11.422854: Current learning rate: 0.00503 
2023-10-26 16:11:15.613954: train_loss -0.8948 
2023-10-26 16:11:15.614336: val_loss -0.7706 
2023-10-26 16:11:15.614606: Pseudo dice [0.8359, 0.9177, 0.9657, 0.5934, 0.8315] 
2023-10-26 16:11:15.614831: Epoch time: 4.19 s 
2023-10-26 16:11:16.766043:  
2023-10-26 16:11:16.766367: Epoch 535 
2023-10-26 16:11:16.766608: Current learning rate: 0.00502 
2023-10-26 16:11:21.032018: train_loss -0.8813 
2023-10-26 16:11:21.032447: val_loss -0.7503 
2023-10-26 16:11:21.032704: Pseudo dice [0.8453, 0.9252, 0.9661, 0.6362, 0.7851] 
2023-10-26 16:11:21.032943: Epoch time: 4.27 s 
2023-10-26 16:11:22.163131:  
2023-10-26 16:11:22.163424: Epoch 536 
2023-10-26 16:11:22.163666: Current learning rate: 0.00501 
2023-10-26 16:11:26.382916: train_loss -0.8853 
2023-10-26 16:11:26.383337: val_loss -0.6894 
2023-10-26 16:11:26.383678: Pseudo dice [0.8406, 0.921, 0.9672, 0.1148, 0.7851] 
2023-10-26 16:11:26.383962: Epoch time: 4.22 s 
2023-10-26 16:11:27.513465:  
2023-10-26 16:11:27.513754: Epoch 537 
2023-10-26 16:11:27.514003: Current learning rate: 0.005 
2023-10-26 16:11:31.679027: train_loss -0.8921 
2023-10-26 16:11:31.679390: val_loss -0.6706 
2023-10-26 16:11:31.679640: Pseudo dice [0.847, 0.9257, 0.9652, 0.6468, 0.6899] 
2023-10-26 16:11:31.679880: Epoch time: 4.17 s 
2023-10-26 16:11:32.834024:  
2023-10-26 16:11:32.834327: Epoch 538 
2023-10-26 16:11:32.834596: Current learning rate: 0.00499 
2023-10-26 16:11:37.134221: train_loss -0.8821 
2023-10-26 16:11:37.134831: val_loss -0.7819 
2023-10-26 16:11:37.135194: Pseudo dice [0.8345, 0.916, 0.9655, 0.4949, 0.8743] 
2023-10-26 16:11:37.135517: Epoch time: 4.3 s 
2023-10-26 16:11:38.301122:  
2023-10-26 16:11:38.301435: Epoch 539 
2023-10-26 16:11:38.301712: Current learning rate: 0.00498 
2023-10-26 16:11:42.623156: train_loss -0.8887 
2023-10-26 16:11:42.623543: val_loss -0.6638 
2023-10-26 16:11:42.623800: Pseudo dice [0.8247, 0.9194, 0.9664, 0.1637, 0.6796] 
2023-10-26 16:11:42.624035: Epoch time: 4.32 s 
2023-10-26 16:11:43.955358:  
2023-10-26 16:11:43.955655: Epoch 540 
2023-10-26 16:11:43.955903: Current learning rate: 0.00497 
2023-10-26 16:11:48.241671: train_loss -0.8825 
2023-10-26 16:11:48.242053: val_loss -0.8059 
2023-10-26 16:11:48.242307: Pseudo dice [0.8428, 0.9274, 0.9678, 0.496, 0.9376] 
2023-10-26 16:11:48.242596: Epoch time: 4.29 s 
2023-10-26 16:11:49.379668:  
2023-10-26 16:11:49.379954: Epoch 541 
2023-10-26 16:11:49.380207: Current learning rate: 0.00496 
2023-10-26 16:11:53.613550: train_loss -0.8913 
2023-10-26 16:11:53.614035: val_loss -0.7789 
2023-10-26 16:11:53.614311: Pseudo dice [0.8368, 0.9284, 0.9674, 0.5244, 0.84] 
2023-10-26 16:11:53.614541: Epoch time: 4.23 s 
2023-10-26 16:11:54.752386:  
2023-10-26 16:11:54.752716: Epoch 542 
2023-10-26 16:11:54.753018: Current learning rate: 0.00495 
2023-10-26 16:11:58.938283: train_loss -0.8961 
2023-10-26 16:11:58.938718: val_loss -0.6792 
2023-10-26 16:11:58.939184: Pseudo dice [0.8319, 0.9219, 0.9668, 0.2255, 0.7612] 
2023-10-26 16:11:58.939479: Epoch time: 4.19 s 
2023-10-26 16:12:00.128882:  
2023-10-26 16:12:00.129240: Epoch 543 
2023-10-26 16:12:00.129533: Current learning rate: 0.00494 
2023-10-26 16:12:04.485687: train_loss -0.8932 
2023-10-26 16:12:04.486104: val_loss -0.8016 
2023-10-26 16:12:04.486373: Pseudo dice [0.8477, 0.9294, 0.9674, 0.5615, 0.9327] 
2023-10-26 16:12:04.486620: Epoch time: 4.36 s 
2023-10-26 16:12:05.606713:  
2023-10-26 16:12:05.607023: Epoch 544 
2023-10-26 16:12:05.607274: Current learning rate: 0.00493 
2023-10-26 16:12:09.716062: train_loss -0.8802 
2023-10-26 16:12:09.716817: val_loss -0.738 
2023-10-26 16:12:09.717204: Pseudo dice [0.8272, 0.9196, 0.9672, 0.3573, 0.7964] 
2023-10-26 16:12:09.717524: Epoch time: 4.11 s 
2023-10-26 16:12:10.898420:  
2023-10-26 16:12:10.898729: Epoch 545 
2023-10-26 16:12:10.898999: Current learning rate: 0.00492 
2023-10-26 16:12:15.043539: train_loss -0.8905 
2023-10-26 16:12:15.044222: val_loss -0.7556 
2023-10-26 16:12:15.044533: Pseudo dice [0.8428, 0.9225, 0.9659, 0.5694, 0.777] 
2023-10-26 16:12:15.044887: Epoch time: 4.15 s 
2023-10-26 16:12:16.219770:  
2023-10-26 16:12:16.220106: Epoch 546 
2023-10-26 16:12:16.220378: Current learning rate: 0.00491 
2023-10-26 16:12:20.386096: train_loss -0.891 
2023-10-26 16:12:20.386483: val_loss -0.727 
2023-10-26 16:12:20.386740: Pseudo dice [0.8204, 0.9141, 0.9632, 0.5524, 0.8029] 
2023-10-26 16:12:20.386993: Epoch time: 4.17 s 
2023-10-26 16:12:21.741384:  
2023-10-26 16:12:21.741900: Epoch 547 
2023-10-26 16:12:21.742190: Current learning rate: 0.0049 
2023-10-26 16:12:25.792012: train_loss -0.889 
2023-10-26 16:12:25.792461: val_loss -0.7559 
2023-10-26 16:12:25.792716: Pseudo dice [0.835, 0.9263, 0.9671, 0.5145, 0.7744] 
2023-10-26 16:12:25.792959: Epoch time: 4.05 s 
2023-10-26 16:12:26.940415:  
2023-10-26 16:12:26.940713: Epoch 548 
2023-10-26 16:12:26.940957: Current learning rate: 0.00489 
2023-10-26 16:12:31.112633: train_loss -0.8913 
2023-10-26 16:12:31.113064: val_loss -0.7157 
2023-10-26 16:12:31.113351: Pseudo dice [0.8543, 0.9262, 0.9656, 0.5876, 0.762] 
2023-10-26 16:12:31.113580: Epoch time: 4.17 s 
2023-10-26 16:12:32.264042:  
2023-10-26 16:12:32.264378: Epoch 549 
2023-10-26 16:12:32.264646: Current learning rate: 0.00488 
2023-10-26 16:12:36.566586: train_loss -0.8949 
2023-10-26 16:12:36.567029: val_loss -0.6591 
2023-10-26 16:12:36.567292: Pseudo dice [0.8418, 0.9232, 0.9674, 0.011, 0.7013] 
2023-10-26 16:12:36.567533: Epoch time: 4.3 s 
2023-10-26 16:12:37.794149:  
2023-10-26 16:12:37.794454: Epoch 550 
2023-10-26 16:12:37.794703: Current learning rate: 0.00487 
2023-10-26 16:12:42.037034: train_loss -0.8858 
2023-10-26 16:12:42.037519: val_loss -0.7778 
2023-10-26 16:12:42.037820: Pseudo dice [0.8413, 0.9252, 0.9682, 0.5245, 0.8527] 
2023-10-26 16:12:42.038104: Epoch time: 4.24 s 
2023-10-26 16:12:43.281414:  
2023-10-26 16:12:43.281732: Epoch 551 
2023-10-26 16:12:43.281998: Current learning rate: 0.00486 
2023-10-26 16:12:47.458640: train_loss -0.883 
2023-10-26 16:12:47.459042: val_loss -0.7787 
2023-10-26 16:12:47.459293: Pseudo dice [0.8255, 0.9169, 0.9643, 0.3766, 0.8953] 
2023-10-26 16:12:47.459535: Epoch time: 4.18 s 
2023-10-26 16:12:48.594166:  
2023-10-26 16:12:48.594474: Epoch 552 
2023-10-26 16:12:48.594726: Current learning rate: 0.00485 
2023-10-26 16:12:52.911680: train_loss -0.8857 
2023-10-26 16:12:52.912100: val_loss -0.7663 
2023-10-26 16:12:52.912353: Pseudo dice [0.8411, 0.9238, 0.9646, 0.3239, 0.837] 
2023-10-26 16:12:52.912586: Epoch time: 4.32 s 
2023-10-26 16:12:54.288913:  
2023-10-26 16:12:54.289216: Epoch 553 
2023-10-26 16:12:54.289467: Current learning rate: 0.00484 
2023-10-26 16:12:58.504524: train_loss -0.8952 
2023-10-26 16:12:58.505153: val_loss -0.7135 
2023-10-26 16:12:58.505442: Pseudo dice [0.8403, 0.9227, 0.9666, 0.5208, 0.7194] 
2023-10-26 16:12:58.505690: Epoch time: 4.22 s 
2023-10-26 16:12:59.654742:  
2023-10-26 16:12:59.655075: Epoch 554 
2023-10-26 16:12:59.655332: Current learning rate: 0.00484 
2023-10-26 16:13:03.827604: train_loss -0.8891 
2023-10-26 16:13:03.828024: val_loss -0.6694 
2023-10-26 16:13:03.828298: Pseudo dice [0.8123, 0.9108, 0.9637, 0.2212, 0.7546] 
2023-10-26 16:13:03.828531: Epoch time: 4.17 s 
2023-10-26 16:13:04.966010:  
2023-10-26 16:13:04.966307: Epoch 555 
2023-10-26 16:13:04.966542: Current learning rate: 0.00483 
2023-10-26 16:13:09.201200: train_loss -0.8708 
2023-10-26 16:13:09.201556: val_loss -0.7328 
2023-10-26 16:13:09.201805: Pseudo dice [0.8452, 0.9246, 0.9644, 0.3651, 0.8219] 
2023-10-26 16:13:09.202053: Epoch time: 4.24 s 
2023-10-26 16:13:10.334126:  
2023-10-26 16:13:10.334430: Epoch 556 
2023-10-26 16:13:10.334729: Current learning rate: 0.00482 
2023-10-26 16:13:14.568082: train_loss -0.8748 
2023-10-26 16:13:14.568478: val_loss -0.7678 
2023-10-26 16:13:14.568735: Pseudo dice [0.8459, 0.9227, 0.9682, 0.589, 0.7877] 
2023-10-26 16:13:14.568977: Epoch time: 4.23 s 
2023-10-26 16:13:15.699242:  
2023-10-26 16:13:15.699546: Epoch 557 
2023-10-26 16:13:15.699796: Current learning rate: 0.00481 
2023-10-26 16:13:19.886748: train_loss -0.8849 
2023-10-26 16:13:19.887125: val_loss -0.7667 
2023-10-26 16:13:19.887392: Pseudo dice [0.856, 0.9206, 0.9669, 0.6751, 0.7738] 
2023-10-26 16:13:19.887615: Epoch time: 4.19 s 
2023-10-26 16:13:21.062495:  
2023-10-26 16:13:21.062815: Epoch 558 
2023-10-26 16:13:21.063064: Current learning rate: 0.0048 
2023-10-26 16:13:25.384462: train_loss -0.8939 
2023-10-26 16:13:25.384849: val_loss -0.7027 
2023-10-26 16:13:25.385276: Pseudo dice [0.8429, 0.9269, 0.9685, 0.6667, 0.6771] 
2023-10-26 16:13:25.385729: Epoch time: 4.32 s 
2023-10-26 16:13:26.493598:  
2023-10-26 16:13:26.493898: Epoch 559 
2023-10-26 16:13:26.494139: Current learning rate: 0.00479 
2023-10-26 16:13:30.862972: train_loss -0.8924 
2023-10-26 16:13:30.863388: val_loss -0.7745 
2023-10-26 16:13:30.863668: Pseudo dice [0.8364, 0.9233, 0.9686, 0.6728, 0.7857] 
2023-10-26 16:13:30.863924: Epoch time: 4.37 s 
2023-10-26 16:13:32.145392:  
2023-10-26 16:13:32.145706: Epoch 560 
2023-10-26 16:13:32.145981: Current learning rate: 0.00478 
2023-10-26 16:13:36.406405: train_loss -0.8797 
2023-10-26 16:13:36.406789: val_loss -0.8103 
2023-10-26 16:13:36.407051: Pseudo dice [0.8417, 0.9285, 0.9681, 0.6412, 0.9261] 
2023-10-26 16:13:36.407281: Epoch time: 4.26 s 
2023-10-26 16:13:37.579180:  
2023-10-26 16:13:37.579485: Epoch 561 
2023-10-26 16:13:37.579739: Current learning rate: 0.00477 
2023-10-26 16:13:41.866486: train_loss -0.8816 
2023-10-26 16:13:41.866882: val_loss -0.8218 
2023-10-26 16:13:41.867146: Pseudo dice [0.8462, 0.9281, 0.9694, 0.6593, 0.9364] 
2023-10-26 16:13:41.867390: Epoch time: 4.29 s 
2023-10-26 16:13:43.010069:  
2023-10-26 16:13:43.010365: Epoch 562 
2023-10-26 16:13:43.010601: Current learning rate: 0.00476 
2023-10-26 16:13:47.168743: train_loss -0.8867 
2023-10-26 16:13:47.169099: val_loss -0.8144 
2023-10-26 16:13:47.169346: Pseudo dice [0.8272, 0.9181, 0.9656, 0.5655, 0.9385] 
2023-10-26 16:13:47.169566: Epoch time: 4.16 s 
2023-10-26 16:13:48.302170:  
2023-10-26 16:13:48.302475: Epoch 563 
2023-10-26 16:13:48.302727: Current learning rate: 0.00475 
2023-10-26 16:13:52.482789: train_loss -0.8793 
2023-10-26 16:13:52.483168: val_loss -0.8232 
2023-10-26 16:13:52.483422: Pseudo dice [0.8433, 0.9267, 0.9672, 0.6713, 0.9358] 
2023-10-26 16:13:52.483667: Epoch time: 4.18 s 
2023-10-26 16:13:53.612363:  
2023-10-26 16:13:53.612907: Epoch 564 
2023-10-26 16:13:53.613164: Current learning rate: 0.00474 
2023-10-26 16:13:57.840588: train_loss -0.89 
2023-10-26 16:13:57.841001: val_loss -0.7972 
2023-10-26 16:13:57.841396: Pseudo dice [0.8369, 0.9241, 0.9671, 0.3906, 0.9176] 
2023-10-26 16:13:57.841725: Epoch time: 4.23 s 
2023-10-26 16:13:58.974037:  
2023-10-26 16:13:58.974323: Epoch 565 
2023-10-26 16:13:58.974555: Current learning rate: 0.00473 
2023-10-26 16:14:03.173122: train_loss -0.881 
2023-10-26 16:14:03.173482: val_loss -0.8072 
2023-10-26 16:14:03.173736: Pseudo dice [0.8329, 0.9274, 0.9671, 0.5026, 0.9274] 
2023-10-26 16:14:03.173974: Epoch time: 4.2 s 
2023-10-26 16:14:04.506402:  
2023-10-26 16:14:04.506692: Epoch 566 
2023-10-26 16:14:04.506925: Current learning rate: 0.00472 
2023-10-26 16:14:08.677348: train_loss -0.8852 
2023-10-26 16:14:08.677782: val_loss -0.7941 
2023-10-26 16:14:08.678052: Pseudo dice [0.8353, 0.9267, 0.9624, 0.5849, 0.8611] 
2023-10-26 16:14:08.678287: Epoch time: 4.17 s 
2023-10-26 16:14:09.814090:  
2023-10-26 16:14:09.814380: Epoch 567 
2023-10-26 16:14:09.814617: Current learning rate: 0.00471 
2023-10-26 16:14:14.038328: train_loss -0.8873 
2023-10-26 16:14:14.038693: val_loss -0.7693 
2023-10-26 16:14:14.038950: Pseudo dice [0.8493, 0.9283, 0.9664, 0.5834, 0.804] 
2023-10-26 16:14:14.039265: Epoch time: 4.22 s 
2023-10-26 16:14:15.180618:  
2023-10-26 16:14:15.180911: Epoch 568 
2023-10-26 16:14:15.181149: Current learning rate: 0.0047 
2023-10-26 16:14:19.474971: train_loss -0.893 
2023-10-26 16:14:19.475333: val_loss -0.6726 
2023-10-26 16:14:19.475590: Pseudo dice [0.8402, 0.9236, 0.964, 0.3457, 0.7229] 
2023-10-26 16:14:19.475817: Epoch time: 4.29 s 
2023-10-26 16:14:20.607082:  
2023-10-26 16:14:20.607376: Epoch 569 
2023-10-26 16:14:20.607621: Current learning rate: 0.00469 
2023-10-26 16:14:24.770064: train_loss -0.8931 
2023-10-26 16:14:24.770464: val_loss -0.7705 
2023-10-26 16:14:24.770741: Pseudo dice [0.8294, 0.9268, 0.9685, 0.4137, 0.8655] 
2023-10-26 16:14:24.771019: Epoch time: 4.16 s 
2023-10-26 16:14:25.939027:  
2023-10-26 16:14:25.939320: Epoch 570 
2023-10-26 16:14:25.939562: Current learning rate: 0.00468 
2023-10-26 16:14:30.076715: train_loss -0.8962 
2023-10-26 16:14:30.077090: val_loss -0.768 
2023-10-26 16:14:30.077348: Pseudo dice [0.8389, 0.9242, 0.9668, 0.5809, 0.7529] 
2023-10-26 16:14:30.077566: Epoch time: 4.14 s 
2023-10-26 16:14:31.210474:  
2023-10-26 16:14:31.210797: Epoch 571 
2023-10-26 16:14:31.211045: Current learning rate: 0.00467 
2023-10-26 16:14:35.553355: train_loss -0.8831 
2023-10-26 16:14:35.553756: val_loss -0.7133 
2023-10-26 16:14:35.554014: Pseudo dice [0.8434, 0.9202, 0.9662, 0.4158, 0.7462] 
2023-10-26 16:14:35.554250: Epoch time: 4.34 s 
2023-10-26 16:14:36.690318:  
2023-10-26 16:14:36.690601: Epoch 572 
2023-10-26 16:14:36.690841: Current learning rate: 0.00466 
2023-10-26 16:14:41.001652: train_loss -0.8856 
2023-10-26 16:14:41.002073: val_loss -0.7873 
2023-10-26 16:14:41.002337: Pseudo dice [0.8398, 0.9252, 0.9674, 0.6325, 0.8622] 
2023-10-26 16:14:41.002585: Epoch time: 4.31 s 
2023-10-26 16:14:42.376782:  
2023-10-26 16:14:42.377089: Epoch 573 
2023-10-26 16:14:42.377332: Current learning rate: 0.00465 
2023-10-26 16:14:46.835523: train_loss -0.8873 
2023-10-26 16:14:46.835924: val_loss -0.7477 
2023-10-26 16:14:46.836198: Pseudo dice [0.8501, 0.9296, 0.9662, 0.7103, 0.7611] 
2023-10-26 16:14:46.836507: Epoch time: 4.46 s 
2023-10-26 16:14:47.963077:  
2023-10-26 16:14:47.963367: Epoch 574 
2023-10-26 16:14:47.963607: Current learning rate: 0.00464 
2023-10-26 16:14:52.301315: train_loss -0.8809 
2023-10-26 16:14:52.301701: val_loss -0.8285 
2023-10-26 16:14:52.301954: Pseudo dice [0.8524, 0.9293, 0.9676, 0.6868, 0.9286] 
2023-10-26 16:14:52.302181: Epoch time: 4.34 s 
2023-10-26 16:14:53.439553:  
2023-10-26 16:14:53.439847: Epoch 575 
2023-10-26 16:14:53.440092: Current learning rate: 0.00463 
2023-10-26 16:14:57.569006: train_loss -0.8885 
2023-10-26 16:14:57.569355: val_loss -0.7564 
2023-10-26 16:14:57.569612: Pseudo dice [0.8242, 0.9218, 0.9663, 0.7019, 0.7337] 
2023-10-26 16:14:57.569835: Epoch time: 4.13 s 
2023-10-26 16:14:58.698711:  
2023-10-26 16:14:58.699010: Epoch 576 
2023-10-26 16:14:58.699244: Current learning rate: 0.00462 
2023-10-26 16:15:02.996461: train_loss -0.8877 
2023-10-26 16:15:02.996802: val_loss -0.7409 
2023-10-26 16:15:02.997061: Pseudo dice [0.8417, 0.9242, 0.9657, 0.6147, 0.7428] 
2023-10-26 16:15:02.997281: Epoch time: 4.3 s 
2023-10-26 16:15:04.171295:  
2023-10-26 16:15:04.171607: Epoch 577 
2023-10-26 16:15:04.171845: Current learning rate: 0.00461 
2023-10-26 16:15:08.335110: train_loss -0.8848 
2023-10-26 16:15:08.335501: val_loss -0.69 
2023-10-26 16:15:08.335773: Pseudo dice [0.8321, 0.9243, 0.9652, 0.0556, 0.7779] 
2023-10-26 16:15:08.336018: Epoch time: 4.16 s 
2023-10-26 16:15:09.475018:  
2023-10-26 16:15:09.475296: Epoch 578 
2023-10-26 16:15:09.475549: Current learning rate: 0.0046 
2023-10-26 16:15:13.646534: train_loss -0.8932 
2023-10-26 16:15:13.646910: val_loss -0.7372 
2023-10-26 16:15:13.647255: Pseudo dice [0.8333, 0.9296, 0.9659, 0.342, 0.7996] 
2023-10-26 16:15:13.647553: Epoch time: 4.17 s 
2023-10-26 16:15:14.972912:  
2023-10-26 16:15:14.973208: Epoch 579 
2023-10-26 16:15:14.973461: Current learning rate: 0.00459 
2023-10-26 16:15:19.168952: train_loss -0.8904 
2023-10-26 16:15:19.169346: val_loss -0.797 
2023-10-26 16:15:19.169607: Pseudo dice [0.8432, 0.9255, 0.9644, 0.5861, 0.8631] 
2023-10-26 16:15:19.169833: Epoch time: 4.2 s 
2023-10-26 16:15:20.314229:  
2023-10-26 16:15:20.314530: Epoch 580 
2023-10-26 16:15:20.314776: Current learning rate: 0.00458 
2023-10-26 16:15:24.297041: train_loss -0.8925 
2023-10-26 16:15:24.297392: val_loss -0.7175 
2023-10-26 16:15:24.297648: Pseudo dice [0.8478, 0.9242, 0.9664, 0.3661, 0.741] 
2023-10-26 16:15:24.297878: Epoch time: 3.98 s 
2023-10-26 16:15:25.450688:  
2023-10-26 16:15:25.450992: Epoch 581 
2023-10-26 16:15:25.451222: Current learning rate: 0.00457 
2023-10-26 16:15:29.614990: train_loss -0.889 
2023-10-26 16:15:29.615348: val_loss -0.7239 
2023-10-26 16:15:29.615599: Pseudo dice [0.8518, 0.918, 0.9665, 0.3313, 0.7829] 
2023-10-26 16:15:29.615816: Epoch time: 4.16 s 
2023-10-26 16:15:30.793494:  
2023-10-26 16:15:30.793789: Epoch 582 
2023-10-26 16:15:30.794039: Current learning rate: 0.00456 
2023-10-26 16:15:34.966188: train_loss -0.8874 
2023-10-26 16:15:34.966568: val_loss -0.722 
2023-10-26 16:15:34.966830: Pseudo dice [0.8567, 0.9319, 0.9676, 0.6128, 0.6751] 
2023-10-26 16:15:34.967062: Epoch time: 4.17 s 
2023-10-26 16:15:36.238448:  
2023-10-26 16:15:36.238752: Epoch 583 
2023-10-26 16:15:36.239004: Current learning rate: 0.00455 
2023-10-26 16:15:40.427337: train_loss -0.8971 
2023-10-26 16:15:40.427719: val_loss -0.7331 
2023-10-26 16:15:40.428014: Pseudo dice [0.8456, 0.9285, 0.967, 0.6481, 0.7864] 
2023-10-26 16:15:40.428283: Epoch time: 4.19 s 
2023-10-26 16:15:41.619798:  
2023-10-26 16:15:41.620105: Epoch 584 
2023-10-26 16:15:41.620379: Current learning rate: 0.00454 
2023-10-26 16:15:45.889526: train_loss -0.9025 
2023-10-26 16:15:45.889972: val_loss -0.6958 
2023-10-26 16:15:45.890239: Pseudo dice [0.8553, 0.9288, 0.9664, 0.385, 0.7052] 
2023-10-26 16:15:45.890486: Epoch time: 4.27 s 
2023-10-26 16:15:47.179337:  
2023-10-26 16:15:47.179651: Epoch 585 
2023-10-26 16:15:47.179933: Current learning rate: 0.00453 
2023-10-26 16:15:51.575865: train_loss -0.8984 
2023-10-26 16:15:51.576229: val_loss -0.7532 
2023-10-26 16:15:51.576500: Pseudo dice [0.8355, 0.9248, 0.9667, 0.5203, 0.7818] 
2023-10-26 16:15:51.576742: Epoch time: 4.4 s 
2023-10-26 16:15:52.721792:  
2023-10-26 16:15:52.722227: Epoch 586 
2023-10-26 16:15:52.722481: Current learning rate: 0.00452 
2023-10-26 16:15:56.929978: train_loss -0.8927 
2023-10-26 16:15:56.930384: val_loss -0.8009 
2023-10-26 16:15:56.930647: Pseudo dice [0.8467, 0.9279, 0.9673, 0.5973, 0.856] 
2023-10-26 16:15:56.930898: Epoch time: 4.21 s 
2023-10-26 16:15:58.079650:  
2023-10-26 16:15:58.079944: Epoch 587 
2023-10-26 16:15:58.080175: Current learning rate: 0.00451 
2023-10-26 16:16:02.236574: train_loss -0.8927 
2023-10-26 16:16:02.237014: val_loss -0.8101 
2023-10-26 16:16:02.237287: Pseudo dice [0.8511, 0.9258, 0.9658, 0.6192, 0.8865] 
2023-10-26 16:16:02.237526: Epoch time: 4.16 s 
2023-10-26 16:16:03.381219:  
2023-10-26 16:16:03.381510: Epoch 588 
2023-10-26 16:16:03.381754: Current learning rate: 0.0045 
2023-10-26 16:16:07.650101: train_loss -0.8957 
2023-10-26 16:16:07.650505: val_loss -0.7131 
2023-10-26 16:16:07.650770: Pseudo dice [0.8529, 0.9232, 0.9657, 0.6446, 0.7583] 
2023-10-26 16:16:07.651032: Epoch time: 4.27 s 
2023-10-26 16:16:08.802211:  
2023-10-26 16:16:08.802523: Epoch 589 
2023-10-26 16:16:08.802775: Current learning rate: 0.00449 
2023-10-26 16:16:13.101388: train_loss -0.8941 
2023-10-26 16:16:13.101765: val_loss -0.7227 
2023-10-26 16:16:13.102071: Pseudo dice [0.8445, 0.9227, 0.9668, 0.4298, 0.8019] 
2023-10-26 16:16:13.102307: Epoch time: 4.3 s 
2023-10-26 16:16:14.256551:  
2023-10-26 16:16:14.256854: Epoch 590 
2023-10-26 16:16:14.257102: Current learning rate: 0.00448 
2023-10-26 16:16:18.522710: train_loss -0.8825 
2023-10-26 16:16:18.523135: val_loss -0.7866 
2023-10-26 16:16:18.523399: Pseudo dice [0.8472, 0.9266, 0.9702, 0.5981, 0.9356] 
2023-10-26 16:16:18.523648: Epoch time: 4.27 s 
2023-10-26 16:16:19.666116:  
2023-10-26 16:16:19.666464: Epoch 591 
2023-10-26 16:16:19.666721: Current learning rate: 0.00447 
2023-10-26 16:16:23.880117: train_loss -0.8897 
2023-10-26 16:16:23.880603: val_loss -0.7939 
2023-10-26 16:16:23.880954: Pseudo dice [0.8429, 0.9283, 0.9662, 0.4766, 0.8217] 
2023-10-26 16:16:23.881262: Epoch time: 4.21 s 
2023-10-26 16:16:25.219098:  
2023-10-26 16:16:25.219398: Epoch 592 
2023-10-26 16:16:25.219657: Current learning rate: 0.00446 
2023-10-26 16:16:29.450392: train_loss -0.8794 
2023-10-26 16:16:29.450915: val_loss -0.7836 
2023-10-26 16:16:29.451338: Pseudo dice [0.8413, 0.922, 0.9681, 0.4634, 0.9176] 
2023-10-26 16:16:29.451670: Epoch time: 4.23 s 
2023-10-26 16:16:30.605282:  
2023-10-26 16:16:30.605606: Epoch 593 
2023-10-26 16:16:30.605868: Current learning rate: 0.00445 
2023-10-26 16:16:34.872931: train_loss -0.882 
2023-10-26 16:16:34.873351: val_loss -0.7914 
2023-10-26 16:16:34.873641: Pseudo dice [0.8262, 0.9206, 0.9668, 0.5055, 0.8717] 
2023-10-26 16:16:34.874056: Epoch time: 4.27 s 
2023-10-26 16:16:36.044213:  
2023-10-26 16:16:36.044527: Epoch 594 
2023-10-26 16:16:36.044777: Current learning rate: 0.00444 
2023-10-26 16:16:40.133894: train_loss -0.8904 
2023-10-26 16:16:40.134259: val_loss -0.7633 
2023-10-26 16:16:40.134515: Pseudo dice [0.838, 0.922, 0.9642, 0.3578, 0.8111] 
2023-10-26 16:16:40.134761: Epoch time: 4.09 s 
2023-10-26 16:16:41.296217:  
2023-10-26 16:16:41.296570: Epoch 595 
2023-10-26 16:16:41.296897: Current learning rate: 0.00443 
2023-10-26 16:16:45.453786: train_loss -0.8896 
2023-10-26 16:16:45.454178: val_loss -0.8014 
2023-10-26 16:16:45.454432: Pseudo dice [0.8455, 0.9216, 0.965, 0.5352, 0.8849] 
2023-10-26 16:16:45.454669: Epoch time: 4.16 s 
2023-10-26 16:16:46.649279:  
2023-10-26 16:16:46.649578: Epoch 596 
2023-10-26 16:16:46.649817: Current learning rate: 0.00442 
2023-10-26 16:16:50.839932: train_loss -0.8875 
2023-10-26 16:16:50.840337: val_loss -0.8184 
2023-10-26 16:16:50.840591: Pseudo dice [0.8385, 0.9238, 0.9676, 0.654, 0.9275] 
2023-10-26 16:16:50.840826: Epoch time: 4.19 s 
2023-10-26 16:16:52.069836:  
2023-10-26 16:16:52.070150: Epoch 597 
2023-10-26 16:16:52.070400: Current learning rate: 0.00441 
2023-10-26 16:16:56.286644: train_loss -0.8713 
2023-10-26 16:16:56.287031: val_loss -0.722 
2023-10-26 16:16:56.287285: Pseudo dice [0.8258, 0.9218, 0.966, 0.5447, 0.7476] 
2023-10-26 16:16:56.287520: Epoch time: 4.22 s 
2023-10-26 16:16:57.628387:  
2023-10-26 16:16:57.628682: Epoch 598 
2023-10-26 16:16:57.628942: Current learning rate: 0.0044 
2023-10-26 16:17:01.799676: train_loss -0.8722 
2023-10-26 16:17:01.800046: val_loss -0.8034 
2023-10-26 16:17:01.800308: Pseudo dice [0.8342, 0.9166, 0.9689, 0.6159, 0.8984] 
2023-10-26 16:17:01.800531: Epoch time: 4.17 s 
2023-10-26 16:17:03.001497:  
2023-10-26 16:17:03.001820: Epoch 599 
2023-10-26 16:17:03.002101: Current learning rate: 0.00439 
2023-10-26 16:17:07.230134: train_loss -0.8847 
2023-10-26 16:17:07.230534: val_loss -0.775 
2023-10-26 16:17:07.230799: Pseudo dice [0.8338, 0.9204, 0.9651, 0.6406, 0.7757] 
2023-10-26 16:17:07.231060: Epoch time: 4.23 s 
2023-10-26 16:17:08.503487:  
2023-10-26 16:17:08.503794: Epoch 600 
2023-10-26 16:17:08.504045: Current learning rate: 0.00438 
2023-10-26 16:17:12.846696: train_loss -0.8768 
2023-10-26 16:17:12.847124: val_loss -0.7169 
2023-10-26 16:17:12.847535: Pseudo dice [0.8369, 0.9086, 0.9658, 0.0, 0.7539] 
2023-10-26 16:17:12.847814: Epoch time: 4.34 s 
2023-10-26 16:17:13.992048:  
2023-10-26 16:17:13.992340: Epoch 601 
2023-10-26 16:17:13.992589: Current learning rate: 0.00437 
2023-10-26 16:17:18.217142: train_loss -0.8708 
2023-10-26 16:17:18.217517: val_loss -0.7563 
2023-10-26 16:17:18.217783: Pseudo dice [0.8286, 0.9177, 0.9629, 0.4744, 0.7921] 
2023-10-26 16:17:18.218036: Epoch time: 4.23 s 
2023-10-26 16:17:19.407563:  
2023-10-26 16:17:19.407864: Epoch 602 
2023-10-26 16:17:19.408118: Current learning rate: 0.00436 
2023-10-26 16:17:23.758026: train_loss -0.8759 
2023-10-26 16:17:23.758425: val_loss -0.7972 
2023-10-26 16:17:23.758696: Pseudo dice [0.8533, 0.9287, 0.9674, 0.6518, 0.875] 
2023-10-26 16:17:23.758942: Epoch time: 4.35 s 
2023-10-26 16:17:24.891597:  
2023-10-26 16:17:24.891893: Epoch 603 
2023-10-26 16:17:24.892134: Current learning rate: 0.00435 
2023-10-26 16:17:29.240961: train_loss -0.8838 
2023-10-26 16:17:29.241332: val_loss -0.7409 
2023-10-26 16:17:29.241585: Pseudo dice [0.8481, 0.9276, 0.9663, 0.5824, 0.7891] 
2023-10-26 16:17:29.241815: Epoch time: 4.35 s 
2023-10-26 16:17:30.537951:  
2023-10-26 16:17:30.538244: Epoch 604 
2023-10-26 16:17:30.538490: Current learning rate: 0.00434 
2023-10-26 16:17:34.898559: train_loss -0.895 
2023-10-26 16:17:34.898951: val_loss -0.7116 
2023-10-26 16:17:34.899218: Pseudo dice [0.8296, 0.9177, 0.9689, 0.2443, 0.8149] 
2023-10-26 16:17:34.899470: Epoch time: 4.36 s 
2023-10-26 16:17:36.098489:  
2023-10-26 16:17:36.098798: Epoch 605 
2023-10-26 16:17:36.099044: Current learning rate: 0.00433 
2023-10-26 16:17:40.387348: train_loss -0.8855 
2023-10-26 16:17:40.387886: val_loss -0.8038 
2023-10-26 16:17:40.388211: Pseudo dice [0.8503, 0.924, 0.9663, 0.6328, 0.843] 
2023-10-26 16:17:40.388704: Epoch time: 4.29 s 
2023-10-26 16:17:41.562045:  
2023-10-26 16:17:41.562387: Epoch 606 
2023-10-26 16:17:41.562687: Current learning rate: 0.00432 
2023-10-26 16:17:45.800574: train_loss -0.8926 
2023-10-26 16:17:45.800940: val_loss -0.7213 
2023-10-26 16:17:45.801195: Pseudo dice [0.8598, 0.9227, 0.9635, 0.6131, 0.7915] 
2023-10-26 16:17:45.801420: Epoch time: 4.24 s 
2023-10-26 16:17:46.950024:  
2023-10-26 16:17:46.950319: Epoch 607 
2023-10-26 16:17:46.950603: Current learning rate: 0.00431 
2023-10-26 16:17:51.157096: train_loss -0.8962 
2023-10-26 16:17:51.157450: val_loss -0.7854 
2023-10-26 16:17:51.157714: Pseudo dice [0.8548, 0.9293, 0.967, 0.6183, 0.7793] 
2023-10-26 16:17:51.157956: Epoch time: 4.21 s 
2023-10-26 16:17:52.318202:  
2023-10-26 16:17:52.318523: Epoch 608 
2023-10-26 16:17:52.318760: Current learning rate: 0.0043 
2023-10-26 16:17:56.534043: train_loss -0.8976 
2023-10-26 16:17:56.534453: val_loss -0.7025 
2023-10-26 16:17:56.534727: Pseudo dice [0.8228, 0.9209, 0.9662, 0.6398, 0.6894] 
2023-10-26 16:17:56.534963: Epoch time: 4.22 s 
2023-10-26 16:17:57.702705:  
2023-10-26 16:17:57.703001: Epoch 609 
2023-10-26 16:17:57.703242: Current learning rate: 0.00429 
2023-10-26 16:18:02.017434: train_loss -0.8832 
2023-10-26 16:18:02.017948: val_loss -0.8121 
2023-10-26 16:18:02.018217: Pseudo dice [0.8388, 0.9217, 0.9666, 0.6404, 0.8797] 
2023-10-26 16:18:02.018444: Epoch time: 4.32 s 
2023-10-26 16:18:03.173851:  
2023-10-26 16:18:03.174170: Epoch 610 
2023-10-26 16:18:03.174421: Current learning rate: 0.00429 
2023-10-26 16:18:07.423315: train_loss -0.8853 
2023-10-26 16:18:07.423667: val_loss -0.7914 
2023-10-26 16:18:07.423921: Pseudo dice [0.8469, 0.9255, 0.967, 0.7195, 0.7402] 
2023-10-26 16:18:07.424145: Epoch time: 4.25 s 
2023-10-26 16:18:08.770302:  
2023-10-26 16:18:08.770606: Epoch 611 
2023-10-26 16:18:08.770845: Current learning rate: 0.00428 
2023-10-26 16:18:13.196000: train_loss -0.8852 
2023-10-26 16:18:13.196359: val_loss -0.7208 
2023-10-26 16:18:13.196622: Pseudo dice [0.8443, 0.9289, 0.9662, 0.6502, 0.6514] 
2023-10-26 16:18:13.196884: Epoch time: 4.43 s 
2023-10-26 16:18:14.413245:  
2023-10-26 16:18:14.413544: Epoch 612 
2023-10-26 16:18:14.413791: Current learning rate: 0.00427 
2023-10-26 16:18:18.696813: train_loss -0.8814 
2023-10-26 16:18:18.697225: val_loss -0.8058 
2023-10-26 16:18:18.697500: Pseudo dice [0.8414, 0.9207, 0.9668, 0.6839, 0.8392] 
2023-10-26 16:18:18.697761: Epoch time: 4.28 s 
2023-10-26 16:18:19.894690:  
2023-10-26 16:18:19.894996: Epoch 613 
2023-10-26 16:18:19.895236: Current learning rate: 0.00426 
2023-10-26 16:18:24.053115: train_loss -0.8918 
2023-10-26 16:18:24.053534: val_loss -0.6781 
2023-10-26 16:18:24.054044: Pseudo dice [0.8421, 0.9228, 0.9663, 0.034, 0.6295] 
2023-10-26 16:18:24.054374: Epoch time: 4.16 s 
2023-10-26 16:18:25.217042:  
2023-10-26 16:18:25.217331: Epoch 614 
2023-10-26 16:18:25.217568: Current learning rate: 0.00425 
2023-10-26 16:18:29.345606: train_loss -0.8849 
2023-10-26 16:18:29.346033: val_loss -0.7304 
2023-10-26 16:18:29.346289: Pseudo dice [0.8345, 0.9221, 0.9657, 0.3788, 0.7476] 
2023-10-26 16:18:29.346532: Epoch time: 4.13 s 
2023-10-26 16:18:30.502563:  
2023-10-26 16:18:30.502867: Epoch 615 
2023-10-26 16:18:30.503118: Current learning rate: 0.00424 
2023-10-26 16:18:34.842092: train_loss -0.8959 
2023-10-26 16:18:34.842470: val_loss -0.7702 
2023-10-26 16:18:34.842729: Pseudo dice [0.8505, 0.9259, 0.9659, 0.5338, 0.7296] 
2023-10-26 16:18:34.843001: Epoch time: 4.34 s 
2023-10-26 16:18:35.990776:  
2023-10-26 16:18:35.991098: Epoch 616 
2023-10-26 16:18:35.991366: Current learning rate: 0.00423 
2023-10-26 16:18:40.273913: train_loss -0.8912 
2023-10-26 16:18:40.274254: val_loss -0.7221 
2023-10-26 16:18:40.274507: Pseudo dice [0.8295, 0.9188, 0.9631, 0.4707, 0.7908] 
2023-10-26 16:18:40.274736: Epoch time: 4.28 s 
2023-10-26 16:18:41.602454:  
2023-10-26 16:18:41.602744: Epoch 617 
2023-10-26 16:18:41.602995: Current learning rate: 0.00422 
2023-10-26 16:18:45.906949: train_loss -0.8914 
2023-10-26 16:18:45.907412: val_loss -0.7116 
2023-10-26 16:18:45.907702: Pseudo dice [0.8294, 0.9255, 0.9674, 0.5064, 0.7142] 
2023-10-26 16:18:45.907949: Epoch time: 4.31 s 
2023-10-26 16:18:47.093883:  
2023-10-26 16:18:47.094195: Epoch 618 
2023-10-26 16:18:47.094437: Current learning rate: 0.00421 
2023-10-26 16:18:51.396274: train_loss -0.8956 
2023-10-26 16:18:51.396633: val_loss -0.7621 
2023-10-26 16:18:51.396894: Pseudo dice [0.8412, 0.9286, 0.967, 0.6887, 0.7867] 
2023-10-26 16:18:51.397112: Epoch time: 4.3 s 
2023-10-26 16:18:52.589926:  
2023-10-26 16:18:52.590226: Epoch 619 
2023-10-26 16:18:52.590472: Current learning rate: 0.0042 
2023-10-26 16:18:56.887940: train_loss -0.8855 
2023-10-26 16:18:56.888334: val_loss -0.7449 
2023-10-26 16:18:56.888592: Pseudo dice [0.8293, 0.9216, 0.968, 0.3502, 0.8027] 
2023-10-26 16:18:56.888837: Epoch time: 4.3 s 
2023-10-26 16:18:58.049664:  
2023-10-26 16:18:58.049963: Epoch 620 
2023-10-26 16:18:58.050211: Current learning rate: 0.00419 
2023-10-26 16:19:02.354373: train_loss -0.8945 
2023-10-26 16:19:02.354829: val_loss -0.7495 
2023-10-26 16:19:02.355110: Pseudo dice [0.8419, 0.9272, 0.9663, 0.5301, 0.7644] 
2023-10-26 16:19:02.355377: Epoch time: 4.31 s 
2023-10-26 16:19:03.539944:  
2023-10-26 16:19:03.540259: Epoch 621 
2023-10-26 16:19:03.540524: Current learning rate: 0.00418 
2023-10-26 16:19:07.738368: train_loss -0.8937 
2023-10-26 16:19:07.738745: val_loss -0.7021 
2023-10-26 16:19:07.739076: Pseudo dice [0.817, 0.9195, 0.968, 0.3934, 0.7319] 
2023-10-26 16:19:07.739378: Epoch time: 4.2 s 
2023-10-26 16:19:08.914434:  
2023-10-26 16:19:08.914742: Epoch 622 
2023-10-26 16:19:08.915027: Current learning rate: 0.00417 
2023-10-26 16:19:13.148943: train_loss -0.8919 
2023-10-26 16:19:13.149348: val_loss -0.7166 
2023-10-26 16:19:13.149615: Pseudo dice [0.8463, 0.925, 0.9663, 0.5191, 0.6965] 
2023-10-26 16:19:13.149865: Epoch time: 4.24 s 
2023-10-26 16:19:14.370801:  
2023-10-26 16:19:14.371113: Epoch 623 
2023-10-26 16:19:14.371357: Current learning rate: 0.00416 
2023-10-26 16:19:18.819083: train_loss -0.8945 
2023-10-26 16:19:18.819456: val_loss -0.6877 
2023-10-26 16:19:18.819715: Pseudo dice [0.8361, 0.9244, 0.9671, 0.4295, 0.7059] 
2023-10-26 16:19:18.819946: Epoch time: 4.45 s 
2023-10-26 16:19:20.086320:  
2023-10-26 16:19:20.086629: Epoch 624 
2023-10-26 16:19:20.086877: Current learning rate: 0.00415 
2023-10-26 16:19:24.358470: train_loss -0.8984 
2023-10-26 16:19:24.358877: val_loss -0.7641 
2023-10-26 16:19:24.359148: Pseudo dice [0.8466, 0.924, 0.9674, 0.6242, 0.7997] 
2023-10-26 16:19:24.359604: Epoch time: 4.27 s 
2023-10-26 16:19:25.545044:  
2023-10-26 16:19:25.545352: Epoch 625 
2023-10-26 16:19:25.545588: Current learning rate: 0.00414 
2023-10-26 16:19:29.817843: train_loss -0.8987 
2023-10-26 16:19:29.818202: val_loss -0.7137 
2023-10-26 16:19:29.818465: Pseudo dice [0.839, 0.9259, 0.9681, 0.4275, 0.7672] 
2023-10-26 16:19:29.818712: Epoch time: 4.27 s 
2023-10-26 16:19:30.997637:  
2023-10-26 16:19:30.997952: Epoch 626 
2023-10-26 16:19:30.998196: Current learning rate: 0.00413 
2023-10-26 16:19:35.231498: train_loss -0.901 
2023-10-26 16:19:35.231906: val_loss -0.7323 
2023-10-26 16:19:35.232161: Pseudo dice [0.8365, 0.9245, 0.9675, 0.5409, 0.7561] 
2023-10-26 16:19:35.232400: Epoch time: 4.23 s 
2023-10-26 16:19:36.459897:  
2023-10-26 16:19:36.460203: Epoch 627 
2023-10-26 16:19:36.460456: Current learning rate: 0.00412 
2023-10-26 16:19:40.814241: train_loss -0.8974 
2023-10-26 16:19:40.814617: val_loss -0.7233 
2023-10-26 16:19:40.814892: Pseudo dice [0.8434, 0.9262, 0.968, 0.5084, 0.7806] 
2023-10-26 16:19:40.815135: Epoch time: 4.35 s 
2023-10-26 16:19:42.026366:  
2023-10-26 16:19:42.026660: Epoch 628 
2023-10-26 16:19:42.026901: Current learning rate: 0.00411 
2023-10-26 16:19:46.098149: train_loss -0.8982 
2023-10-26 16:19:46.098516: val_loss -0.7536 
2023-10-26 16:19:46.098771: Pseudo dice [0.8414, 0.9268, 0.9672, 0.5522, 0.8353] 
2023-10-26 16:19:46.098998: Epoch time: 4.07 s 
2023-10-26 16:19:47.258555:  
2023-10-26 16:19:47.258852: Epoch 629 
2023-10-26 16:19:47.259102: Current learning rate: 0.0041 
2023-10-26 16:19:51.390172: train_loss -0.8967 
2023-10-26 16:19:51.390595: val_loss -0.7176 
2023-10-26 16:19:51.390851: Pseudo dice [0.8464, 0.9284, 0.9666, 0.6111, 0.7436] 
2023-10-26 16:19:51.391106: Epoch time: 4.13 s 
2023-10-26 16:19:52.775150:  
2023-10-26 16:19:52.775441: Epoch 630 
2023-10-26 16:19:52.775685: Current learning rate: 0.00409 
2023-10-26 16:19:57.086090: train_loss -0.8991 
2023-10-26 16:19:57.086463: val_loss -0.6694 
2023-10-26 16:19:57.086713: Pseudo dice [0.846, 0.9314, 0.9667, 0.5935, 0.6768] 
2023-10-26 16:19:57.086940: Epoch time: 4.31 s 
2023-10-26 16:19:58.228361:  
2023-10-26 16:19:58.228655: Epoch 631 
2023-10-26 16:19:58.228891: Current learning rate: 0.00408 
2023-10-26 16:20:02.625469: train_loss -0.8837 
2023-10-26 16:20:02.625861: val_loss -0.7598 
2023-10-26 16:20:02.626238: Pseudo dice [0.8396, 0.9245, 0.967, 0.3917, 0.8758] 
2023-10-26 16:20:02.626476: Epoch time: 4.4 s 
2023-10-26 16:20:03.760352:  
2023-10-26 16:20:03.760636: Epoch 632 
2023-10-26 16:20:03.760869: Current learning rate: 0.00407 
2023-10-26 16:20:07.983252: train_loss -0.89 
2023-10-26 16:20:07.983617: val_loss -0.7486 
2023-10-26 16:20:07.983868: Pseudo dice [0.8344, 0.9303, 0.9635, 0.3414, 0.7522] 
2023-10-26 16:20:07.984117: Epoch time: 4.22 s 
2023-10-26 16:20:09.122148:  
2023-10-26 16:20:09.122469: Epoch 633 
2023-10-26 16:20:09.122704: Current learning rate: 0.00406 
2023-10-26 16:20:13.212399: train_loss -0.8938 
2023-10-26 16:20:13.212763: val_loss -0.7463 
2023-10-26 16:20:13.213043: Pseudo dice [0.8244, 0.9236, 0.9649, 0.4474, 0.7999] 
2023-10-26 16:20:13.213289: Epoch time: 4.09 s 
2023-10-26 16:20:14.379971:  
2023-10-26 16:20:14.380270: Epoch 634 
2023-10-26 16:20:14.380521: Current learning rate: 0.00405 
2023-10-26 16:20:18.679106: train_loss -0.8922 
2023-10-26 16:20:18.679502: val_loss -0.7395 
2023-10-26 16:20:18.679760: Pseudo dice [0.8392, 0.9253, 0.9648, 0.6565, 0.7107] 
2023-10-26 16:20:18.680000: Epoch time: 4.3 s 
2023-10-26 16:20:19.835746:  
2023-10-26 16:20:19.836097: Epoch 635 
2023-10-26 16:20:19.836399: Current learning rate: 0.00404 
2023-10-26 16:20:24.106741: train_loss -0.8996 
2023-10-26 16:20:24.107191: val_loss -0.7887 
2023-10-26 16:20:24.107487: Pseudo dice [0.8521, 0.9309, 0.9653, 0.6354, 0.8421] 
2023-10-26 16:20:24.107749: Epoch time: 4.27 s 
2023-10-26 16:20:25.514764:  
2023-10-26 16:20:25.515145: Epoch 636 
2023-10-26 16:20:25.515448: Current learning rate: 0.00403 
2023-10-26 16:20:29.772575: train_loss -0.8972 
2023-10-26 16:20:29.773035: val_loss -0.804 
2023-10-26 16:20:29.773295: Pseudo dice [0.8406, 0.9295, 0.9626, 0.6581, 0.8658] 
2023-10-26 16:20:29.773646: Epoch time: 4.26 s 
2023-10-26 16:20:30.934332:  
2023-10-26 16:20:30.934624: Epoch 637 
2023-10-26 16:20:30.934860: Current learning rate: 0.00402 
2023-10-26 16:20:35.179635: train_loss -0.8927 
2023-10-26 16:20:35.180009: val_loss -0.7099 
2023-10-26 16:20:35.180270: Pseudo dice [0.8467, 0.9187, 0.9652, 0.4931, 0.7799] 
2023-10-26 16:20:35.180511: Epoch time: 4.25 s 
2023-10-26 16:20:36.366645:  
2023-10-26 16:20:36.366961: Epoch 638 
2023-10-26 16:20:36.367208: Current learning rate: 0.00401 
2023-10-26 16:20:40.651405: train_loss -0.8678 
2023-10-26 16:20:40.651820: val_loss -0.8314 
2023-10-26 16:20:40.652080: Pseudo dice [0.8537, 0.9298, 0.9666, 0.7523, 0.9347] 
2023-10-26 16:20:40.652317: Epoch time: 4.29 s 
2023-10-26 16:20:41.812195:  
2023-10-26 16:20:41.812496: Epoch 639 
2023-10-26 16:20:41.812726: Current learning rate: 0.004 
2023-10-26 16:20:46.082990: train_loss -0.8912 
2023-10-26 16:20:46.083361: val_loss -0.7437 
2023-10-26 16:20:46.083615: Pseudo dice [0.8431, 0.9278, 0.9672, 0.399, 0.7732] 
2023-10-26 16:20:46.083852: Epoch time: 4.27 s 
2023-10-26 16:20:47.280011:  
2023-10-26 16:20:47.280373: Epoch 640 
2023-10-26 16:20:47.280692: Current learning rate: 0.00399 
2023-10-26 16:20:51.560585: train_loss -0.8912 
2023-10-26 16:20:51.561054: val_loss -0.7841 
2023-10-26 16:20:51.561415: Pseudo dice [0.8468, 0.9262, 0.9675, 0.6281, 0.911] 
2023-10-26 16:20:51.561784: Epoch time: 4.28 s 
2023-10-26 16:20:52.749159:  
2023-10-26 16:20:52.749472: Epoch 641 
2023-10-26 16:20:52.749715: Current learning rate: 0.00398 
2023-10-26 16:20:56.914296: train_loss -0.8952 
2023-10-26 16:20:56.914694: val_loss -0.7707 
2023-10-26 16:20:56.914953: Pseudo dice [0.836, 0.9179, 0.9648, 0.5885, 0.8738] 
2023-10-26 16:20:56.915187: Epoch time: 4.17 s 
2023-10-26 16:20:58.102723:  
2023-10-26 16:20:58.103028: Epoch 642 
2023-10-26 16:20:58.103273: Current learning rate: 0.00397 
2023-10-26 16:21:02.166939: train_loss -0.8724 
2023-10-26 16:21:02.167303: val_loss -0.8202 
2023-10-26 16:21:02.167556: Pseudo dice [0.8581, 0.9244, 0.9683, 0.6378, 0.9322] 
2023-10-26 16:21:02.167784: Epoch time: 4.06 s 
2023-10-26 16:21:03.536517:  
2023-10-26 16:21:03.536814: Epoch 643 
2023-10-26 16:21:03.537062: Current learning rate: 0.00396 
2023-10-26 16:21:07.597725: train_loss -0.8832 
2023-10-26 16:21:07.598135: val_loss -0.7365 
2023-10-26 16:21:07.598385: Pseudo dice [0.8289, 0.9215, 0.9659, 0.5934, 0.7515] 
2023-10-26 16:21:07.598616: Epoch time: 4.06 s 
2023-10-26 16:21:08.761724:  
2023-10-26 16:21:08.762016: Epoch 644 
2023-10-26 16:21:08.762280: Current learning rate: 0.00395 
2023-10-26 16:21:12.884606: train_loss -0.8929 
2023-10-26 16:21:12.885247: val_loss -0.7689 
2023-10-26 16:21:12.885538: Pseudo dice [0.8291, 0.9236, 0.968, 0.5537, 0.8238] 
2023-10-26 16:21:12.885829: Epoch time: 4.12 s 
2023-10-26 16:21:14.036841:  
2023-10-26 16:21:14.037157: Epoch 645 
2023-10-26 16:21:14.037416: Current learning rate: 0.00394 
2023-10-26 16:21:18.319409: train_loss -0.899 
2023-10-26 16:21:18.319805: val_loss -0.7799 
2023-10-26 16:21:18.320084: Pseudo dice [0.8388, 0.9232, 0.9665, 0.6453, 0.8187] 
2023-10-26 16:21:18.320321: Epoch time: 4.28 s 
2023-10-26 16:21:19.474977:  
2023-10-26 16:21:19.475279: Epoch 646 
2023-10-26 16:21:19.475528: Current learning rate: 0.00393 
2023-10-26 16:21:23.813206: train_loss -0.8981 
2023-10-26 16:21:23.813551: val_loss -0.7 
2023-10-26 16:21:23.813801: Pseudo dice [0.8457, 0.9298, 0.9666, 0.3746, 0.6711] 
2023-10-26 16:21:23.814036: Epoch time: 4.34 s 
2023-10-26 16:21:24.983745:  
2023-10-26 16:21:24.984088: Epoch 647 
2023-10-26 16:21:24.984364: Current learning rate: 0.00392 
2023-10-26 16:21:29.203468: train_loss -0.9026 
2023-10-26 16:21:29.203862: val_loss -0.6687 
2023-10-26 16:21:29.204199: Pseudo dice [0.8439, 0.9277, 0.9686, 0.4708, 0.6607] 
2023-10-26 16:21:29.204465: Epoch time: 4.22 s 
2023-10-26 16:21:30.352376:  
2023-10-26 16:21:30.352656: Epoch 648 
2023-10-26 16:21:30.352884: Current learning rate: 0.00391 
2023-10-26 16:21:34.590212: train_loss -0.9002 
2023-10-26 16:21:34.590741: val_loss -0.7805 
2023-10-26 16:21:34.591041: Pseudo dice [0.8335, 0.9215, 0.9665, 0.5552, 0.8176] 
2023-10-26 16:21:34.591292: Epoch time: 4.24 s 
2023-10-26 16:21:35.888733:  
2023-10-26 16:21:35.889055: Epoch 649 
2023-10-26 16:21:35.889307: Current learning rate: 0.0039 
2023-10-26 16:21:40.214810: train_loss -0.8994 
2023-10-26 16:21:40.215201: val_loss -0.6797 
2023-10-26 16:21:40.215451: Pseudo dice [0.8471, 0.9251, 0.9644, 0.4422, 0.6391] 
2023-10-26 16:21:40.215667: Epoch time: 4.33 s 
2023-10-26 16:21:41.465285:  
2023-10-26 16:21:41.465626: Epoch 650 
2023-10-26 16:21:41.465882: Current learning rate: 0.00389 
2023-10-26 16:21:45.711147: train_loss -0.8949 
2023-10-26 16:21:45.711499: val_loss -0.6587 
2023-10-26 16:21:45.711753: Pseudo dice [0.8414, 0.9258, 0.9654, 0.4308, 0.7156] 
2023-10-26 16:21:45.711996: Epoch time: 4.25 s 
2023-10-26 16:21:46.897625:  
2023-10-26 16:21:46.897935: Epoch 651 
2023-10-26 16:21:46.898186: Current learning rate: 0.00388 
2023-10-26 16:21:51.091636: train_loss -0.9029 
2023-10-26 16:21:51.092015: val_loss -0.7153 
2023-10-26 16:21:51.092273: Pseudo dice [0.8451, 0.9279, 0.9658, 0.6011, 0.7496] 
2023-10-26 16:21:51.092525: Epoch time: 4.19 s 
2023-10-26 16:21:52.242084:  
2023-10-26 16:21:52.242396: Epoch 652 
2023-10-26 16:21:52.242636: Current learning rate: 0.00387 
2023-10-26 16:21:56.489450: train_loss -0.8996 
2023-10-26 16:21:56.489830: val_loss -0.724 
2023-10-26 16:21:56.490109: Pseudo dice [0.821, 0.9218, 0.9678, 0.2954, 0.8305] 
2023-10-26 16:21:56.490354: Epoch time: 4.25 s 
2023-10-26 16:21:57.689579:  
2023-10-26 16:21:57.689898: Epoch 653 
2023-10-26 16:21:57.690158: Current learning rate: 0.00386 
2023-10-26 16:22:01.785176: train_loss -0.9011 
2023-10-26 16:22:01.785570: val_loss -0.7214 
2023-10-26 16:22:01.785831: Pseudo dice [0.8415, 0.9262, 0.9668, 0.4857, 0.7646] 
2023-10-26 16:22:01.786074: Epoch time: 4.1 s 
2023-10-26 16:22:02.968284:  
2023-10-26 16:22:02.968575: Epoch 654 
2023-10-26 16:22:02.968830: Current learning rate: 0.00385 
2023-10-26 16:22:07.056266: train_loss -0.8961 
2023-10-26 16:22:07.056626: val_loss -0.7124 
2023-10-26 16:22:07.056867: Pseudo dice [0.8264, 0.9233, 0.9669, 0.3681, 0.7997] 
2023-10-26 16:22:07.057115: Epoch time: 4.09 s 
2023-10-26 16:22:08.402586:  
2023-10-26 16:22:08.402894: Epoch 655 
2023-10-26 16:22:08.403153: Current learning rate: 0.00384 
2023-10-26 16:22:12.503743: train_loss -0.8974 
2023-10-26 16:22:12.504347: val_loss -0.7444 
2023-10-26 16:22:12.504622: Pseudo dice [0.8398, 0.927, 0.9692, 0.2934, 0.7632] 
2023-10-26 16:22:12.504842: Epoch time: 4.1 s 
2023-10-26 16:22:13.688351:  
2023-10-26 16:22:13.688653: Epoch 656 
2023-10-26 16:22:13.688900: Current learning rate: 0.00383 
2023-10-26 16:22:17.710536: train_loss -0.9043 
2023-10-26 16:22:17.710921: val_loss -0.7663 
2023-10-26 16:22:17.711183: Pseudo dice [0.8308, 0.9211, 0.9652, 0.5342, 0.838] 
2023-10-26 16:22:17.711401: Epoch time: 4.02 s 
2023-10-26 16:22:18.893103:  
2023-10-26 16:22:18.893407: Epoch 657 
2023-10-26 16:22:18.893659: Current learning rate: 0.00382 
2023-10-26 16:22:23.099428: train_loss -0.8913 
2023-10-26 16:22:23.099804: val_loss -0.6917 
2023-10-26 16:22:23.100068: Pseudo dice [0.8397, 0.9227, 0.9629, 0.374, 0.6575] 
2023-10-26 16:22:23.100300: Epoch time: 4.21 s 
2023-10-26 16:22:24.300579:  
2023-10-26 16:22:24.300891: Epoch 658 
2023-10-26 16:22:24.301144: Current learning rate: 0.00381 
2023-10-26 16:22:28.537920: train_loss -0.8939 
2023-10-26 16:22:28.538283: val_loss -0.768 
2023-10-26 16:22:28.538527: Pseudo dice [0.8267, 0.9216, 0.964, 0.5533, 0.864] 
2023-10-26 16:22:28.538761: Epoch time: 4.24 s 
2023-10-26 16:22:29.711825:  
2023-10-26 16:22:29.712169: Epoch 659 
2023-10-26 16:22:29.712440: Current learning rate: 0.0038 
2023-10-26 16:22:33.734864: train_loss -0.8972 
2023-10-26 16:22:33.735380: val_loss -0.7241 
2023-10-26 16:22:33.735682: Pseudo dice [0.8314, 0.9232, 0.9636, 0.4009, 0.7701] 
2023-10-26 16:22:33.735996: Epoch time: 4.02 s 
2023-10-26 16:22:34.936015:  
2023-10-26 16:22:34.936308: Epoch 660 
2023-10-26 16:22:34.936556: Current learning rate: 0.00379 
2023-10-26 16:22:39.190139: train_loss -0.8997 
2023-10-26 16:22:39.190691: val_loss -0.7573 
2023-10-26 16:22:39.191193: Pseudo dice [0.8205, 0.9226, 0.9661, 0.4448, 0.7856] 
2023-10-26 16:22:39.191616: Epoch time: 4.25 s 
2023-10-26 16:22:40.594443:  
2023-10-26 16:22:40.594759: Epoch 661 
2023-10-26 16:22:40.595041: Current learning rate: 0.00378 
2023-10-26 16:22:44.830648: train_loss -0.9025 
2023-10-26 16:22:44.831103: val_loss -0.7464 
2023-10-26 16:22:44.831367: Pseudo dice [0.8431, 0.9236, 0.9655, 0.5803, 0.6685] 
2023-10-26 16:22:44.831601: Epoch time: 4.24 s 
2023-10-26 16:22:46.048042:  
2023-10-26 16:22:46.048338: Epoch 662 
2023-10-26 16:22:46.048579: Current learning rate: 0.00377 
2023-10-26 16:22:50.282823: train_loss -0.9013 
2023-10-26 16:22:50.283209: val_loss -0.715 
2023-10-26 16:22:50.283464: Pseudo dice [0.8386, 0.9229, 0.9666, 0.4712, 0.7543] 
2023-10-26 16:22:50.283699: Epoch time: 4.24 s 
2023-10-26 16:22:51.447375:  
2023-10-26 16:22:51.447754: Epoch 663 
2023-10-26 16:22:51.448056: Current learning rate: 0.00376 
2023-10-26 16:22:55.672985: train_loss -0.8987 
2023-10-26 16:22:55.673361: val_loss -0.6913 
2023-10-26 16:22:55.673651: Pseudo dice [0.836, 0.9251, 0.968, 0.4011, 0.7217] 
2023-10-26 16:22:55.673909: Epoch time: 4.23 s 
2023-10-26 16:22:56.896985:  
2023-10-26 16:22:56.897280: Epoch 664 
2023-10-26 16:22:56.897537: Current learning rate: 0.00375 
2023-10-26 16:23:01.124364: train_loss -0.9011 
2023-10-26 16:23:01.124740: val_loss -0.6975 
2023-10-26 16:23:01.124999: Pseudo dice [0.843, 0.9268, 0.9671, 0.5646, 0.7197] 
2023-10-26 16:23:01.125218: Epoch time: 4.23 s 
2023-10-26 16:23:02.325630:  
2023-10-26 16:23:02.325918: Epoch 665 
2023-10-26 16:23:02.326164: Current learning rate: 0.00374 
2023-10-26 16:23:06.542284: train_loss -0.9016 
2023-10-26 16:23:06.542685: val_loss -0.6748 
2023-10-26 16:23:06.542946: Pseudo dice [0.8278, 0.926, 0.9672, 0.4057, 0.674] 
2023-10-26 16:23:06.543181: Epoch time: 4.22 s 
2023-10-26 16:23:07.731299:  
2023-10-26 16:23:07.731600: Epoch 666 
2023-10-26 16:23:07.731844: Current learning rate: 0.00373 
2023-10-26 16:23:12.037814: train_loss -0.8951 
2023-10-26 16:23:12.038181: val_loss -0.7583 
2023-10-26 16:23:12.038466: Pseudo dice [0.8303, 0.9238, 0.9661, 0.532, 0.8264] 
2023-10-26 16:23:12.038683: Epoch time: 4.31 s 
2023-10-26 16:23:13.184095:  
2023-10-26 16:23:13.184386: Epoch 667 
2023-10-26 16:23:13.184617: Current learning rate: 0.00372 
2023-10-26 16:23:17.558278: train_loss -0.8976 
2023-10-26 16:23:17.558671: val_loss -0.6656 
2023-10-26 16:23:17.558922: Pseudo dice [0.8358, 0.9272, 0.9661, 0.3246, 0.6239] 
2023-10-26 16:23:17.559152: Epoch time: 4.37 s 
2023-10-26 16:23:18.898373:  
2023-10-26 16:23:18.898662: Epoch 668 
2023-10-26 16:23:18.898899: Current learning rate: 0.00371 
2023-10-26 16:23:23.235977: train_loss -0.8992 
2023-10-26 16:23:23.236339: val_loss -0.7838 
2023-10-26 16:23:23.236591: Pseudo dice [0.8319, 0.9269, 0.9658, 0.502, 0.8665] 
2023-10-26 16:23:23.236811: Epoch time: 4.34 s 
2023-10-26 16:23:24.422174:  
2023-10-26 16:23:24.422523: Epoch 669 
2023-10-26 16:23:24.422828: Current learning rate: 0.0037 
2023-10-26 16:23:28.702554: train_loss -0.8997 
2023-10-26 16:23:28.702955: val_loss -0.6756 
2023-10-26 16:23:28.703215: Pseudo dice [0.8308, 0.923, 0.9669, 0.4054, 0.7319] 
2023-10-26 16:23:28.703453: Epoch time: 4.28 s 
2023-10-26 16:23:29.874137:  
2023-10-26 16:23:29.874438: Epoch 670 
2023-10-26 16:23:29.874692: Current learning rate: 0.00369 
2023-10-26 16:23:34.143738: train_loss -0.9004 
2023-10-26 16:23:34.144118: val_loss -0.6909 
2023-10-26 16:23:34.144363: Pseudo dice [0.8298, 0.9247, 0.9677, 0.229, 0.7925] 
2023-10-26 16:23:34.144597: Epoch time: 4.27 s 
2023-10-26 16:23:35.361451:  
2023-10-26 16:23:35.361775: Epoch 671 
2023-10-26 16:23:35.362016: Current learning rate: 0.00368 
2023-10-26 16:23:39.566588: train_loss -0.902 
2023-10-26 16:23:39.567103: val_loss -0.7033 
2023-10-26 16:23:39.567563: Pseudo dice [0.8312, 0.9274, 0.9658, 0.2971, 0.7236] 
2023-10-26 16:23:39.567955: Epoch time: 4.21 s 
2023-10-26 16:23:40.784464:  
2023-10-26 16:23:40.784766: Epoch 672 
2023-10-26 16:23:40.785135: Current learning rate: 0.00367 
2023-10-26 16:23:44.958359: train_loss -0.9044 
2023-10-26 16:23:44.958712: val_loss -0.7089 
2023-10-26 16:23:44.958968: Pseudo dice [0.8475, 0.9278, 0.9674, 0.6104, 0.7288] 
2023-10-26 16:23:44.959184: Epoch time: 4.17 s 
2023-10-26 16:23:46.140676:  
2023-10-26 16:23:46.140972: Epoch 673 
2023-10-26 16:23:46.141207: Current learning rate: 0.00366 
2023-10-26 16:23:50.264109: train_loss -0.91 
2023-10-26 16:23:50.264468: val_loss -0.6911 
2023-10-26 16:23:50.264724: Pseudo dice [0.8321, 0.9239, 0.9672, 0.4473, 0.6863] 
2023-10-26 16:23:50.264951: Epoch time: 4.12 s 
2023-10-26 16:23:51.626882:  
2023-10-26 16:23:51.627244: Epoch 674 
2023-10-26 16:23:51.627552: Current learning rate: 0.00365 
2023-10-26 16:23:55.861987: train_loss -0.9072 
2023-10-26 16:23:55.862363: val_loss -0.6851 
2023-10-26 16:23:55.862621: Pseudo dice [0.8235, 0.9247, 0.9662, 0.3179, 0.6885] 
2023-10-26 16:23:55.862853: Epoch time: 4.24 s 
2023-10-26 16:23:57.060516:  
2023-10-26 16:23:57.060820: Epoch 675 
2023-10-26 16:23:57.061057: Current learning rate: 0.00364 
2023-10-26 16:24:01.284792: train_loss -0.8993 
2023-10-26 16:24:01.285243: val_loss -0.6726 
2023-10-26 16:24:01.285539: Pseudo dice [0.8486, 0.9225, 0.9658, 0.3675, 0.7179] 
2023-10-26 16:24:01.285766: Epoch time: 4.22 s 
2023-10-26 16:24:02.458417:  
2023-10-26 16:24:02.458718: Epoch 676 
2023-10-26 16:24:02.458956: Current learning rate: 0.00363 
2023-10-26 16:24:06.649103: train_loss -0.8984 
2023-10-26 16:24:06.649469: val_loss -0.688 
2023-10-26 16:24:06.649725: Pseudo dice [0.842, 0.9292, 0.9683, 0.539, 0.6879] 
2023-10-26 16:24:06.649971: Epoch time: 4.19 s 
2023-10-26 16:24:07.832377:  
2023-10-26 16:24:07.832685: Epoch 677 
2023-10-26 16:24:07.832942: Current learning rate: 0.00362 
2023-10-26 16:24:12.103839: train_loss -0.9048 
2023-10-26 16:24:12.104297: val_loss -0.7534 
2023-10-26 16:24:12.104626: Pseudo dice [0.8342, 0.9265, 0.967, 0.5239, 0.7748] 
2023-10-26 16:24:12.104995: Epoch time: 4.27 s 
2023-10-26 16:24:13.289799:  
2023-10-26 16:24:13.290083: Epoch 678 
2023-10-26 16:24:13.290311: Current learning rate: 0.00361 
2023-10-26 16:24:17.531741: train_loss -0.8978 
2023-10-26 16:24:17.532111: val_loss -0.702 
2023-10-26 16:24:17.532370: Pseudo dice [0.8274, 0.9133, 0.9631, 0.343, 0.7525] 
2023-10-26 16:24:17.532603: Epoch time: 4.24 s 
2023-10-26 16:24:18.735011:  
2023-10-26 16:24:18.735313: Epoch 679 
2023-10-26 16:24:18.735556: Current learning rate: 0.0036 
2023-10-26 16:24:23.014061: train_loss -0.8859 
2023-10-26 16:24:23.014422: val_loss -0.6578 
2023-10-26 16:24:23.014688: Pseudo dice [0.8392, 0.9242, 0.9676, 0.3605, 0.6775] 
2023-10-26 16:24:23.014925: Epoch time: 4.28 s 
2023-10-26 16:24:24.368668:  
2023-10-26 16:24:24.368968: Epoch 680 
2023-10-26 16:24:24.369209: Current learning rate: 0.00359 
2023-10-26 16:24:28.718588: train_loss -0.8947 
2023-10-26 16:24:28.718999: val_loss -0.7582 
2023-10-26 16:24:28.719267: Pseudo dice [0.8365, 0.9197, 0.9662, 0.6999, 0.7925] 
2023-10-26 16:24:28.719499: Epoch time: 4.35 s 
2023-10-26 16:24:29.885397:  
2023-10-26 16:24:29.885685: Epoch 681 
2023-10-26 16:24:29.885938: Current learning rate: 0.00358 
2023-10-26 16:24:34.206485: train_loss -0.8938 
2023-10-26 16:24:34.220345: val_loss -0.6762 
2023-10-26 16:24:34.220718: Pseudo dice [0.8362, 0.921, 0.966, 0.2887, 0.7434] 
2023-10-26 16:24:34.221032: Epoch time: 4.32 s 
2023-10-26 16:24:35.383404:  
2023-10-26 16:24:35.383684: Epoch 682 
2023-10-26 16:24:35.383929: Current learning rate: 0.00357 
2023-10-26 16:24:39.701590: train_loss -0.8992 
2023-10-26 16:24:39.702009: val_loss -0.6928 
2023-10-26 16:24:39.702270: Pseudo dice [0.8346, 0.9252, 0.9659, 0.3919, 0.6684] 
2023-10-26 16:24:39.702521: Epoch time: 4.32 s 
2023-10-26 16:24:40.869032:  
2023-10-26 16:24:40.869376: Epoch 683 
2023-10-26 16:24:40.869699: Current learning rate: 0.00356 
2023-10-26 16:24:45.218680: train_loss -0.8968 
2023-10-26 16:24:45.219082: val_loss -0.749 
2023-10-26 16:24:45.219355: Pseudo dice [0.8481, 0.9314, 0.9665, 0.6175, 0.7819] 
2023-10-26 16:24:45.219595: Epoch time: 4.35 s 
2023-10-26 16:24:46.416256:  
2023-10-26 16:24:46.416566: Epoch 684 
2023-10-26 16:24:46.416818: Current learning rate: 0.00355 
2023-10-26 16:24:50.748447: train_loss -0.8936 
2023-10-26 16:24:50.748840: val_loss -0.6868 
2023-10-26 16:24:50.749096: Pseudo dice [0.8376, 0.9322, 0.9679, 0.386, 0.6551] 
2023-10-26 16:24:50.749329: Epoch time: 4.33 s 
2023-10-26 16:24:51.982194:  
2023-10-26 16:24:51.982492: Epoch 685 
2023-10-26 16:24:51.982738: Current learning rate: 0.00354 
2023-10-26 16:24:56.158201: train_loss -0.8988 
2023-10-26 16:24:56.158597: val_loss -0.6886 
2023-10-26 16:24:56.158885: Pseudo dice [0.8345, 0.924, 0.9661, 0.3644, 0.7057] 
2023-10-26 16:24:56.159133: Epoch time: 4.18 s 
2023-10-26 16:24:57.542119:  
2023-10-26 16:24:57.542431: Epoch 686 
2023-10-26 16:24:57.542676: Current learning rate: 0.00353 
2023-10-26 16:25:01.842015: train_loss -0.8983 
2023-10-26 16:25:01.842526: val_loss -0.7775 
2023-10-26 16:25:01.843030: Pseudo dice [0.844, 0.9232, 0.9677, 0.3393, 0.8772] 
2023-10-26 16:25:01.843356: Epoch time: 4.3 s 
2023-10-26 16:25:03.055430:  
2023-10-26 16:25:03.055724: Epoch 687 
2023-10-26 16:25:03.055965: Current learning rate: 0.00352 
2023-10-26 16:25:07.224944: train_loss -0.8935 
2023-10-26 16:25:07.225304: val_loss -0.6884 
2023-10-26 16:25:07.225562: Pseudo dice [0.8398, 0.921, 0.9652, 0.4473, 0.7302] 
2023-10-26 16:25:07.225787: Epoch time: 4.17 s 
2023-10-26 16:25:08.421340:  
2023-10-26 16:25:08.421646: Epoch 688 
2023-10-26 16:25:08.421889: Current learning rate: 0.00351 
2023-10-26 16:25:12.546770: train_loss -0.8881 
2023-10-26 16:25:12.547184: val_loss -0.7545 
2023-10-26 16:25:12.547482: Pseudo dice [0.8278, 0.9219, 0.9661, 0.5321, 0.7647] 
2023-10-26 16:25:12.547729: Epoch time: 4.13 s 
2023-10-26 16:25:13.744375:  
2023-10-26 16:25:13.744679: Epoch 689 
2023-10-26 16:25:13.744928: Current learning rate: 0.0035 
2023-10-26 16:25:17.900535: train_loss -0.8938 
2023-10-26 16:25:17.900904: val_loss -0.7451 
2023-10-26 16:25:17.901158: Pseudo dice [0.8476, 0.9263, 0.9656, 0.3984, 0.7813] 
2023-10-26 16:25:17.901384: Epoch time: 4.16 s 
2023-10-26 16:25:19.136831:  
2023-10-26 16:25:19.137213: Epoch 690 
2023-10-26 16:25:19.137464: Current learning rate: 0.00349 
2023-10-26 16:25:23.287744: train_loss -0.8978 
2023-10-26 16:25:23.288290: val_loss -0.7291 
2023-10-26 16:25:23.288676: Pseudo dice [0.8405, 0.9279, 0.9638, 0.4736, 0.7455] 
2023-10-26 16:25:23.288994: Epoch time: 4.15 s 
2023-10-26 16:25:24.483130:  
2023-10-26 16:25:24.483454: Epoch 691 
2023-10-26 16:25:24.483712: Current learning rate: 0.00348 
2023-10-26 16:25:28.554322: train_loss -0.8984 
2023-10-26 16:25:28.554722: val_loss -0.7418 
2023-10-26 16:25:28.554982: Pseudo dice [0.8518, 0.9275, 0.9663, 0.5249, 0.7647] 
2023-10-26 16:25:28.555214: Epoch time: 4.07 s 
2023-10-26 16:25:29.969828:  
2023-10-26 16:25:29.970198: Epoch 692 
2023-10-26 16:25:29.970521: Current learning rate: 0.00346 
2023-10-26 16:25:34.059476: train_loss -0.9037 
2023-10-26 16:25:34.059927: val_loss -0.7518 
2023-10-26 16:25:34.060349: Pseudo dice [0.8317, 0.9251, 0.9651, 0.4011, 0.8149] 
2023-10-26 16:25:34.060619: Epoch time: 4.09 s 
2023-10-26 16:25:35.291479:  
2023-10-26 16:25:35.291800: Epoch 693 
2023-10-26 16:25:35.292053: Current learning rate: 0.00345 
2023-10-26 16:25:39.394370: train_loss -0.8957 
2023-10-26 16:25:39.394947: val_loss -0.7229 
2023-10-26 16:25:39.395216: Pseudo dice [0.8338, 0.9281, 0.9651, 0.4472, 0.7624] 
2023-10-26 16:25:39.395559: Epoch time: 4.1 s 
2023-10-26 16:25:40.589386:  
2023-10-26 16:25:40.589693: Epoch 694 
2023-10-26 16:25:40.589951: Current learning rate: 0.00344 
2023-10-26 16:25:44.794555: train_loss -0.9059 
2023-10-26 16:25:44.795436: val_loss -0.795 
2023-10-26 16:25:44.796041: Pseudo dice [0.8426, 0.927, 0.9675, 0.3945, 0.8804] 
2023-10-26 16:25:44.796311: Epoch time: 4.21 s 
2023-10-26 16:25:46.013014:  
2023-10-26 16:25:46.013324: Epoch 695 
2023-10-26 16:25:46.013585: Current learning rate: 0.00343 
2023-10-26 16:25:50.237375: train_loss -0.903 
2023-10-26 16:25:50.237755: val_loss -0.7947 
2023-10-26 16:25:50.238032: Pseudo dice [0.841, 0.9286, 0.9672, 0.5097, 0.8626] 
2023-10-26 16:25:50.238427: Epoch time: 4.23 s 
2023-10-26 16:25:51.435540:  
2023-10-26 16:25:51.435838: Epoch 696 
2023-10-26 16:25:51.436074: Current learning rate: 0.00342 
2023-10-26 16:25:55.736257: train_loss -0.8906 
2023-10-26 16:25:55.736647: val_loss -0.6992 
2023-10-26 16:25:55.736913: Pseudo dice [0.8434, 0.9218, 0.9664, 0.0, 0.8364] 
2023-10-26 16:25:55.737150: Epoch time: 4.3 s 
2023-10-26 16:25:56.908992:  
2023-10-26 16:25:56.909286: Epoch 697 
2023-10-26 16:25:56.909536: Current learning rate: 0.00341 
2023-10-26 16:26:01.076663: train_loss -0.8913 
2023-10-26 16:26:01.077152: val_loss -0.7433 
2023-10-26 16:26:01.077483: Pseudo dice [0.8571, 0.9252, 0.968, 0.6159, 0.788] 
2023-10-26 16:26:01.077747: Epoch time: 4.17 s 
2023-10-26 16:26:02.447219:  
2023-10-26 16:26:02.447510: Epoch 698 
2023-10-26 16:26:02.447751: Current learning rate: 0.0034 
2023-10-26 16:26:06.875241: train_loss -0.8964 
2023-10-26 16:26:06.875616: val_loss -0.6776 
2023-10-26 16:26:06.875862: Pseudo dice [0.8337, 0.9217, 0.9661, 0.1332, 0.7229] 
2023-10-26 16:26:06.876092: Epoch time: 4.43 s 
2023-10-26 16:26:08.062891:  
2023-10-26 16:26:08.063235: Epoch 699 
2023-10-26 16:26:08.063530: Current learning rate: 0.00339 
2023-10-26 16:26:12.406684: train_loss -0.8948 
2023-10-26 16:26:12.407162: val_loss -0.6734 
2023-10-26 16:26:12.407524: Pseudo dice [0.8398, 0.9232, 0.9636, 0.2344, 0.7815] 
2023-10-26 16:26:12.407818: Epoch time: 4.34 s 
2023-10-26 16:26:13.763265:  
2023-10-26 16:26:13.763584: Epoch 700 
2023-10-26 16:26:13.763862: Current learning rate: 0.00338 
2023-10-26 16:26:18.046833: train_loss -0.9003 
2023-10-26 16:26:18.047253: val_loss -0.721 
2023-10-26 16:26:18.047566: Pseudo dice [0.8196, 0.9209, 0.9646, 0.2509, 0.8349] 
2023-10-26 16:26:18.047807: Epoch time: 4.28 s 
2023-10-26 16:26:19.257097:  
2023-10-26 16:26:19.257402: Epoch 701 
2023-10-26 16:26:19.257647: Current learning rate: 0.00337 
2023-10-26 16:26:23.506758: train_loss -0.8965 
2023-10-26 16:26:23.507154: val_loss -0.6635 
2023-10-26 16:26:23.507421: Pseudo dice [0.8346, 0.9239, 0.9639, 0.2717, 0.6659] 
2023-10-26 16:26:23.507677: Epoch time: 4.25 s 
2023-10-26 16:26:24.704601:  
2023-10-26 16:26:24.704926: Epoch 702 
2023-10-26 16:26:24.705242: Current learning rate: 0.00336 
2023-10-26 16:26:29.103463: train_loss -0.8957 
2023-10-26 16:26:29.103830: val_loss -0.7557 
2023-10-26 16:26:29.104088: Pseudo dice [0.8241, 0.9315, 0.9676, 0.506, 0.8408] 
2023-10-26 16:26:29.104317: Epoch time: 4.4 s 
2023-10-26 16:26:30.291367:  
2023-10-26 16:26:30.291664: Epoch 703 
2023-10-26 16:26:30.291935: Current learning rate: 0.00335 
2023-10-26 16:26:34.566190: train_loss -0.9011 
2023-10-26 16:26:34.566582: val_loss -0.7234 
2023-10-26 16:26:34.566832: Pseudo dice [0.8448, 0.9264, 0.9639, 0.5299, 0.7865] 
2023-10-26 16:26:34.567074: Epoch time: 4.28 s 
2023-10-26 16:26:35.773563:  
2023-10-26 16:26:35.773855: Epoch 704 
2023-10-26 16:26:35.774101: Current learning rate: 0.00334 
2023-10-26 16:26:40.013487: train_loss -0.9029 
2023-10-26 16:26:40.013866: val_loss -0.6866 
2023-10-26 16:26:40.014122: Pseudo dice [0.8347, 0.926, 0.964, 0.2931, 0.7597] 
2023-10-26 16:26:40.014344: Epoch time: 4.24 s 
2023-10-26 16:26:41.394293:  
2023-10-26 16:26:41.394604: Epoch 705 
2023-10-26 16:26:41.394848: Current learning rate: 0.00333 
2023-10-26 16:26:45.727124: train_loss -0.9012 
2023-10-26 16:26:45.727488: val_loss -0.7001 
2023-10-26 16:26:45.727740: Pseudo dice [0.8286, 0.9282, 0.9667, 0.3055, 0.7134] 
2023-10-26 16:26:45.727966: Epoch time: 4.33 s 
2023-10-26 16:26:46.936397:  
2023-10-26 16:26:46.936801: Epoch 706 
2023-10-26 16:26:46.937077: Current learning rate: 0.00332 
2023-10-26 16:26:51.226592: train_loss -0.8953 
2023-10-26 16:26:51.227011: val_loss -0.6824 
2023-10-26 16:26:51.227275: Pseudo dice [0.8337, 0.9274, 0.9682, 0.1881, 0.7619] 
2023-10-26 16:26:51.227515: Epoch time: 4.29 s 
2023-10-26 16:26:52.421268:  
2023-10-26 16:26:52.421565: Epoch 707 
2023-10-26 16:26:52.421802: Current learning rate: 0.00331 
2023-10-26 16:26:56.647015: train_loss -0.9053 
2023-10-26 16:26:56.647366: val_loss -0.7088 
2023-10-26 16:26:56.647619: Pseudo dice [0.8386, 0.9278, 0.9667, 0.4455, 0.7946] 
2023-10-26 16:26:56.647844: Epoch time: 4.23 s 
2023-10-26 16:26:57.827144:  
2023-10-26 16:26:57.827454: Epoch 708 
2023-10-26 16:26:57.827696: Current learning rate: 0.0033 
2023-10-26 16:27:02.174095: train_loss -0.9023 
2023-10-26 16:27:02.174487: val_loss -0.7327 
2023-10-26 16:27:02.174895: Pseudo dice [0.8342, 0.9228, 0.9659, 0.6273, 0.8019] 
2023-10-26 16:27:02.175210: Epoch time: 4.35 s 
2023-10-26 16:27:03.390199:  
2023-10-26 16:27:03.390490: Epoch 709 
2023-10-26 16:27:03.390742: Current learning rate: 0.00329 
2023-10-26 16:27:07.555631: train_loss -0.8784 
2023-10-26 16:27:07.556028: val_loss -0.6703 
2023-10-26 16:27:07.556286: Pseudo dice [0.8402, 0.9205, 0.9649, 0.0, 0.769] 
2023-10-26 16:27:07.556514: Epoch time: 4.17 s 
2023-10-26 16:27:08.751019:  
2023-10-26 16:27:08.751323: Epoch 710 
2023-10-26 16:27:08.751572: Current learning rate: 0.00328 
2023-10-26 16:27:13.104589: train_loss -0.8876 
2023-10-26 16:27:13.104990: val_loss -0.7539 
2023-10-26 16:27:13.105255: Pseudo dice [0.8163, 0.9207, 0.9649, 0.6046, 0.7833] 
2023-10-26 16:27:13.105490: Epoch time: 4.35 s 
2023-10-26 16:27:14.441242:  
2023-10-26 16:27:14.441559: Epoch 711 
2023-10-26 16:27:14.441824: Current learning rate: 0.00327 
2023-10-26 16:27:18.808241: train_loss -0.8877 
2023-10-26 16:27:18.808702: val_loss -0.7531 
2023-10-26 16:27:18.809023: Pseudo dice [0.83, 0.9184, 0.965, 0.6477, 0.8341] 
2023-10-26 16:27:18.809282: Epoch time: 4.37 s 
2023-10-26 16:27:19.979074:  
2023-10-26 16:27:19.979378: Epoch 712 
2023-10-26 16:27:19.979627: Current learning rate: 0.00326 
2023-10-26 16:27:24.276000: train_loss -0.8858 
2023-10-26 16:27:24.276387: val_loss -0.7734 
2023-10-26 16:27:24.276660: Pseudo dice [0.8222, 0.9273, 0.9644, 0.5635, 0.7828] 
2023-10-26 16:27:24.276909: Epoch time: 4.3 s 
2023-10-26 16:27:25.465541:  
2023-10-26 16:27:25.465896: Epoch 713 
2023-10-26 16:27:25.466162: Current learning rate: 0.00325 
2023-10-26 16:27:29.639331: train_loss -0.8879 
2023-10-26 16:27:29.639713: val_loss -0.8125 
2023-10-26 16:27:29.639985: Pseudo dice [0.8471, 0.9266, 0.9639, 0.6072, 0.8669] 
2023-10-26 16:27:29.640225: Epoch time: 4.17 s 
2023-10-26 16:27:30.869094:  
2023-10-26 16:27:30.869409: Epoch 714 
2023-10-26 16:27:30.869661: Current learning rate: 0.00324 
2023-10-26 16:27:34.995392: train_loss -0.8999 
2023-10-26 16:27:34.995740: val_loss -0.7842 
2023-10-26 16:27:34.995987: Pseudo dice [0.8487, 0.9252, 0.9651, 0.5342, 0.7852] 
2023-10-26 16:27:34.996203: Epoch time: 4.13 s 
2023-10-26 16:27:36.194973:  
2023-10-26 16:27:36.195253: Epoch 715 
2023-10-26 16:27:36.195490: Current learning rate: 0.00323 
2023-10-26 16:27:40.304296: train_loss -0.8981 
2023-10-26 16:27:40.304795: val_loss -0.7574 
2023-10-26 16:27:40.305073: Pseudo dice [0.8498, 0.9262, 0.9667, 0.6252, 0.7806] 
2023-10-26 16:27:40.305303: Epoch time: 4.11 s 
2023-10-26 16:27:41.533207:  
2023-10-26 16:27:41.533506: Epoch 716 
2023-10-26 16:27:41.533754: Current learning rate: 0.00322 
2023-10-26 16:27:45.798777: train_loss -0.8974 
2023-10-26 16:27:45.799167: val_loss -0.7876 
2023-10-26 16:27:45.799524: Pseudo dice [0.8373, 0.9262, 0.965, 0.5932, 0.8027] 
2023-10-26 16:27:45.799759: Epoch time: 4.27 s 
2023-10-26 16:27:47.201190:  
2023-10-26 16:27:47.201586: Epoch 717 
2023-10-26 16:27:47.201852: Current learning rate: 0.00321 
2023-10-26 16:27:51.466472: train_loss -0.885 
2023-10-26 16:27:51.466875: val_loss -0.7155 
2023-10-26 16:27:51.467141: Pseudo dice [0.8338, 0.9225, 0.9624, 0.3894, 0.7965] 
2023-10-26 16:27:51.467396: Epoch time: 4.27 s 
2023-10-26 16:27:52.711662:  
2023-10-26 16:27:52.712240: Epoch 718 
2023-10-26 16:27:52.712534: Current learning rate: 0.0032 
2023-10-26 16:27:56.929116: train_loss -0.8802 
2023-10-26 16:27:56.929483: val_loss -0.7614 
2023-10-26 16:27:56.929742: Pseudo dice [0.8244, 0.924, 0.9649, 0.3015, 0.8603] 
2023-10-26 16:27:56.929985: Epoch time: 4.22 s 
2023-10-26 16:27:58.154598:  
2023-10-26 16:27:58.154952: Epoch 719 
2023-10-26 16:27:58.155242: Current learning rate: 0.00319 
2023-10-26 16:28:02.314549: train_loss -0.8943 
2023-10-26 16:28:02.315061: val_loss -0.7447 
2023-10-26 16:28:02.315328: Pseudo dice [0.8434, 0.9298, 0.966, 0.2683, 0.8362] 
2023-10-26 16:28:02.315569: Epoch time: 4.16 s 
2023-10-26 16:28:03.501128:  
2023-10-26 16:28:03.501436: Epoch 720 
2023-10-26 16:28:03.501684: Current learning rate: 0.00318 
2023-10-26 16:28:07.491386: train_loss -0.8982 
2023-10-26 16:28:07.491787: val_loss -0.7018 
2023-10-26 16:28:07.492077: Pseudo dice [0.8417, 0.9247, 0.9655, 0.3292, 0.6265] 
2023-10-26 16:28:07.492375: Epoch time: 3.99 s 
2023-10-26 16:28:08.694322:  
2023-10-26 16:28:08.694623: Epoch 721 
2023-10-26 16:28:08.694870: Current learning rate: 0.00317 
2023-10-26 16:28:13.021125: train_loss -0.9 
2023-10-26 16:28:13.021490: val_loss -0.7674 
2023-10-26 16:28:13.021740: Pseudo dice [0.8343, 0.9263, 0.9649, 0.3476, 0.8449] 
2023-10-26 16:28:13.021980: Epoch time: 4.33 s 
2023-10-26 16:28:14.398703:  
2023-10-26 16:28:14.399836: Epoch 722 
2023-10-26 16:28:14.400081: Current learning rate: 0.00316 
2023-10-26 16:28:18.506325: train_loss -0.9009 
2023-10-26 16:28:18.506742: val_loss -0.6975 
2023-10-26 16:28:18.507024: Pseudo dice [0.8397, 0.9231, 0.964, 0.2029, 0.7307] 
2023-10-26 16:28:18.507269: Epoch time: 4.11 s 
2023-10-26 16:28:19.909419:  
2023-10-26 16:28:19.909771: Epoch 723 
2023-10-26 16:28:19.910071: Current learning rate: 0.00315 
2023-10-26 16:28:24.038705: train_loss -0.904 
2023-10-26 16:28:24.039123: val_loss -0.7323 
2023-10-26 16:28:24.039379: Pseudo dice [0.8386, 0.9212, 0.9639, 0.2901, 0.8023] 
2023-10-26 16:28:24.039606: Epoch time: 4.13 s 
2023-10-26 16:28:25.245286:  
2023-10-26 16:28:25.245645: Epoch 724 
2023-10-26 16:28:25.245905: Current learning rate: 0.00314 
2023-10-26 16:28:29.506465: train_loss -0.9007 
2023-10-26 16:28:29.506854: val_loss -0.7598 
2023-10-26 16:28:29.507119: Pseudo dice [0.8306, 0.9275, 0.9664, 0.6698, 0.7164] 
2023-10-26 16:28:29.507346: Epoch time: 4.26 s 
2023-10-26 16:28:30.712150:  
2023-10-26 16:28:30.712453: Epoch 725 
2023-10-26 16:28:30.712699: Current learning rate: 0.00313 
2023-10-26 16:28:34.875629: train_loss -0.9 
2023-10-26 16:28:34.876010: val_loss -0.704 
2023-10-26 16:28:34.876264: Pseudo dice [0.8221, 0.9198, 0.9607, 0.4551, 0.7466] 
2023-10-26 16:28:34.876498: Epoch time: 4.16 s 
2023-10-26 16:28:36.105385:  
2023-10-26 16:28:36.105684: Epoch 726 
2023-10-26 16:28:36.105985: Current learning rate: 0.00312 
2023-10-26 16:28:40.189181: train_loss -0.9011 
2023-10-26 16:28:40.189555: val_loss -0.8101 
2023-10-26 16:28:40.189816: Pseudo dice [0.8514, 0.9318, 0.9661, 0.5799, 0.887] 
2023-10-26 16:28:40.190070: Epoch time: 4.08 s 
2023-10-26 16:28:41.476827:  
2023-10-26 16:28:41.477195: Epoch 727 
2023-10-26 16:28:41.477452: Current learning rate: 0.00311 
2023-10-26 16:28:45.618756: train_loss -0.9035 
2023-10-26 16:28:45.619218: val_loss -0.7623 
2023-10-26 16:28:45.619526: Pseudo dice [0.8368, 0.9254, 0.961, 0.279, 0.8364] 
2023-10-26 16:28:45.619793: Epoch time: 4.14 s 
2023-10-26 16:28:46.811760:  
2023-10-26 16:28:46.812060: Epoch 728 
2023-10-26 16:28:46.812307: Current learning rate: 0.0031 
2023-10-26 16:28:50.884882: train_loss -0.8994 
2023-10-26 16:28:50.885258: val_loss -0.7887 
2023-10-26 16:28:50.885516: Pseudo dice [0.8314, 0.9234, 0.9669, 0.5751, 0.8197] 
2023-10-26 16:28:50.885765: Epoch time: 4.07 s 
2023-10-26 16:28:52.372565:  
2023-10-26 16:28:52.372879: Epoch 729 
2023-10-26 16:28:52.373129: Current learning rate: 0.00309 
2023-10-26 16:28:56.667749: train_loss -0.9048 
2023-10-26 16:28:56.668164: val_loss -0.772 
2023-10-26 16:28:56.668429: Pseudo dice [0.8318, 0.9248, 0.9669, 0.563, 0.7826] 
2023-10-26 16:28:56.668667: Epoch time: 4.3 s 
2023-10-26 16:28:57.864620:  
2023-10-26 16:28:57.864921: Epoch 730 
2023-10-26 16:28:57.865172: Current learning rate: 0.00308 
2023-10-26 16:29:02.178254: train_loss -0.9034 
2023-10-26 16:29:02.178681: val_loss -0.7048 
2023-10-26 16:29:02.178942: Pseudo dice [0.8447, 0.9258, 0.9661, 0.4401, 0.7563] 
2023-10-26 16:29:02.179173: Epoch time: 4.31 s 
2023-10-26 16:29:03.418524:  
2023-10-26 16:29:03.418828: Epoch 731 
2023-10-26 16:29:03.419147: Current learning rate: 0.00307 
2023-10-26 16:29:07.646240: train_loss -0.9043 
2023-10-26 16:29:07.646694: val_loss -0.7395 
2023-10-26 16:29:07.647219: Pseudo dice [0.8357, 0.929, 0.964, 0.4014, 0.8095] 
2023-10-26 16:29:07.647629: Epoch time: 4.23 s 
2023-10-26 16:29:08.882990:  
2023-10-26 16:29:08.883283: Epoch 732 
2023-10-26 16:29:08.883536: Current learning rate: 0.00306 
2023-10-26 16:29:13.172598: train_loss -0.9029 
2023-10-26 16:29:13.172960: val_loss -0.701 
2023-10-26 16:29:13.173219: Pseudo dice [0.829, 0.9237, 0.9651, 0.6066, 0.6871] 
2023-10-26 16:29:13.173446: Epoch time: 4.29 s 
2023-10-26 16:29:14.355336:  
2023-10-26 16:29:14.355644: Epoch 733 
2023-10-26 16:29:14.355901: Current learning rate: 0.00305 
2023-10-26 16:29:18.666571: train_loss -0.8983 
2023-10-26 16:29:18.666955: val_loss -0.7199 
2023-10-26 16:29:18.667228: Pseudo dice [0.8367, 0.926, 0.9657, 0.5207, 0.7483] 
2023-10-26 16:29:18.667523: Epoch time: 4.31 s 
2023-10-26 16:29:19.904824:  
2023-10-26 16:29:19.905132: Epoch 734 
2023-10-26 16:29:19.905374: Current learning rate: 0.00304 
2023-10-26 16:29:24.163486: train_loss -0.9064 
2023-10-26 16:29:24.163902: val_loss -0.7385 
2023-10-26 16:29:24.164167: Pseudo dice [0.8314, 0.9263, 0.9661, 0.4871, 0.7864] 
2023-10-26 16:29:24.164423: Epoch time: 4.26 s 
2023-10-26 16:29:25.381320:  
2023-10-26 16:29:25.381631: Epoch 735 
2023-10-26 16:29:25.381905: Current learning rate: 0.00303 
2023-10-26 16:29:29.669941: train_loss -0.9015 
2023-10-26 16:29:29.670330: val_loss -0.6837 
2023-10-26 16:29:29.670594: Pseudo dice [0.8324, 0.9245, 0.9646, 0.3048, 0.6715] 
2023-10-26 16:29:29.670838: Epoch time: 4.29 s 
2023-10-26 16:29:31.017310:  
2023-10-26 16:29:31.017621: Epoch 736 
2023-10-26 16:29:31.017869: Current learning rate: 0.00302 
2023-10-26 16:29:35.290178: train_loss -0.9029 
2023-10-26 16:29:35.290599: val_loss -0.7645 
2023-10-26 16:29:35.290864: Pseudo dice [0.8518, 0.9261, 0.9642, 0.5635, 0.7323] 
2023-10-26 16:29:35.291126: Epoch time: 4.27 s 
2023-10-26 16:29:36.499130:  
2023-10-26 16:29:36.499449: Epoch 737 
2023-10-26 16:29:36.499718: Current learning rate: 0.00301 
2023-10-26 16:29:40.651676: train_loss -0.8996 
2023-10-26 16:29:40.652175: val_loss -0.7665 
2023-10-26 16:29:40.652582: Pseudo dice [0.8406, 0.9288, 0.9671, 0.5479, 0.7887] 
2023-10-26 16:29:40.653140: Epoch time: 4.15 s 
2023-10-26 16:29:41.960380:  
2023-10-26 16:29:41.960685: Epoch 738 
2023-10-26 16:29:41.960942: Current learning rate: 0.003 
2023-10-26 16:29:46.051545: train_loss -0.9052 
2023-10-26 16:29:46.052000: val_loss -0.7673 
2023-10-26 16:29:46.052391: Pseudo dice [0.8459, 0.9274, 0.9671, 0.6566, 0.8025] 
2023-10-26 16:29:46.052696: Epoch time: 4.09 s 
2023-10-26 16:29:47.255968:  
2023-10-26 16:29:47.256272: Epoch 739 
2023-10-26 16:29:47.256537: Current learning rate: 0.00299 
2023-10-26 16:29:51.526273: train_loss -0.9099 
2023-10-26 16:29:51.526689: val_loss -0.7309 
2023-10-26 16:29:51.526944: Pseudo dice [0.8453, 0.9283, 0.9668, 0.5475, 0.7091] 
2023-10-26 16:29:51.527168: Epoch time: 4.27 s 
2023-10-26 16:29:52.763233:  
2023-10-26 16:29:52.763547: Epoch 740 
2023-10-26 16:29:52.763792: Current learning rate: 0.00297 
2023-10-26 16:29:57.047757: train_loss -0.8988 
2023-10-26 16:29:57.048133: val_loss -0.804 
2023-10-26 16:29:57.048393: Pseudo dice [0.8523, 0.9262, 0.9653, 0.601, 0.8478] 
2023-10-26 16:29:57.048633: Epoch time: 4.29 s 
2023-10-26 16:29:58.280521:  
2023-10-26 16:29:58.280929: Epoch 741 
2023-10-26 16:29:58.281181: Current learning rate: 0.00296 
2023-10-26 16:30:02.575353: train_loss -0.9057 
2023-10-26 16:30:02.575700: val_loss -0.7035 
2023-10-26 16:30:02.575949: Pseudo dice [0.8456, 0.9266, 0.9648, 0.4831, 0.6583] 
2023-10-26 16:30:02.576178: Epoch time: 4.3 s 
2023-10-26 16:30:03.986786:  
2023-10-26 16:30:03.987147: Epoch 742 
2023-10-26 16:30:03.987467: Current learning rate: 0.00295 
2023-10-26 16:30:08.259339: train_loss -0.9106 
2023-10-26 16:30:08.259708: val_loss -0.7153 
2023-10-26 16:30:08.259966: Pseudo dice [0.8353, 0.9247, 0.9623, 0.5116, 0.6623] 
2023-10-26 16:30:08.260199: Epoch time: 4.27 s 
2023-10-26 16:30:09.441298:  
2023-10-26 16:30:09.441606: Epoch 743 
2023-10-26 16:30:09.441843: Current learning rate: 0.00294 
2023-10-26 16:30:13.697533: train_loss -0.9041 
2023-10-26 16:30:13.697917: val_loss -0.7046 
2023-10-26 16:30:13.698225: Pseudo dice [0.8328, 0.9252, 0.9636, 0.2626, 0.7664] 
2023-10-26 16:30:13.698487: Epoch time: 4.26 s 
2023-10-26 16:30:14.897703:  
2023-10-26 16:30:14.898001: Epoch 744 
2023-10-26 16:30:14.898237: Current learning rate: 0.00293 
2023-10-26 16:30:19.131346: train_loss -0.9002 
2023-10-26 16:30:19.131705: val_loss -0.7059 
2023-10-26 16:30:19.131973: Pseudo dice [0.852, 0.9246, 0.9644, 0.4253, 0.776] 
2023-10-26 16:30:19.132226: Epoch time: 4.23 s 
2023-10-26 16:30:20.327553:  
2023-10-26 16:30:20.327843: Epoch 745 
2023-10-26 16:30:20.328086: Current learning rate: 0.00292 
2023-10-26 16:30:24.663938: train_loss -0.8975 
2023-10-26 16:30:24.664303: val_loss -0.7728 
2023-10-26 16:30:24.664553: Pseudo dice [0.8441, 0.9272, 0.9677, 0.4942, 0.8336] 
2023-10-26 16:30:24.664775: Epoch time: 4.34 s 
2023-10-26 16:30:25.881004:  
2023-10-26 16:30:25.881299: Epoch 746 
2023-10-26 16:30:25.881532: Current learning rate: 0.00291 
2023-10-26 16:30:30.124672: train_loss -0.8972 
2023-10-26 16:30:30.125101: val_loss -0.723 
2023-10-26 16:30:30.125355: Pseudo dice [0.8413, 0.9281, 0.9665, 0.5171, 0.6328] 
2023-10-26 16:30:30.125582: Epoch time: 4.24 s 
2023-10-26 16:30:31.371914:  
2023-10-26 16:30:31.372227: Epoch 747 
2023-10-26 16:30:31.372480: Current learning rate: 0.0029 
2023-10-26 16:30:35.661462: train_loss -0.9037 
2023-10-26 16:30:35.661856: val_loss -0.6662 
2023-10-26 16:30:35.662118: Pseudo dice [0.8243, 0.9241, 0.9669, 0.2004, 0.6763] 
2023-10-26 16:30:35.662348: Epoch time: 4.29 s 
2023-10-26 16:30:37.064464:  
2023-10-26 16:30:37.064755: Epoch 748 
2023-10-26 16:30:37.065005: Current learning rate: 0.00289 
2023-10-26 16:30:41.266760: train_loss -0.9084 
2023-10-26 16:30:41.267187: val_loss -0.7355 
2023-10-26 16:30:41.267463: Pseudo dice [0.8393, 0.9276, 0.9672, 0.5173, 0.755] 
2023-10-26 16:30:41.267838: Epoch time: 4.2 s 
2023-10-26 16:30:42.454368:  
2023-10-26 16:30:42.454665: Epoch 749 
2023-10-26 16:30:42.454915: Current learning rate: 0.00288 
2023-10-26 16:30:46.523353: train_loss -0.9093 
2023-10-26 16:30:46.523727: val_loss -0.7366 
2023-10-26 16:30:46.523969: Pseudo dice [0.8376, 0.9295, 0.966, 0.3955, 0.7674] 
2023-10-26 16:30:46.524197: Epoch time: 4.07 s 
2023-10-26 16:30:47.826644:  
2023-10-26 16:30:47.826952: Epoch 750 
2023-10-26 16:30:47.827194: Current learning rate: 0.00287 
2023-10-26 16:30:52.161466: train_loss -0.9088 
2023-10-26 16:30:52.161845: val_loss -0.7586 
2023-10-26 16:30:52.162104: Pseudo dice [0.829, 0.9252, 0.9672, 0.5451, 0.8233] 
2023-10-26 16:30:52.162333: Epoch time: 4.34 s 
2023-10-26 16:30:53.336725:  
2023-10-26 16:30:53.337077: Epoch 751 
2023-10-26 16:30:53.337352: Current learning rate: 0.00286 
2023-10-26 16:30:57.641387: train_loss -0.9091 
2023-10-26 16:30:57.641779: val_loss -0.7553 
2023-10-26 16:30:57.642045: Pseudo dice [0.8399, 0.9229, 0.9666, 0.6594, 0.7956] 
2023-10-26 16:30:57.642283: Epoch time: 4.31 s 
2023-10-26 16:30:58.827529:  
2023-10-26 16:30:58.827853: Epoch 752 
2023-10-26 16:30:58.828117: Current learning rate: 0.00285 
2023-10-26 16:31:03.186465: train_loss -0.9081 
2023-10-26 16:31:03.186882: val_loss -0.67 
2023-10-26 16:31:03.187157: Pseudo dice [0.8454, 0.9285, 0.9671, 0.4127, 0.7156] 
2023-10-26 16:31:03.187433: Epoch time: 4.36 s 
2023-10-26 16:31:04.399595:  
2023-10-26 16:31:04.399894: Epoch 753 
2023-10-26 16:31:04.400147: Current learning rate: 0.00284 
2023-10-26 16:31:08.779625: train_loss -0.8961 
2023-10-26 16:31:08.779973: val_loss -0.77 
2023-10-26 16:31:08.780226: Pseudo dice [0.8409, 0.9294, 0.9669, 0.5002, 0.7372] 
2023-10-26 16:31:08.780441: Epoch time: 4.38 s 
2023-10-26 16:31:10.164520:  
2023-10-26 16:31:10.164833: Epoch 754 
2023-10-26 16:31:10.165092: Current learning rate: 0.00283 
2023-10-26 16:31:14.380697: train_loss -0.9039 
2023-10-26 16:31:14.381123: val_loss -0.7277 
2023-10-26 16:31:14.381380: Pseudo dice [0.8417, 0.9205, 0.9643, 0.507, 0.7673] 
2023-10-26 16:31:14.381632: Epoch time: 4.22 s 
2023-10-26 16:31:15.582000:  
2023-10-26 16:31:15.582298: Epoch 755 
2023-10-26 16:31:15.582543: Current learning rate: 0.00282 
2023-10-26 16:31:19.512571: train_loss -0.9029 
2023-10-26 16:31:19.512962: val_loss -0.7784 
2023-10-26 16:31:19.513217: Pseudo dice [0.8369, 0.9248, 0.9637, 0.5209, 0.8628] 
2023-10-26 16:31:19.513448: Epoch time: 3.93 s 
2023-10-26 16:31:20.716962:  
2023-10-26 16:31:20.717290: Epoch 756 
2023-10-26 16:31:20.717539: Current learning rate: 0.00281 
2023-10-26 16:31:24.861370: train_loss -0.9102 
2023-10-26 16:31:24.861778: val_loss -0.7002 
2023-10-26 16:31:24.862054: Pseudo dice [0.8142, 0.9174, 0.9647, 0.1847, 0.709] 
2023-10-26 16:31:24.862318: Epoch time: 4.14 s 
2023-10-26 16:31:26.124206:  
2023-10-26 16:31:26.124511: Epoch 757 
2023-10-26 16:31:26.124744: Current learning rate: 0.0028 
2023-10-26 16:31:30.248506: train_loss -0.8991 
2023-10-26 16:31:30.248928: val_loss -0.6882 
2023-10-26 16:31:30.249191: Pseudo dice [0.8426, 0.9263, 0.9643, 0.5971, 0.6936] 
2023-10-26 16:31:30.249437: Epoch time: 4.12 s 
2023-10-26 16:31:31.465494:  
2023-10-26 16:31:31.465861: Epoch 758 
2023-10-26 16:31:31.466140: Current learning rate: 0.00279 
2023-10-26 16:31:35.774137: train_loss -0.9002 
2023-10-26 16:31:35.774532: val_loss -0.7116 
2023-10-26 16:31:35.774820: Pseudo dice [0.8475, 0.9269, 0.9667, 0.4074, 0.7048] 
2023-10-26 16:31:35.775060: Epoch time: 4.31 s 
2023-10-26 16:31:37.023304:  
2023-10-26 16:31:37.023610: Epoch 759 
2023-10-26 16:31:37.023855: Current learning rate: 0.00278 
2023-10-26 16:31:41.234444: train_loss -0.9062 
2023-10-26 16:31:41.234835: val_loss -0.7653 
2023-10-26 16:31:41.235138: Pseudo dice [0.8356, 0.9242, 0.9669, 0.4807, 0.8357] 
2023-10-26 16:31:41.235453: Epoch time: 4.21 s 
2023-10-26 16:31:42.704712:  
2023-10-26 16:31:42.705015: Epoch 760 
2023-10-26 16:31:42.705271: Current learning rate: 0.00277 
2023-10-26 16:31:46.776318: train_loss -0.9067 
2023-10-26 16:31:46.776684: val_loss -0.7919 
2023-10-26 16:31:46.776936: Pseudo dice [0.835, 0.9183, 0.9637, 0.5895, 0.8211] 
2023-10-26 16:31:46.777293: Epoch time: 4.07 s 
2023-10-26 16:31:47.979888:  
2023-10-26 16:31:47.980194: Epoch 761 
2023-10-26 16:31:47.980435: Current learning rate: 0.00276 
2023-10-26 16:31:52.245348: train_loss -0.9074 
2023-10-26 16:31:52.245705: val_loss -0.7484 
2023-10-26 16:31:52.245954: Pseudo dice [0.8366, 0.9243, 0.9663, 0.5554, 0.7409] 
2023-10-26 16:31:52.246174: Epoch time: 4.27 s 
2023-10-26 16:31:53.449444:  
2023-10-26 16:31:53.449733: Epoch 762 
2023-10-26 16:31:53.449972: Current learning rate: 0.00275 
2023-10-26 16:31:57.678945: train_loss -0.8971 
2023-10-26 16:31:57.679334: val_loss -0.7528 
2023-10-26 16:31:57.679598: Pseudo dice [0.8335, 0.9223, 0.9644, 0.5405, 0.7497] 
2023-10-26 16:31:57.679841: Epoch time: 4.23 s 
2023-10-26 16:31:58.916316:  
2023-10-26 16:31:58.916620: Epoch 763 
2023-10-26 16:31:58.916880: Current learning rate: 0.00274 
2023-10-26 16:32:03.034288: train_loss -0.9005 
2023-10-26 16:32:03.034647: val_loss -0.7433 
2023-10-26 16:32:03.034907: Pseudo dice [0.8417, 0.92, 0.9654, 0.6607, 0.7072] 
2023-10-26 16:32:03.035134: Epoch time: 4.12 s 
2023-10-26 16:32:04.253377:  
2023-10-26 16:32:04.253664: Epoch 764 
2023-10-26 16:32:04.253911: Current learning rate: 0.00273 
2023-10-26 16:32:08.499156: train_loss -0.9005 
2023-10-26 16:32:08.499543: val_loss -0.7429 
2023-10-26 16:32:08.499813: Pseudo dice [0.8372, 0.919, 0.9653, 0.6386, 0.7005] 
2023-10-26 16:32:08.500105: Epoch time: 4.25 s 
2023-10-26 16:32:09.743683:  
2023-10-26 16:32:09.743990: Epoch 765 
2023-10-26 16:32:09.744272: Current learning rate: 0.00272 
2023-10-26 16:32:13.833199: train_loss -0.9025 
2023-10-26 16:32:13.833626: val_loss -0.7272 
2023-10-26 16:32:13.834071: Pseudo dice [0.8314, 0.9244, 0.9652, 0.5107, 0.7715] 
2023-10-26 16:32:13.834344: Epoch time: 4.09 s 
2023-10-26 16:32:15.230444:  
2023-10-26 16:32:15.230754: Epoch 766 
2023-10-26 16:32:15.231007: Current learning rate: 0.00271 
2023-10-26 16:32:19.556320: train_loss -0.9055 
2023-10-26 16:32:19.556691: val_loss -0.7202 
2023-10-26 16:32:19.556948: Pseudo dice [0.8396, 0.9205, 0.9641, 0.5511, 0.756] 
2023-10-26 16:32:19.557179: Epoch time: 4.33 s 
2023-10-26 16:32:20.750631:  
2023-10-26 16:32:20.751157: Epoch 767 
2023-10-26 16:32:20.751454: Current learning rate: 0.0027 
2023-10-26 16:32:24.936808: train_loss -0.9052 
2023-10-26 16:32:24.937154: val_loss -0.7095 
2023-10-26 16:32:24.937412: Pseudo dice [0.8299, 0.9239, 0.9683, 0.5517, 0.743] 
2023-10-26 16:32:24.937626: Epoch time: 4.19 s 
2023-10-26 16:32:26.159905:  
2023-10-26 16:32:26.160212: Epoch 768 
2023-10-26 16:32:26.160458: Current learning rate: 0.00268 
2023-10-26 16:32:30.471134: train_loss -0.9068 
2023-10-26 16:32:30.471504: val_loss -0.7705 
2023-10-26 16:32:30.471770: Pseudo dice [0.834, 0.9267, 0.9679, 0.6807, 0.8415] 
2023-10-26 16:32:30.472011: Epoch time: 4.31 s 
2023-10-26 16:32:31.683690:  
2023-10-26 16:32:31.684010: Epoch 769 
2023-10-26 16:32:31.684271: Current learning rate: 0.00267 
2023-10-26 16:32:35.817156: train_loss -0.9097 
2023-10-26 16:32:35.817510: val_loss -0.7638 
2023-10-26 16:32:35.817768: Pseudo dice [0.8347, 0.922, 0.9653, 0.6742, 0.8225] 
2023-10-26 16:32:35.817997: Epoch time: 4.13 s 
2023-10-26 16:32:37.009971:  
2023-10-26 16:32:37.010271: Epoch 770 
2023-10-26 16:32:37.010518: Current learning rate: 0.00266 
2023-10-26 16:32:41.268114: train_loss -0.9064 
2023-10-26 16:32:41.268494: val_loss -0.7509 
2023-10-26 16:32:41.268753: Pseudo dice [0.8358, 0.9249, 0.9668, 0.6354, 0.8002] 
2023-10-26 16:32:41.269009: Epoch time: 4.26 s 
2023-10-26 16:32:42.540520:  
2023-10-26 16:32:42.540823: Epoch 771 
2023-10-26 16:32:42.541075: Current learning rate: 0.00265 
2023-10-26 16:32:46.805448: train_loss -0.9105 
2023-10-26 16:32:46.805860: val_loss -0.7686 
2023-10-26 16:32:46.806138: Pseudo dice [0.841, 0.9295, 0.9666, 0.6845, 0.813] 
2023-10-26 16:32:46.806375: Epoch time: 4.27 s 
2023-10-26 16:32:48.229960:  
2023-10-26 16:32:48.230301: Epoch 772 
2023-10-26 16:32:48.230561: Current learning rate: 0.00264 
2023-10-26 16:32:52.409945: train_loss -0.9043 
2023-10-26 16:32:52.410355: val_loss -0.7201 
2023-10-26 16:32:52.410616: Pseudo dice [0.8404, 0.9251, 0.9668, 0.2968, 0.8243] 
2023-10-26 16:32:52.410900: Epoch time: 4.18 s 
2023-10-26 16:32:53.629436:  
2023-10-26 16:32:53.629727: Epoch 773 
2023-10-26 16:32:53.629964: Current learning rate: 0.00263 
2023-10-26 16:32:57.818186: train_loss -0.906 
2023-10-26 16:32:57.818651: val_loss -0.6893 
2023-10-26 16:32:57.818971: Pseudo dice [0.8373, 0.9228, 0.9652, 0.566, 0.7044] 
2023-10-26 16:32:57.819252: Epoch time: 4.19 s 
2023-10-26 16:32:59.067207:  
2023-10-26 16:32:59.067499: Epoch 774 
2023-10-26 16:32:59.067747: Current learning rate: 0.00262 
2023-10-26 16:33:03.382911: train_loss -0.9054 
2023-10-26 16:33:03.383314: val_loss -0.6641 
2023-10-26 16:33:03.383610: Pseudo dice [0.8371, 0.9233, 0.9652, 0.1511, 0.6405] 
2023-10-26 16:33:03.383854: Epoch time: 4.32 s 
2023-10-26 16:33:04.588784:  
2023-10-26 16:33:04.589092: Epoch 775 
2023-10-26 16:33:04.589318: Current learning rate: 0.00261 
2023-10-26 16:33:08.778926: train_loss -0.9066 
2023-10-26 16:33:08.779266: val_loss -0.7739 
2023-10-26 16:33:08.779516: Pseudo dice [0.8417, 0.9249, 0.9673, 0.5534, 0.8523] 
2023-10-26 16:33:08.779732: Epoch time: 4.19 s 
2023-10-26 16:33:09.986524:  
2023-10-26 16:33:09.986820: Epoch 776 
2023-10-26 16:33:09.987057: Current learning rate: 0.0026 
2023-10-26 16:33:14.249117: train_loss -0.9051 
2023-10-26 16:33:14.249526: val_loss -0.7177 
2023-10-26 16:33:14.249797: Pseudo dice [0.8415, 0.931, 0.9671, 0.4981, 0.7352] 
2023-10-26 16:33:14.250043: Epoch time: 4.26 s 
2023-10-26 16:33:15.531118:  
2023-10-26 16:33:15.531465: Epoch 777 
2023-10-26 16:33:15.531779: Current learning rate: 0.00259 
2023-10-26 16:33:19.750686: train_loss -0.905 
2023-10-26 16:33:19.751102: val_loss -0.7264 
2023-10-26 16:33:19.751362: Pseudo dice [0.8388, 0.9239, 0.9656, 0.456, 0.802] 
2023-10-26 16:33:19.751603: Epoch time: 4.22 s 
2023-10-26 16:33:21.158540:  
2023-10-26 16:33:21.158852: Epoch 778 
2023-10-26 16:33:21.159111: Current learning rate: 0.00258 
2023-10-26 16:33:25.464965: train_loss -0.8981 
2023-10-26 16:33:25.465422: val_loss -0.748 
2023-10-26 16:33:25.465947: Pseudo dice [0.8186, 0.9157, 0.9657, 0.2929, 0.7963] 
2023-10-26 16:33:25.466300: Epoch time: 4.31 s 
2023-10-26 16:33:26.665010:  
2023-10-26 16:33:26.665298: Epoch 779 
2023-10-26 16:33:26.665543: Current learning rate: 0.00257 
2023-10-26 16:33:31.131454: train_loss -0.9046 
2023-10-26 16:33:31.131794: val_loss -0.7633 
2023-10-26 16:33:31.132045: Pseudo dice [0.8317, 0.9248, 0.9664, 0.388, 0.8307] 
2023-10-26 16:33:31.132267: Epoch time: 4.47 s 
2023-10-26 16:33:32.328035:  
2023-10-26 16:33:32.328809: Epoch 780 
2023-10-26 16:33:32.329080: Current learning rate: 0.00256 
2023-10-26 16:33:36.661601: train_loss -0.9096 
2023-10-26 16:33:36.661968: val_loss -0.765 
2023-10-26 16:33:36.662214: Pseudo dice [0.8249, 0.9237, 0.9675, 0.3918, 0.7879] 
2023-10-26 16:33:36.662434: Epoch time: 4.33 s 
2023-10-26 16:33:37.854417:  
2023-10-26 16:33:37.854748: Epoch 781 
2023-10-26 16:33:37.855020: Current learning rate: 0.00255 
2023-10-26 16:33:42.072298: train_loss -0.9021 
2023-10-26 16:33:42.072687: val_loss -0.7929 
2023-10-26 16:33:42.072948: Pseudo dice [0.8325, 0.9157, 0.9661, 0.5485, 0.8731] 
2023-10-26 16:33:42.073211: Epoch time: 4.22 s 
2023-10-26 16:33:43.360622:  
2023-10-26 16:33:43.360927: Epoch 782 
2023-10-26 16:33:43.361182: Current learning rate: 0.00254 
2023-10-26 16:33:47.706705: train_loss -0.8915 
2023-10-26 16:33:47.707134: val_loss -0.7824 
2023-10-26 16:33:47.707407: Pseudo dice [0.8354, 0.9219, 0.9683, 0.4203, 0.8858] 
2023-10-26 16:33:47.707646: Epoch time: 4.35 s 
2023-10-26 16:33:48.957135:  
2023-10-26 16:33:48.957486: Epoch 783 
2023-10-26 16:33:48.957751: Current learning rate: 0.00253 
2023-10-26 16:33:53.174577: train_loss -0.9 
2023-10-26 16:33:53.174947: val_loss -0.7629 
2023-10-26 16:33:53.175313: Pseudo dice [0.8421, 0.9288, 0.9665, 0.3618, 0.8299] 
2023-10-26 16:33:53.175663: Epoch time: 4.22 s 
2023-10-26 16:33:54.701226:  
2023-10-26 16:33:54.701534: Epoch 784 
2023-10-26 16:33:54.701775: Current learning rate: 0.00252 
2023-10-26 16:33:58.800071: train_loss -0.9052 
2023-10-26 16:33:58.800464: val_loss -0.7847 
2023-10-26 16:33:58.800739: Pseudo dice [0.8394, 0.9287, 0.967, 0.5166, 0.8445] 
2023-10-26 16:33:58.800980: Epoch time: 4.1 s 
2023-10-26 16:34:00.061497:  
2023-10-26 16:34:00.061785: Epoch 785 
2023-10-26 16:34:00.062030: Current learning rate: 0.00251 
2023-10-26 16:34:04.307419: train_loss -0.9076 
2023-10-26 16:34:04.307757: val_loss -0.7704 
2023-10-26 16:34:04.308006: Pseudo dice [0.8414, 0.9308, 0.9667, 0.5076, 0.7911] 
2023-10-26 16:34:04.308230: Epoch time: 4.25 s 
2023-10-26 16:34:05.609630:  
2023-10-26 16:34:05.609912: Epoch 786 
2023-10-26 16:34:05.610156: Current learning rate: 0.0025 
2023-10-26 16:34:09.765975: train_loss -0.9049 
2023-10-26 16:34:09.766345: val_loss -0.783 
2023-10-26 16:34:09.766607: Pseudo dice [0.8384, 0.9223, 0.9648, 0.6047, 0.7824] 
2023-10-26 16:34:09.766832: Epoch time: 4.16 s 
2023-10-26 16:34:10.976298:  
2023-10-26 16:34:10.976641: Epoch 787 
2023-10-26 16:34:10.976949: Current learning rate: 0.00249 
2023-10-26 16:34:15.145065: train_loss -0.8999 
2023-10-26 16:34:15.145408: val_loss -0.6911 
2023-10-26 16:34:15.145656: Pseudo dice [0.8368, 0.9187, 0.9652, 0.4882, 0.7874] 
2023-10-26 16:34:15.145890: Epoch time: 4.17 s 
2023-10-26 16:34:16.357472:  
2023-10-26 16:34:16.357773: Epoch 788 
2023-10-26 16:34:16.358034: Current learning rate: 0.00248 
2023-10-26 16:34:20.484156: train_loss -0.9016 
2023-10-26 16:34:20.484532: val_loss -0.6515 
2023-10-26 16:34:20.484788: Pseudo dice [0.8355, 0.9216, 0.9672, 0.2316, 0.6458] 
2023-10-26 16:34:20.485021: Epoch time: 4.13 s 
2023-10-26 16:34:21.729648:  
2023-10-26 16:34:21.729950: Epoch 789 
2023-10-26 16:34:21.730197: Current learning rate: 0.00247 
2023-10-26 16:34:25.680456: train_loss -0.9091 
2023-10-26 16:34:25.680969: val_loss -0.6969 
2023-10-26 16:34:25.681307: Pseudo dice [0.8315, 0.9231, 0.9643, 0.3605, 0.7656] 
2023-10-26 16:34:25.681609: Epoch time: 3.95 s 
2023-10-26 16:34:27.137333:  
2023-10-26 16:34:27.137617: Epoch 790 
2023-10-26 16:34:27.137852: Current learning rate: 0.00245 
2023-10-26 16:34:31.165281: train_loss -0.9018 
2023-10-26 16:34:31.165658: val_loss -0.6949 
2023-10-26 16:34:31.165962: Pseudo dice [0.8437, 0.9243, 0.9657, 0.4195, 0.7234] 
2023-10-26 16:34:31.166193: Epoch time: 4.03 s 
2023-10-26 16:34:32.424533:  
2023-10-26 16:34:32.424862: Epoch 791 
2023-10-26 16:34:32.425131: Current learning rate: 0.00244 
2023-10-26 16:34:36.432020: train_loss -0.9068 
2023-10-26 16:34:36.432432: val_loss -0.7012 
2023-10-26 16:34:36.432704: Pseudo dice [0.8427, 0.9247, 0.9659, 0.289, 0.7788] 
2023-10-26 16:34:36.432956: Epoch time: 4.01 s 
2023-10-26 16:34:37.657727:  
2023-10-26 16:34:37.658034: Epoch 792 
2023-10-26 16:34:37.658285: Current learning rate: 0.00243 
2023-10-26 16:34:41.667953: train_loss -0.9051 
2023-10-26 16:34:41.668309: val_loss -0.7191 
2023-10-26 16:34:41.668580: Pseudo dice [0.8348, 0.927, 0.9673, 0.5242, 0.7185] 
2023-10-26 16:34:41.668804: Epoch time: 4.01 s 
2023-10-26 16:34:42.902863:  
2023-10-26 16:34:42.903173: Epoch 793 
2023-10-26 16:34:42.903405: Current learning rate: 0.00242 
2023-10-26 16:34:47.104439: train_loss -0.9002 
2023-10-26 16:34:47.104905: val_loss -0.7089 
2023-10-26 16:34:47.105460: Pseudo dice [0.8216, 0.9173, 0.965, 0.3771, 0.8012] 
2023-10-26 16:34:47.105819: Epoch time: 4.2 s 
2023-10-26 16:34:48.313389:  
2023-10-26 16:34:48.313682: Epoch 794 
2023-10-26 16:34:48.313956: Current learning rate: 0.00241 
2023-10-26 16:34:52.789361: train_loss -0.9031 
2023-10-26 16:34:52.789737: val_loss -0.7117 
2023-10-26 16:34:52.790005: Pseudo dice [0.8351, 0.9279, 0.9666, 0.3707, 0.7784] 
2023-10-26 16:34:52.790237: Epoch time: 4.48 s 
2023-10-26 16:34:54.034905:  
2023-10-26 16:34:54.035389: Epoch 795 
2023-10-26 16:34:54.035644: Current learning rate: 0.0024 
2023-10-26 16:34:58.327220: train_loss -0.9084 
2023-10-26 16:34:58.327574: val_loss -0.7136 
2023-10-26 16:34:58.327843: Pseudo dice [0.8315, 0.9214, 0.9671, 0.2987, 0.7854] 
2023-10-26 16:34:58.328061: Epoch time: 4.29 s 
2023-10-26 16:34:59.738701:  
2023-10-26 16:34:59.739036: Epoch 796 
2023-10-26 16:34:59.739507: Current learning rate: 0.00239 
2023-10-26 16:35:04.004760: train_loss -0.9036 
2023-10-26 16:35:04.005166: val_loss -0.7231 
2023-10-26 16:35:04.005420: Pseudo dice [0.8236, 0.9243, 0.9672, 0.4184, 0.7882] 
2023-10-26 16:35:04.005655: Epoch time: 4.27 s 
2023-10-26 16:35:05.222236:  
2023-10-26 16:35:05.222556: Epoch 797 
2023-10-26 16:35:05.222811: Current learning rate: 0.00238 
2023-10-26 16:35:09.462813: train_loss -0.8993 
2023-10-26 16:35:09.463254: val_loss -0.6555 
2023-10-26 16:35:09.463537: Pseudo dice [0.8209, 0.915, 0.9664, 0.0, 0.6893] 
2023-10-26 16:35:09.463785: Epoch time: 4.24 s 
2023-10-26 16:35:10.755728:  
2023-10-26 16:35:10.756092: Epoch 798 
2023-10-26 16:35:10.756377: Current learning rate: 0.00237 
2023-10-26 16:35:15.014841: train_loss -0.895 
2023-10-26 16:35:15.015329: val_loss -0.7113 
2023-10-26 16:35:15.015707: Pseudo dice [0.8455, 0.9282, 0.9681, 0.6664, 0.7993] 
2023-10-26 16:35:15.016050: Epoch time: 4.26 s 
2023-10-26 16:35:16.247706:  
2023-10-26 16:35:16.248016: Epoch 799 
2023-10-26 16:35:16.248263: Current learning rate: 0.00236 
2023-10-26 16:35:20.484517: train_loss -0.899 
2023-10-26 16:35:20.484926: val_loss -0.7476 
2023-10-26 16:35:20.485204: Pseudo dice [0.8275, 0.9191, 0.9653, 0.473, 0.8106] 
2023-10-26 16:35:20.485462: Epoch time: 4.24 s 
2023-10-26 16:35:21.817833:  
2023-10-26 16:35:21.818145: Epoch 800 
2023-10-26 16:35:21.818390: Current learning rate: 0.00235 
2023-10-26 16:35:26.026202: train_loss -0.9013 
2023-10-26 16:35:26.026727: val_loss -0.6936 
2023-10-26 16:35:26.027299: Pseudo dice [0.8308, 0.9236, 0.9663, 0.3374, 0.7006] 
2023-10-26 16:35:26.027756: Epoch time: 4.21 s 
2023-10-26 16:35:27.255480:  
2023-10-26 16:35:27.255775: Epoch 801 
2023-10-26 16:35:27.256020: Current learning rate: 0.00234 
2023-10-26 16:35:31.485706: train_loss -0.8929 
2023-10-26 16:35:31.486116: val_loss -0.7335 
2023-10-26 16:35:31.486386: Pseudo dice [0.8469, 0.9255, 0.9676, 0.67, 0.7119] 
2023-10-26 16:35:31.486624: Epoch time: 4.23 s 
2023-10-26 16:35:32.891246:  
2023-10-26 16:35:32.891556: Epoch 802 
2023-10-26 16:35:32.891793: Current learning rate: 0.00233 
2023-10-26 16:35:37.169053: train_loss -0.8963 
2023-10-26 16:35:37.169430: val_loss -0.7106 
2023-10-26 16:35:37.169683: Pseudo dice [0.8103, 0.9162, 0.9642, 0.2639, 0.7674] 
2023-10-26 16:35:37.169918: Epoch time: 4.28 s 
2023-10-26 16:35:38.413693:  
2023-10-26 16:35:38.414042: Epoch 803 
2023-10-26 16:35:38.414333: Current learning rate: 0.00232 
2023-10-26 16:35:42.668033: train_loss -0.9022 
2023-10-26 16:35:42.668401: val_loss -0.8034 
2023-10-26 16:35:42.668667: Pseudo dice [0.8424, 0.9264, 0.9665, 0.6858, 0.872] 
2023-10-26 16:35:42.668905: Epoch time: 4.26 s 
2023-10-26 16:35:43.888590:  
2023-10-26 16:35:43.888893: Epoch 804 
2023-10-26 16:35:43.889134: Current learning rate: 0.00231 
2023-10-26 16:35:48.015500: train_loss -0.905 
2023-10-26 16:35:48.015896: val_loss -0.722 
2023-10-26 16:35:48.016177: Pseudo dice [0.8447, 0.9255, 0.9696, 0.5754, 0.7183] 
2023-10-26 16:35:48.016401: Epoch time: 4.13 s 
2023-10-26 16:35:49.251892:  
2023-10-26 16:35:49.252211: Epoch 805 
2023-10-26 16:35:49.252452: Current learning rate: 0.0023 
2023-10-26 16:35:53.452221: train_loss -0.9031 
2023-10-26 16:35:53.452612: val_loss -0.7599 
2023-10-26 16:35:53.452867: Pseudo dice [0.8283, 0.9201, 0.9659, 0.522, 0.8305] 
2023-10-26 16:35:53.453105: Epoch time: 4.2 s 
2023-10-26 16:35:54.677378:  
2023-10-26 16:35:54.677674: Epoch 806 
2023-10-26 16:35:54.677932: Current learning rate: 0.00229 
2023-10-26 16:35:58.873698: train_loss -0.9074 
2023-10-26 16:35:58.874071: val_loss -0.6957 
2023-10-26 16:35:58.874318: Pseudo dice [0.8435, 0.9234, 0.9675, 0.5016, 0.7168] 
2023-10-26 16:35:58.874542: Epoch time: 4.2 s 
2023-10-26 16:36:00.067980:  
2023-10-26 16:36:00.068269: Epoch 807 
2023-10-26 16:36:00.068544: Current learning rate: 0.00228 
2023-10-26 16:36:04.363865: train_loss -0.906 
2023-10-26 16:36:04.364275: val_loss -0.726 
2023-10-26 16:36:04.364532: Pseudo dice [0.8433, 0.9219, 0.9671, 0.5419, 0.7962] 
2023-10-26 16:36:04.364765: Epoch time: 4.3 s 
2023-10-26 16:36:05.784988:  
2023-10-26 16:36:05.785311: Epoch 808 
2023-10-26 16:36:05.785568: Current learning rate: 0.00226 
2023-10-26 16:36:10.039055: train_loss -0.9045 
2023-10-26 16:36:10.039424: val_loss -0.7131 
2023-10-26 16:36:10.039682: Pseudo dice [0.8476, 0.9243, 0.9667, 0.5611, 0.7564] 
2023-10-26 16:36:10.039913: Epoch time: 4.25 s 
2023-10-26 16:36:11.299668:  
2023-10-26 16:36:11.300042: Epoch 809 
2023-10-26 16:36:11.300369: Current learning rate: 0.00225 
2023-10-26 16:36:15.559254: train_loss -0.9091 
2023-10-26 16:36:15.559613: val_loss -0.7389 
2023-10-26 16:36:15.559895: Pseudo dice [0.843, 0.9245, 0.9653, 0.3827, 0.794] 
2023-10-26 16:36:15.560142: Epoch time: 4.26 s 
2023-10-26 16:36:16.801970:  
2023-10-26 16:36:16.802278: Epoch 810 
2023-10-26 16:36:16.802522: Current learning rate: 0.00224 
2023-10-26 16:36:20.976813: train_loss -0.895 
2023-10-26 16:36:20.977271: val_loss -0.7709 
2023-10-26 16:36:20.977664: Pseudo dice [0.8286, 0.9224, 0.9661, 0.4573, 0.8298] 
2023-10-26 16:36:20.977953: Epoch time: 4.18 s 
2023-10-26 16:36:22.217972:  
2023-10-26 16:36:22.218276: Epoch 811 
2023-10-26 16:36:22.218518: Current learning rate: 0.00223 
2023-10-26 16:36:26.399465: train_loss -0.906 
2023-10-26 16:36:26.399863: val_loss -0.741 
2023-10-26 16:36:26.400124: Pseudo dice [0.832, 0.922, 0.9672, 0.5628, 0.727] 
2023-10-26 16:36:26.400355: Epoch time: 4.18 s 
2023-10-26 16:36:27.643916:  
2023-10-26 16:36:27.644209: Epoch 812 
2023-10-26 16:36:27.644442: Current learning rate: 0.00222 
2023-10-26 16:36:31.801884: train_loss -0.9084 
2023-10-26 16:36:31.802317: val_loss -0.7393 
2023-10-26 16:36:31.802690: Pseudo dice [0.8439, 0.9245, 0.9657, 0.4402, 0.7903] 
2023-10-26 16:36:31.803003: Epoch time: 4.16 s 
2023-10-26 16:36:33.022416:  
2023-10-26 16:36:33.022708: Epoch 813 
2023-10-26 16:36:33.022955: Current learning rate: 0.00221 
2023-10-26 16:36:37.118340: train_loss -0.909 
2023-10-26 16:36:37.118832: val_loss -0.7475 
2023-10-26 16:36:37.119238: Pseudo dice [0.8179, 0.923, 0.9649, 0.4856, 0.7809] 
2023-10-26 16:36:37.119501: Epoch time: 4.1 s 
2023-10-26 16:36:38.557096:  
2023-10-26 16:36:38.557396: Epoch 814 
2023-10-26 16:36:38.557636: Current learning rate: 0.0022 
2023-10-26 16:36:42.809241: train_loss -0.9107 
2023-10-26 16:36:42.809855: val_loss -0.7115 
2023-10-26 16:36:42.810255: Pseudo dice [0.8413, 0.9238, 0.9655, 0.5165, 0.749] 
2023-10-26 16:36:42.810626: Epoch time: 4.25 s 
2023-10-26 16:36:44.029254:  
2023-10-26 16:36:44.029549: Epoch 815 
2023-10-26 16:36:44.029776: Current learning rate: 0.00219 
2023-10-26 16:36:48.172540: train_loss -0.9076 
2023-10-26 16:36:48.172907: val_loss -0.7068 
2023-10-26 16:36:48.173183: Pseudo dice [0.8497, 0.9276, 0.9669, 0.5506, 0.6405] 
2023-10-26 16:36:48.173437: Epoch time: 4.14 s 
2023-10-26 16:36:49.408473:  
2023-10-26 16:36:49.408841: Epoch 816 
2023-10-26 16:36:49.409122: Current learning rate: 0.00218 
2023-10-26 16:36:53.610355: train_loss -0.9118 
2023-10-26 16:36:53.610773: val_loss -0.6593 
2023-10-26 16:36:53.611058: Pseudo dice [0.8459, 0.9264, 0.9661, 0.4897, 0.5964] 
2023-10-26 16:36:53.611314: Epoch time: 4.2 s 
2023-10-26 16:36:54.872561:  
2023-10-26 16:36:54.872860: Epoch 817 
2023-10-26 16:36:54.873109: Current learning rate: 0.00217 
2023-10-26 16:36:59.096285: train_loss -0.9059 
2023-10-26 16:36:59.096698: val_loss -0.6985 
2023-10-26 16:36:59.096956: Pseudo dice [0.8446, 0.9253, 0.9661, 0.4665, 0.669] 
2023-10-26 16:36:59.097200: Epoch time: 4.22 s 
2023-10-26 16:37:00.346625:  
2023-10-26 16:37:00.346928: Epoch 818 
2023-10-26 16:37:00.347194: Current learning rate: 0.00216 
2023-10-26 16:37:04.550026: train_loss -0.9119 
2023-10-26 16:37:04.550442: val_loss -0.7213 
2023-10-26 16:37:04.550701: Pseudo dice [0.8413, 0.9271, 0.9675, 0.4196, 0.7632] 
2023-10-26 16:37:04.550959: Epoch time: 4.2 s 
2023-10-26 16:37:05.794356:  
2023-10-26 16:37:05.794694: Epoch 819 
2023-10-26 16:37:05.794990: Current learning rate: 0.00215 
2023-10-26 16:37:10.052137: train_loss -0.905 
2023-10-26 16:37:10.052546: val_loss -0.7552 
2023-10-26 16:37:10.052809: Pseudo dice [0.8307, 0.9235, 0.9656, 0.6422, 0.7925] 
2023-10-26 16:37:10.053045: Epoch time: 4.26 s 
2023-10-26 16:37:11.391733:  
2023-10-26 16:37:11.392043: Epoch 820 
2023-10-26 16:37:11.392282: Current learning rate: 0.00214 
2023-10-26 16:37:15.666078: train_loss -0.9095 
2023-10-26 16:37:15.666461: val_loss -0.6521 
2023-10-26 16:37:15.666721: Pseudo dice [0.8333, 0.9266, 0.966, 0.2736, 0.4916] 
2023-10-26 16:37:15.666949: Epoch time: 4.27 s 
2023-10-26 16:37:16.818017:  
2023-10-26 16:37:16.818308: Epoch 821 
2023-10-26 16:37:16.818537: Current learning rate: 0.00213 
2023-10-26 16:37:20.794292: train_loss -0.9071 
2023-10-26 16:37:20.794646: val_loss -0.7056 
2023-10-26 16:37:20.794925: Pseudo dice [0.8392, 0.9254, 0.9674, 0.5166, 0.6688] 
2023-10-26 16:37:20.795145: Epoch time: 3.98 s 
2023-10-26 16:37:21.954682:  
2023-10-26 16:37:21.954990: Epoch 822 
2023-10-26 16:37:21.955238: Current learning rate: 0.00212 
2023-10-26 16:37:26.172428: train_loss -0.9106 
2023-10-26 16:37:26.172790: val_loss -0.7521 
2023-10-26 16:37:26.173049: Pseudo dice [0.8276, 0.9203, 0.9668, 0.5527, 0.833] 
2023-10-26 16:37:26.173283: Epoch time: 4.22 s 
2023-10-26 16:37:27.328429:  
2023-10-26 16:37:27.328724: Epoch 823 
2023-10-26 16:37:27.328982: Current learning rate: 0.0021 
2023-10-26 16:37:31.674446: train_loss -0.9106 
2023-10-26 16:37:31.674796: val_loss -0.6999 
2023-10-26 16:37:31.675051: Pseudo dice [0.8203, 0.9193, 0.9683, 0.1623, 0.7451] 
2023-10-26 16:37:31.675269: Epoch time: 4.35 s 
2023-10-26 16:37:32.855246:  
2023-10-26 16:37:32.855545: Epoch 824 
2023-10-26 16:37:32.855790: Current learning rate: 0.00209 
2023-10-26 16:37:36.984410: train_loss -0.9056 
2023-10-26 16:37:36.984896: val_loss -0.7663 
2023-10-26 16:37:36.985193: Pseudo dice [0.8462, 0.9253, 0.9674, 0.6512, 0.8374] 
2023-10-26 16:37:36.985482: Epoch time: 4.13 s 
2023-10-26 16:37:38.134437:  
2023-10-26 16:37:38.134728: Epoch 825 
2023-10-26 16:37:38.134979: Current learning rate: 0.00208 
2023-10-26 16:37:42.521432: train_loss -0.9081 
2023-10-26 16:37:42.521840: val_loss -0.7965 
2023-10-26 16:37:42.522126: Pseudo dice [0.8288, 0.9219, 0.9665, 0.5487, 0.8824] 
2023-10-26 16:37:42.522376: Epoch time: 4.39 s 
2023-10-26 16:37:43.875047:  
2023-10-26 16:37:43.875361: Epoch 826 
2023-10-26 16:37:43.875622: Current learning rate: 0.00207 
2023-10-26 16:37:48.119965: train_loss -0.9062 
2023-10-26 16:37:48.120328: val_loss -0.7429 
2023-10-26 16:37:48.120597: Pseudo dice [0.8266, 0.9201, 0.9664, 0.1962, 0.8243] 
2023-10-26 16:37:48.120834: Epoch time: 4.25 s 
2023-10-26 16:37:49.369690:  
2023-10-26 16:37:49.370225: Epoch 827 
2023-10-26 16:37:49.370541: Current learning rate: 0.00206 
2023-10-26 16:37:53.552369: train_loss -0.9039 
2023-10-26 16:37:53.552738: val_loss -0.7057 
2023-10-26 16:37:53.553033: Pseudo dice [0.8393, 0.9264, 0.9658, 0.3817, 0.699] 
2023-10-26 16:37:53.553270: Epoch time: 4.18 s 
2023-10-26 16:37:54.776213:  
2023-10-26 16:37:54.776512: Epoch 828 
2023-10-26 16:37:54.776770: Current learning rate: 0.00205 
2023-10-26 16:37:58.962828: train_loss -0.9142 
2023-10-26 16:37:58.963207: val_loss -0.7427 
2023-10-26 16:37:58.963467: Pseudo dice [0.8459, 0.927, 0.9678, 0.4689, 0.7892] 
2023-10-26 16:37:58.963694: Epoch time: 4.19 s 
2023-10-26 16:38:00.146723:  
2023-10-26 16:38:00.147021: Epoch 829 
2023-10-26 16:38:00.147254: Current learning rate: 0.00204 
2023-10-26 16:38:04.303425: train_loss -0.9122 
2023-10-26 16:38:04.303771: val_loss -0.7084 
2023-10-26 16:38:04.304039: Pseudo dice [0.838, 0.9207, 0.9667, 0.5724, 0.7092] 
2023-10-26 16:38:04.304265: Epoch time: 4.16 s 
2023-10-26 16:38:05.466150:  
2023-10-26 16:38:05.466429: Epoch 830 
2023-10-26 16:38:05.466660: Current learning rate: 0.00203 
2023-10-26 16:38:09.731992: train_loss -0.9084 
2023-10-26 16:38:09.732412: val_loss -0.74 
2023-10-26 16:38:09.732679: Pseudo dice [0.8356, 0.9227, 0.9643, 0.33, 0.8409] 
2023-10-26 16:38:09.732952: Epoch time: 4.27 s 
2023-10-26 16:38:10.928481:  
2023-10-26 16:38:10.928782: Epoch 831 
2023-10-26 16:38:10.929050: Current learning rate: 0.00202 
2023-10-26 16:38:15.242092: train_loss -0.9089 
2023-10-26 16:38:15.242471: val_loss -0.6946 
2023-10-26 16:38:15.242721: Pseudo dice [0.8481, 0.9279, 0.9664, 0.4569, 0.702] 
2023-10-26 16:38:15.242948: Epoch time: 4.31 s 
2023-10-26 16:38:16.443818:  
2023-10-26 16:38:16.444121: Epoch 832 
2023-10-26 16:38:16.444366: Current learning rate: 0.00201 
2023-10-26 16:38:20.680857: train_loss -0.9046 
2023-10-26 16:38:20.681390: val_loss -0.691 
2023-10-26 16:38:20.681747: Pseudo dice [0.8402, 0.9257, 0.9648, 0.3281, 0.7164] 
2023-10-26 16:38:20.682071: Epoch time: 4.24 s 
2023-10-26 16:38:22.094994:  
2023-10-26 16:38:22.095283: Epoch 833 
2023-10-26 16:38:22.095521: Current learning rate: 0.002 
2023-10-26 16:38:26.261224: train_loss -0.8987 
2023-10-26 16:38:26.261590: val_loss -0.7247 
2023-10-26 16:38:26.261842: Pseudo dice [0.8283, 0.9229, 0.9652, 0.5377, 0.727] 
2023-10-26 16:38:26.262100: Epoch time: 4.17 s 
2023-10-26 16:38:27.420040:  
2023-10-26 16:38:27.420326: Epoch 834 
2023-10-26 16:38:27.420571: Current learning rate: 0.00199 
2023-10-26 16:38:31.743982: train_loss -0.9073 
2023-10-26 16:38:31.744382: val_loss -0.6978 
2023-10-26 16:38:31.744631: Pseudo dice [0.8362, 0.9235, 0.966, 0.5357, 0.6975] 
2023-10-26 16:38:31.744861: Epoch time: 4.32 s 
2023-10-26 16:38:32.892577:  
2023-10-26 16:38:32.892939: Epoch 835 
2023-10-26 16:38:32.893253: Current learning rate: 0.00198 
2023-10-26 16:38:37.259809: train_loss -0.9113 
2023-10-26 16:38:37.260181: val_loss -0.7326 
2023-10-26 16:38:37.260461: Pseudo dice [0.8376, 0.9284, 0.9667, 0.5753, 0.7991] 
2023-10-26 16:38:37.260713: Epoch time: 4.37 s 
2023-10-26 16:38:38.427775:  
2023-10-26 16:38:38.428079: Epoch 836 
2023-10-26 16:38:38.428325: Current learning rate: 0.00196 
2023-10-26 16:38:42.802944: train_loss -0.91 
2023-10-26 16:38:42.803337: val_loss -0.7383 
2023-10-26 16:38:42.803587: Pseudo dice [0.8475, 0.9284, 0.9668, 0.5238, 0.7543] 
2023-10-26 16:38:42.803819: Epoch time: 4.38 s 
2023-10-26 16:38:43.946420:  
2023-10-26 16:38:43.946715: Epoch 837 
2023-10-26 16:38:43.946949: Current learning rate: 0.00195 
2023-10-26 16:38:48.297018: train_loss -0.9109 
2023-10-26 16:38:48.297436: val_loss -0.7086 
2023-10-26 16:38:48.297709: Pseudo dice [0.8401, 0.9238, 0.9676, 0.6553, 0.7382] 
2023-10-26 16:38:48.297958: Epoch time: 4.35 s 
2023-10-26 16:38:49.514422:  
2023-10-26 16:38:49.514738: Epoch 838 
2023-10-26 16:38:49.515108: Current learning rate: 0.00194 
2023-10-26 16:38:53.801850: train_loss -0.9123 
2023-10-26 16:38:53.802256: val_loss -0.7284 
2023-10-26 16:38:53.802514: Pseudo dice [0.8401, 0.9256, 0.9656, 0.4793, 0.7735] 
2023-10-26 16:38:53.802755: Epoch time: 4.29 s 
2023-10-26 16:38:54.995217:  
2023-10-26 16:38:54.995511: Epoch 839 
2023-10-26 16:38:54.995746: Current learning rate: 0.00193 
2023-10-26 16:38:59.153494: train_loss -0.9138 
2023-10-26 16:38:59.153894: val_loss -0.7223 
2023-10-26 16:38:59.154167: Pseudo dice [0.8422, 0.93, 0.9676, 0.576, 0.715] 
2023-10-26 16:38:59.154460: Epoch time: 4.16 s 
2023-10-26 16:39:00.523264:  
2023-10-26 16:39:00.523562: Epoch 840 
2023-10-26 16:39:00.523804: Current learning rate: 0.00192 
2023-10-26 16:39:04.817210: train_loss -0.913 
2023-10-26 16:39:04.817585: val_loss -0.7259 
2023-10-26 16:39:04.817851: Pseudo dice [0.8456, 0.9272, 0.9658, 0.573, 0.7775] 
2023-10-26 16:39:04.818088: Epoch time: 4.29 s 
2023-10-26 16:39:05.992053:  
2023-10-26 16:39:05.992374: Epoch 841 
2023-10-26 16:39:05.992624: Current learning rate: 0.00191 
2023-10-26 16:39:10.179682: train_loss -0.9089 
2023-10-26 16:39:10.180098: val_loss -0.7246 
2023-10-26 16:39:10.180356: Pseudo dice [0.8407, 0.9234, 0.9663, 0.4867, 0.7778] 
2023-10-26 16:39:10.180585: Epoch time: 4.19 s 
2023-10-26 16:39:11.353526:  
2023-10-26 16:39:11.353817: Epoch 842 
2023-10-26 16:39:11.354053: Current learning rate: 0.0019 
2023-10-26 16:39:15.571435: train_loss -0.9092 
2023-10-26 16:39:15.571808: val_loss -0.7718 
2023-10-26 16:39:15.572073: Pseudo dice [0.8404, 0.9275, 0.9666, 0.5867, 0.8308] 
2023-10-26 16:39:15.572295: Epoch time: 4.22 s 
2023-10-26 16:39:16.770068:  
2023-10-26 16:39:16.770372: Epoch 843 
2023-10-26 16:39:16.770620: Current learning rate: 0.00189 
2023-10-26 16:39:21.017936: train_loss -0.9121 
2023-10-26 16:39:21.018390: val_loss -0.7504 
2023-10-26 16:39:21.018657: Pseudo dice [0.8356, 0.9246, 0.9679, 0.5523, 0.8084] 
2023-10-26 16:39:21.019024: Epoch time: 4.25 s 
2023-10-26 16:39:22.253897:  
2023-10-26 16:39:22.254287: Epoch 844 
2023-10-26 16:39:22.254618: Current learning rate: 0.00188 
2023-10-26 16:39:26.541942: train_loss -0.9124 
2023-10-26 16:39:26.542341: val_loss -0.721 
2023-10-26 16:39:26.542586: Pseudo dice [0.8404, 0.9244, 0.9655, 0.5059, 0.7236] 
2023-10-26 16:39:26.542825: Epoch time: 4.29 s 
2023-10-26 16:39:27.748065:  
2023-10-26 16:39:27.748353: Epoch 845 
2023-10-26 16:39:27.748605: Current learning rate: 0.00187 
2023-10-26 16:39:32.044163: train_loss -0.9036 
2023-10-26 16:39:32.044571: val_loss -0.7319 
2023-10-26 16:39:32.044846: Pseudo dice [0.8307, 0.9265, 0.9663, 0.5514, 0.7679] 
2023-10-26 16:39:32.045107: Epoch time: 4.3 s 
2023-10-26 16:39:33.383945:  
2023-10-26 16:39:33.384240: Epoch 846 
2023-10-26 16:39:33.384484: Current learning rate: 0.00186 
2023-10-26 16:39:37.627844: train_loss -0.9122 
2023-10-26 16:39:37.628282: val_loss -0.6574 
2023-10-26 16:39:37.628560: Pseudo dice [0.8401, 0.9238, 0.9653, 0.4188, 0.6754] 
2023-10-26 16:39:37.628817: Epoch time: 4.24 s 
2023-10-26 16:39:38.799537:  
2023-10-26 16:39:38.799860: Epoch 847 
2023-10-26 16:39:38.800136: Current learning rate: 0.00185 
2023-10-26 16:39:43.114737: train_loss -0.9091 
2023-10-26 16:39:43.115219: val_loss -0.6641 
2023-10-26 16:39:43.115547: Pseudo dice [0.8417, 0.9259, 0.9659, 0.3582, 0.7252] 
2023-10-26 16:39:43.115942: Epoch time: 4.32 s 
2023-10-26 16:39:44.309546:  
2023-10-26 16:39:44.309864: Epoch 848 
2023-10-26 16:39:44.310142: Current learning rate: 0.00184 
2023-10-26 16:39:48.591973: train_loss -0.9137 
2023-10-26 16:39:48.592474: val_loss -0.6923 
2023-10-26 16:39:48.592766: Pseudo dice [0.8431, 0.9281, 0.9673, 0.4073, 0.7452] 
2023-10-26 16:39:48.593071: Epoch time: 4.28 s 
2023-10-26 16:39:49.744166:  
2023-10-26 16:39:49.744459: Epoch 849 
2023-10-26 16:39:49.744710: Current learning rate: 0.00182 
2023-10-26 16:39:54.190957: train_loss -0.9081 
2023-10-26 16:39:54.191365: val_loss -0.6693 
2023-10-26 16:39:54.191638: Pseudo dice [0.842, 0.9255, 0.9647, 0.5235, 0.58] 
2023-10-26 16:39:54.191885: Epoch time: 4.45 s 
2023-10-26 16:39:55.565765:  
2023-10-26 16:39:55.566081: Epoch 850 
2023-10-26 16:39:55.566350: Current learning rate: 0.00181 
2023-10-26 16:39:59.787715: train_loss -0.9141 
2023-10-26 16:39:59.788154: val_loss -0.686 
2023-10-26 16:39:59.788474: Pseudo dice [0.842, 0.9231, 0.9663, 0.412, 0.7112] 
2023-10-26 16:39:59.788732: Epoch time: 4.22 s 
2023-10-26 16:40:00.984920:  
2023-10-26 16:40:00.985402: Epoch 851 
2023-10-26 16:40:00.985660: Current learning rate: 0.0018 
2023-10-26 16:40:05.157148: train_loss -0.9151 
2023-10-26 16:40:05.157552: val_loss -0.6976 
2023-10-26 16:40:05.157808: Pseudo dice [0.8353, 0.9247, 0.9664, 0.4128, 0.7093] 
2023-10-26 16:40:05.158070: Epoch time: 4.17 s 
2023-10-26 16:40:06.345590:  
2023-10-26 16:40:06.345893: Epoch 852 
2023-10-26 16:40:06.346136: Current learning rate: 0.00179 
2023-10-26 16:40:10.676033: train_loss -0.9103 
2023-10-26 16:40:10.676723: val_loss -0.65 
2023-10-26 16:40:10.677018: Pseudo dice [0.8337, 0.9206, 0.9655, 0.216, 0.6702] 
2023-10-26 16:40:10.677263: Epoch time: 4.33 s 
2023-10-26 16:40:12.047116:  
2023-10-26 16:40:12.047462: Epoch 853 
2023-10-26 16:40:12.047765: Current learning rate: 0.00178 
2023-10-26 16:40:16.338320: train_loss -0.9124 
2023-10-26 16:40:16.338705: val_loss -0.6708 
2023-10-26 16:40:16.338990: Pseudo dice [0.8485, 0.9248, 0.9668, 0.5438, 0.6358] 
2023-10-26 16:40:16.339227: Epoch time: 4.29 s 
2023-10-26 16:40:17.500249:  
2023-10-26 16:40:17.500542: Epoch 854 
2023-10-26 16:40:17.500778: Current learning rate: 0.00177 
2023-10-26 16:40:21.795438: train_loss -0.909 
2023-10-26 16:40:21.795917: val_loss -0.6932 
2023-10-26 16:40:21.796196: Pseudo dice [0.812, 0.921, 0.9676, 0.2614, 0.7685] 
2023-10-26 16:40:21.796468: Epoch time: 4.3 s 
2023-10-26 16:40:22.963980:  
2023-10-26 16:40:22.964305: Epoch 855 
2023-10-26 16:40:22.964565: Current learning rate: 0.00176 
2023-10-26 16:40:27.276088: train_loss -0.9073 
2023-10-26 16:40:27.276492: val_loss -0.7151 
2023-10-26 16:40:27.276768: Pseudo dice [0.8435, 0.9269, 0.9669, 0.5161, 0.752] 
2023-10-26 16:40:27.277028: Epoch time: 4.31 s 
2023-10-26 16:40:28.437066:  
2023-10-26 16:40:28.437425: Epoch 856 
2023-10-26 16:40:28.437725: Current learning rate: 0.00175 
2023-10-26 16:40:32.758089: train_loss -0.9148 
2023-10-26 16:40:32.758516: val_loss -0.7432 
2023-10-26 16:40:32.758900: Pseudo dice [0.8253, 0.9231, 0.9635, 0.3503, 0.8153] 
2023-10-26 16:40:32.759235: Epoch time: 4.32 s 
2023-10-26 16:40:33.930257:  
2023-10-26 16:40:33.930611: Epoch 857 
2023-10-26 16:40:33.930948: Current learning rate: 0.00174 
2023-10-26 16:40:38.147570: train_loss -0.9097 
2023-10-26 16:40:38.147957: val_loss -0.7092 
2023-10-26 16:40:38.148209: Pseudo dice [0.8386, 0.922, 0.9637, 0.3492, 0.7346] 
2023-10-26 16:40:38.148438: Epoch time: 4.22 s 
2023-10-26 16:40:39.371220:  
2023-10-26 16:40:39.371601: Epoch 858 
2023-10-26 16:40:39.371949: Current learning rate: 0.00173 
2023-10-26 16:40:43.674718: train_loss -0.9092 
2023-10-26 16:40:43.675181: val_loss -0.6862 
2023-10-26 16:40:43.675532: Pseudo dice [0.8421, 0.9201, 0.9662, 0.492, 0.7219] 
2023-10-26 16:40:43.675806: Epoch time: 4.3 s 
2023-10-26 16:40:44.996838:  
2023-10-26 16:40:44.997147: Epoch 859 
2023-10-26 16:40:44.997391: Current learning rate: 0.00172 
2023-10-26 16:40:49.321964: train_loss -0.9133 
2023-10-26 16:40:49.322349: val_loss -0.7061 
2023-10-26 16:40:49.322610: Pseudo dice [0.8251, 0.9197, 0.9668, 0.4054, 0.7804] 
2023-10-26 16:40:49.322840: Epoch time: 4.33 s 
2023-10-26 16:40:50.504957:  
2023-10-26 16:40:50.505280: Epoch 860 
2023-10-26 16:40:50.505640: Current learning rate: 0.0017 
2023-10-26 16:40:54.740580: train_loss -0.9149 
2023-10-26 16:40:54.740953: val_loss -0.7273 
2023-10-26 16:40:54.741209: Pseudo dice [0.8244, 0.9206, 0.9674, 0.4485, 0.7901] 
2023-10-26 16:40:54.741442: Epoch time: 4.24 s 
2023-10-26 16:40:55.885840:  
2023-10-26 16:40:55.886150: Epoch 861 
2023-10-26 16:40:55.886391: Current learning rate: 0.00169 
2023-10-26 16:41:00.030678: train_loss -0.9142 
2023-10-26 16:41:00.031046: val_loss -0.7259 
2023-10-26 16:41:00.031305: Pseudo dice [0.8337, 0.9247, 0.9671, 0.5193, 0.7139] 
2023-10-26 16:41:00.031664: Epoch time: 4.15 s 
2023-10-26 16:41:01.174992:  
2023-10-26 16:41:01.175276: Epoch 862 
2023-10-26 16:41:01.175519: Current learning rate: 0.00168 
2023-10-26 16:41:05.575653: train_loss -0.9125 
2023-10-26 16:41:05.576070: val_loss -0.6977 
2023-10-26 16:41:05.576369: Pseudo dice [0.8485, 0.9211, 0.9652, 0.4506, 0.7582] 
2023-10-26 16:41:05.576624: Epoch time: 4.4 s 
2023-10-26 16:41:06.765697:  
2023-10-26 16:41:06.766222: Epoch 863 
2023-10-26 16:41:06.766505: Current learning rate: 0.00167 
2023-10-26 16:41:10.772094: train_loss -0.9089 
2023-10-26 16:41:10.772469: val_loss -0.6556 
2023-10-26 16:41:10.772727: Pseudo dice [0.8386, 0.9225, 0.9662, 0.3366, 0.707] 
2023-10-26 16:41:10.772964: Epoch time: 4.01 s 
2023-10-26 16:41:11.945767:  
2023-10-26 16:41:11.946073: Epoch 864 
2023-10-26 16:41:11.946307: Current learning rate: 0.00166 
2023-10-26 16:41:16.041485: train_loss -0.9134 
2023-10-26 16:41:16.041841: val_loss -0.7009 
2023-10-26 16:41:16.042109: Pseudo dice [0.8466, 0.9263, 0.9653, 0.355, 0.7504] 
2023-10-26 16:41:16.042346: Epoch time: 4.1 s 
2023-10-26 16:41:17.219673:  
2023-10-26 16:41:17.219987: Epoch 865 
2023-10-26 16:41:17.220240: Current learning rate: 0.00165 
2023-10-26 16:41:21.435813: train_loss -0.9135 
2023-10-26 16:41:21.436198: val_loss -0.6903 
2023-10-26 16:41:21.436477: Pseudo dice [0.8416, 0.9237, 0.9657, 0.3417, 0.7116] 
2023-10-26 16:41:21.436704: Epoch time: 4.22 s 
2023-10-26 16:41:22.798043:  
2023-10-26 16:41:22.798345: Epoch 866 
2023-10-26 16:41:22.798582: Current learning rate: 0.00164 
2023-10-26 16:41:27.025797: train_loss -0.9082 
2023-10-26 16:41:27.026183: val_loss -0.6999 
2023-10-26 16:41:27.026503: Pseudo dice [0.837, 0.9255, 0.9656, 0.5087, 0.7016] 
2023-10-26 16:41:27.026744: Epoch time: 4.23 s 
2023-10-26 16:41:28.248428:  
2023-10-26 16:41:28.248748: Epoch 867 
2023-10-26 16:41:28.249003: Current learning rate: 0.00163 
2023-10-26 16:41:32.400713: train_loss -0.9103 
2023-10-26 16:41:32.401086: val_loss -0.709 
2023-10-26 16:41:32.401335: Pseudo dice [0.8257, 0.9225, 0.966, 0.3925, 0.7262] 
2023-10-26 16:41:32.401566: Epoch time: 4.15 s 
2023-10-26 16:41:33.606539:  
2023-10-26 16:41:33.606840: Epoch 868 
2023-10-26 16:41:33.607090: Current learning rate: 0.00162 
2023-10-26 16:41:37.782331: train_loss -0.9104 
2023-10-26 16:41:37.782761: val_loss -0.711 
2023-10-26 16:41:37.783107: Pseudo dice [0.8385, 0.9229, 0.9631, 0.5553, 0.7164] 
2023-10-26 16:41:37.783374: Epoch time: 4.18 s 
2023-10-26 16:41:38.983186:  
2023-10-26 16:41:38.983486: Epoch 869 
2023-10-26 16:41:38.983730: Current learning rate: 0.00161 
2023-10-26 16:41:43.218274: train_loss -0.9093 
2023-10-26 16:41:43.218731: val_loss -0.7651 
2023-10-26 16:41:43.219032: Pseudo dice [0.8352, 0.9232, 0.9663, 0.4901, 0.7944] 
2023-10-26 16:41:43.219289: Epoch time: 4.24 s 
2023-10-26 16:41:44.422910:  
2023-10-26 16:41:44.423191: Epoch 870 
2023-10-26 16:41:44.423435: Current learning rate: 0.00159 
2023-10-26 16:41:48.647392: train_loss -0.9069 
2023-10-26 16:41:48.655246: val_loss -0.7354 
2023-10-26 16:41:48.655505: Pseudo dice [0.837, 0.9236, 0.9669, 0.3319, 0.7621] 
2023-10-26 16:41:48.655803: Epoch time: 4.23 s 
2023-10-26 16:41:49.846712:  
2023-10-26 16:41:49.847011: Epoch 871 
2023-10-26 16:41:49.847253: Current learning rate: 0.00158 
2023-10-26 16:41:54.046396: train_loss -0.9106 
2023-10-26 16:41:54.046805: val_loss -0.7375 
2023-10-26 16:41:54.047067: Pseudo dice [0.8277, 0.9228, 0.9662, 0.3969, 0.8354] 
2023-10-26 16:41:54.047321: Epoch time: 4.2 s 
2023-10-26 16:41:55.222591:  
2023-10-26 16:41:55.222959: Epoch 872 
2023-10-26 16:41:55.223208: Current learning rate: 0.00157 
2023-10-26 16:41:59.393477: train_loss -0.9106 
2023-10-26 16:41:59.393847: val_loss -0.736 
2023-10-26 16:41:59.394114: Pseudo dice [0.8316, 0.9241, 0.9636, 0.39, 0.8065] 
2023-10-26 16:41:59.394340: Epoch time: 4.17 s 
2023-10-26 16:42:00.843816:  
2023-10-26 16:42:00.844122: Epoch 873 
2023-10-26 16:42:00.844362: Current learning rate: 0.00156 
2023-10-26 16:42:05.135639: train_loss -0.9083 
2023-10-26 16:42:05.136031: val_loss -0.719 
2023-10-26 16:42:05.136339: Pseudo dice [0.8272, 0.9211, 0.9676, 0.4896, 0.6313] 
2023-10-26 16:42:05.136569: Epoch time: 4.29 s 
2023-10-26 16:42:06.269208:  
2023-10-26 16:42:06.269500: Epoch 874 
2023-10-26 16:42:06.269740: Current learning rate: 0.00155 
2023-10-26 16:42:10.646062: train_loss -0.9134 
2023-10-26 16:42:10.646462: val_loss -0.734 
2023-10-26 16:42:10.646715: Pseudo dice [0.8388, 0.9239, 0.9668, 0.4876, 0.6941] 
2023-10-26 16:42:10.646947: Epoch time: 4.38 s 
2023-10-26 16:42:11.795843:  
2023-10-26 16:42:11.796205: Epoch 875 
2023-10-26 16:42:11.796452: Current learning rate: 0.00154 
2023-10-26 16:42:16.089008: train_loss -0.9157 
2023-10-26 16:42:16.089425: val_loss -0.699 
2023-10-26 16:42:16.089700: Pseudo dice [0.83, 0.9204, 0.966, 0.4024, 0.7471] 
2023-10-26 16:42:16.089988: Epoch time: 4.29 s 
2023-10-26 16:42:17.325416:  
2023-10-26 16:42:17.325722: Epoch 876 
2023-10-26 16:42:17.325970: Current learning rate: 0.00153 
2023-10-26 16:42:21.590057: train_loss -0.91 
2023-10-26 16:42:21.590480: val_loss -0.7206 
2023-10-26 16:42:21.590753: Pseudo dice [0.8233, 0.9207, 0.966, 0.3632, 0.7579] 
2023-10-26 16:42:21.591018: Epoch time: 4.27 s 
2023-10-26 16:42:22.797575:  
2023-10-26 16:42:22.797878: Epoch 877 
2023-10-26 16:42:22.798136: Current learning rate: 0.00152 
2023-10-26 16:42:26.999985: train_loss -0.9063 
2023-10-26 16:42:27.000389: val_loss -0.7433 
2023-10-26 16:42:27.000652: Pseudo dice [0.8273, 0.919, 0.9656, 0.4852, 0.8067] 
2023-10-26 16:42:27.000898: Epoch time: 4.2 s 
2023-10-26 16:42:28.198574:  
2023-10-26 16:42:28.198963: Epoch 878 
2023-10-26 16:42:28.199207: Current learning rate: 0.00151 
2023-10-26 16:42:32.290461: train_loss -0.9102 
2023-10-26 16:42:32.290896: val_loss -0.6742 
2023-10-26 16:42:32.291170: Pseudo dice [0.823, 0.9224, 0.9637, 0.0597, 0.7203] 
2023-10-26 16:42:32.291412: Epoch time: 4.09 s 
2023-10-26 16:42:33.461596:  
2023-10-26 16:42:33.461893: Epoch 879 
2023-10-26 16:42:33.462123: Current learning rate: 0.00149 
2023-10-26 16:42:37.661048: train_loss -0.9097 
2023-10-26 16:42:37.661466: val_loss -0.6746 
2023-10-26 16:42:37.661754: Pseudo dice [0.8469, 0.9239, 0.9657, 0.4444, 0.6586] 
2023-10-26 16:42:37.662007: Epoch time: 4.2 s 
2023-10-26 16:42:39.064508:  
2023-10-26 16:42:39.064821: Epoch 880 
2023-10-26 16:42:39.065074: Current learning rate: 0.00148 
2023-10-26 16:42:43.268736: train_loss -0.9064 
2023-10-26 16:42:43.269143: val_loss -0.6666 
2023-10-26 16:42:43.269407: Pseudo dice [0.8445, 0.921, 0.9653, 0.1326, 0.7342] 
2023-10-26 16:42:43.269631: Epoch time: 4.2 s 
2023-10-26 16:42:44.426654:  
2023-10-26 16:42:44.426955: Epoch 881 
2023-10-26 16:42:44.427193: Current learning rate: 0.00147 
2023-10-26 16:42:48.648861: train_loss -0.9072 
2023-10-26 16:42:48.649235: val_loss -0.7068 
2023-10-26 16:42:48.649488: Pseudo dice [0.8429, 0.9258, 0.9665, 0.1836, 0.7563] 
2023-10-26 16:42:48.649713: Epoch time: 4.22 s 
2023-10-26 16:42:49.809937:  
2023-10-26 16:42:49.810232: Epoch 882 
2023-10-26 16:42:49.810465: Current learning rate: 0.00146 
2023-10-26 16:42:54.042557: train_loss -0.9077 
2023-10-26 16:42:54.043018: val_loss -0.6598 
2023-10-26 16:42:54.043302: Pseudo dice [0.8445, 0.922, 0.9658, 0.1355, 0.7266] 
2023-10-26 16:42:54.043550: Epoch time: 4.23 s 
2023-10-26 16:42:55.216968:  
2023-10-26 16:42:55.217279: Epoch 883 
2023-10-26 16:42:55.217520: Current learning rate: 0.00145 
2023-10-26 16:42:59.346399: train_loss -0.9119 
2023-10-26 16:42:59.346783: val_loss -0.6925 
2023-10-26 16:42:59.347042: Pseudo dice [0.8371, 0.9249, 0.9665, 0.3336, 0.6972] 
2023-10-26 16:42:59.347258: Epoch time: 4.13 s 
2023-10-26 16:43:00.504681:  
2023-10-26 16:43:00.505010: Epoch 884 
2023-10-26 16:43:00.505291: Current learning rate: 0.00144 
2023-10-26 16:43:04.725059: train_loss -0.9114 
2023-10-26 16:43:04.725497: val_loss -0.7019 
2023-10-26 16:43:04.725758: Pseudo dice [0.844, 0.9232, 0.9662, 0.4203, 0.7388] 
2023-10-26 16:43:04.726000: Epoch time: 4.22 s 
2023-10-26 16:43:05.934746:  
2023-10-26 16:43:05.935065: Epoch 885 
2023-10-26 16:43:05.935303: Current learning rate: 0.00143 
2023-10-26 16:43:10.214620: train_loss -0.9132 
2023-10-26 16:43:10.215046: val_loss -0.713 
2023-10-26 16:43:10.215480: Pseudo dice [0.8405, 0.9223, 0.9669, 0.5466, 0.7441] 
2023-10-26 16:43:10.215735: Epoch time: 4.28 s 
2023-10-26 16:43:11.384879:  
2023-10-26 16:43:11.385231: Epoch 886 
2023-10-26 16:43:11.385556: Current learning rate: 0.00142 
2023-10-26 16:43:16.034534: train_loss -0.9115 
2023-10-26 16:43:16.034913: val_loss -0.726 
2023-10-26 16:43:16.035174: Pseudo dice [0.8497, 0.9243, 0.9653, 0.4298, 0.7795] 
2023-10-26 16:43:16.035404: Epoch time: 4.65 s 
2023-10-26 16:43:17.179154:  
2023-10-26 16:43:17.179468: Epoch 887 
2023-10-26 16:43:17.179751: Current learning rate: 0.00141 
2023-10-26 16:43:21.532196: train_loss -0.9146 
2023-10-26 16:43:21.532603: val_loss -0.6895 
2023-10-26 16:43:21.532862: Pseudo dice [0.8433, 0.925, 0.9642, 0.3896, 0.6566] 
2023-10-26 16:43:21.533119: Epoch time: 4.35 s 
2023-10-26 16:43:22.717119:  
2023-10-26 16:43:22.717455: Epoch 888 
2023-10-26 16:43:22.717697: Current learning rate: 0.00139 
2023-10-26 16:43:27.010331: train_loss -0.9101 
2023-10-26 16:43:27.010716: val_loss -0.798 
2023-10-26 16:43:27.010966: Pseudo dice [0.8415, 0.9245, 0.9655, 0.4762, 0.9066] 
2023-10-26 16:43:27.011197: Epoch time: 4.29 s 
2023-10-26 16:43:28.164318:  
2023-10-26 16:43:28.164617: Epoch 889 
2023-10-26 16:43:28.164888: Current learning rate: 0.00138 
2023-10-26 16:43:32.461675: train_loss -0.907 
2023-10-26 16:43:32.462140: val_loss -0.7826 
2023-10-26 16:43:32.462596: Pseudo dice [0.8424, 0.9272, 0.9663, 0.6042, 0.7941] 
2023-10-26 16:43:32.462893: Epoch time: 4.3 s 
2023-10-26 16:43:33.607193:  
2023-10-26 16:43:33.607506: Epoch 890 
2023-10-26 16:43:33.607758: Current learning rate: 0.00137 
2023-10-26 16:43:37.743150: train_loss -0.9111 
2023-10-26 16:43:37.743545: val_loss -0.7466 
2023-10-26 16:43:37.743807: Pseudo dice [0.8474, 0.9267, 0.9656, 0.569, 0.7477] 
2023-10-26 16:43:37.744049: Epoch time: 4.14 s 
2023-10-26 16:43:38.908830:  
2023-10-26 16:43:38.909136: Epoch 891 
2023-10-26 16:43:38.909389: Current learning rate: 0.00136 
2023-10-26 16:43:43.195504: train_loss -0.9171 
2023-10-26 16:43:43.195906: val_loss -0.7303 
2023-10-26 16:43:43.196193: Pseudo dice [0.8317, 0.9235, 0.9656, 0.5213, 0.7532] 
2023-10-26 16:43:43.196444: Epoch time: 4.29 s 
2023-10-26 16:43:44.355490:  
2023-10-26 16:43:44.355781: Epoch 892 
2023-10-26 16:43:44.356019: Current learning rate: 0.00135 
2023-10-26 16:43:48.600950: train_loss -0.9118 
2023-10-26 16:43:48.601305: val_loss -0.7408 
2023-10-26 16:43:48.601550: Pseudo dice [0.8443, 0.9302, 0.9649, 0.5416, 0.7169] 
2023-10-26 16:43:48.601782: Epoch time: 4.25 s 
2023-10-26 16:43:49.956336:  
2023-10-26 16:43:49.956712: Epoch 893 
2023-10-26 16:43:49.957022: Current learning rate: 0.00134 
2023-10-26 16:43:54.221263: train_loss -0.9127 
2023-10-26 16:43:54.221637: val_loss -0.6688 
2023-10-26 16:43:54.221905: Pseudo dice [0.8256, 0.9175, 0.9657, 0.0, 0.7824] 
2023-10-26 16:43:54.222146: Epoch time: 4.27 s 
2023-10-26 16:43:55.409409:  
2023-10-26 16:43:55.409714: Epoch 894 
2023-10-26 16:43:55.409963: Current learning rate: 0.00133 
2023-10-26 16:43:59.652194: train_loss -0.9058 
2023-10-26 16:43:59.652572: val_loss -0.7198 
2023-10-26 16:43:59.652838: Pseudo dice [0.8349, 0.9182, 0.9652, 0.3866, 0.8185] 
2023-10-26 16:43:59.653075: Epoch time: 4.24 s 
2023-10-26 16:44:00.822057:  
2023-10-26 16:44:00.822365: Epoch 895 
2023-10-26 16:44:00.822641: Current learning rate: 0.00132 
2023-10-26 16:44:04.922351: train_loss -0.9129 
2023-10-26 16:44:04.922722: val_loss -0.7169 
2023-10-26 16:44:04.922994: Pseudo dice [0.8425, 0.923, 0.9675, 0.5201, 0.7707] 
2023-10-26 16:44:04.923227: Epoch time: 4.1 s 
2023-10-26 16:44:06.088236:  
2023-10-26 16:44:06.088552: Epoch 896 
2023-10-26 16:44:06.088810: Current learning rate: 0.0013 
2023-10-26 16:44:10.298050: train_loss -0.9093 
2023-10-26 16:44:10.298460: val_loss -0.7187 
2023-10-26 16:44:10.298718: Pseudo dice [0.8404, 0.9282, 0.967, 0.4914, 0.7845] 
2023-10-26 16:44:10.298950: Epoch time: 4.21 s 
2023-10-26 16:44:11.481691:  
2023-10-26 16:44:11.482089: Epoch 897 
2023-10-26 16:44:11.482460: Current learning rate: 0.00129 
2023-10-26 16:44:15.539305: train_loss -0.9127 
2023-10-26 16:44:15.539697: val_loss -0.6658 
2023-10-26 16:44:15.539958: Pseudo dice [0.8448, 0.9193, 0.9654, 0.0435, 0.7264] 
2023-10-26 16:44:15.540196: Epoch time: 4.06 s 
2023-10-26 16:44:16.703624:  
2023-10-26 16:44:16.703922: Epoch 898 
2023-10-26 16:44:16.704187: Current learning rate: 0.00128 
2023-10-26 16:44:20.943448: train_loss -0.9076 
2023-10-26 16:44:20.943827: val_loss -0.635 
2023-10-26 16:44:20.944086: Pseudo dice [0.8439, 0.9166, 0.9667, 0.3698, 0.672] 
2023-10-26 16:44:20.944309: Epoch time: 4.24 s 
2023-10-26 16:44:22.132185:  
2023-10-26 16:44:22.132482: Epoch 899 
2023-10-26 16:44:22.132722: Current learning rate: 0.00127 
2023-10-26 16:44:26.312569: train_loss -0.9107 
2023-10-26 16:44:26.313284: val_loss -0.7085 
2023-10-26 16:44:26.313553: Pseudo dice [0.8408, 0.9204, 0.9666, 0.3452, 0.7781] 
2023-10-26 16:44:26.313781: Epoch time: 4.18 s 
2023-10-26 16:44:27.799949:  
2023-10-26 16:44:27.800296: Epoch 900 
2023-10-26 16:44:27.800547: Current learning rate: 0.00126 
2023-10-26 16:44:32.056211: train_loss -0.9086 
2023-10-26 16:44:32.056577: val_loss -0.708 
2023-10-26 16:44:32.056838: Pseudo dice [0.8295, 0.917, 0.9665, 0.5045, 0.7973] 
2023-10-26 16:44:32.057075: Epoch time: 4.26 s 
2023-10-26 16:44:33.260880:  
2023-10-26 16:44:33.261239: Epoch 901 
2023-10-26 16:44:33.261509: Current learning rate: 0.00125 
2023-10-26 16:44:37.584918: train_loss -0.9087 
2023-10-26 16:44:37.585363: val_loss -0.7062 
2023-10-26 16:44:37.585637: Pseudo dice [0.8401, 0.9234, 0.9668, 0.3932, 0.7876] 
2023-10-26 16:44:37.585870: Epoch time: 4.32 s 
2023-10-26 16:44:38.734255:  
2023-10-26 16:44:38.734593: Epoch 902 
2023-10-26 16:44:38.734835: Current learning rate: 0.00124 
2023-10-26 16:44:43.006761: train_loss -0.913 
2023-10-26 16:44:43.007258: val_loss -0.7801 
2023-10-26 16:44:43.007627: Pseudo dice [0.8502, 0.9225, 0.9653, 0.5, 0.84] 
2023-10-26 16:44:43.007939: Epoch time: 4.27 s 
2023-10-26 16:44:44.252658:  
2023-10-26 16:44:44.252975: Epoch 903 
2023-10-26 16:44:44.253226: Current learning rate: 0.00122 
2023-10-26 16:44:48.498701: train_loss -0.91 
2023-10-26 16:44:48.499116: val_loss -0.7317 
2023-10-26 16:44:48.499447: Pseudo dice [0.8356, 0.9289, 0.9669, 0.6082, 0.7717] 
2023-10-26 16:44:48.499751: Epoch time: 4.25 s 
2023-10-26 16:44:49.639543:  
2023-10-26 16:44:49.639836: Epoch 904 
2023-10-26 16:44:49.640088: Current learning rate: 0.00121 
2023-10-26 16:44:54.108847: train_loss -0.9117 
2023-10-26 16:44:54.109294: val_loss -0.6942 
2023-10-26 16:44:54.109652: Pseudo dice [0.8244, 0.9199, 0.9679, 0.2196, 0.7705] 
2023-10-26 16:44:54.110140: Epoch time: 4.47 s 
2023-10-26 16:44:55.302539:  
2023-10-26 16:44:55.302859: Epoch 905 
2023-10-26 16:44:55.303183: Current learning rate: 0.0012 
2023-10-26 16:44:59.447417: train_loss -0.9149 
2023-10-26 16:44:59.447822: val_loss -0.6929 
2023-10-26 16:44:59.448102: Pseudo dice [0.8323, 0.9203, 0.9669, 0.3575, 0.7522] 
2023-10-26 16:44:59.448347: Epoch time: 4.15 s 
2023-10-26 16:45:00.764574:  
2023-10-26 16:45:00.764946: Epoch 906 
2023-10-26 16:45:00.765230: Current learning rate: 0.00119 
2023-10-26 16:45:04.897552: train_loss -0.9151 
2023-10-26 16:45:04.898383: val_loss -0.7483 
2023-10-26 16:45:04.898760: Pseudo dice [0.8346, 0.9201, 0.9666, 0.4716, 0.8309] 
2023-10-26 16:45:04.899104: Epoch time: 4.13 s 
2023-10-26 16:45:06.260684:  
2023-10-26 16:45:06.261031: Epoch 907 
2023-10-26 16:45:06.261281: Current learning rate: 0.00118 
2023-10-26 16:45:10.442866: train_loss -0.9162 
2023-10-26 16:45:10.443293: val_loss -0.74 
2023-10-26 16:45:10.443591: Pseudo dice [0.8361, 0.9231, 0.9668, 0.4377, 0.8314] 
2023-10-26 16:45:10.443848: Epoch time: 4.18 s 
2023-10-26 16:45:11.658696:  
2023-10-26 16:45:11.659033: Epoch 908 
2023-10-26 16:45:11.659309: Current learning rate: 0.00117 
2023-10-26 16:45:15.818027: train_loss -0.9135 
2023-10-26 16:45:15.818415: val_loss -0.7017 
2023-10-26 16:45:15.818678: Pseudo dice [0.8306, 0.9214, 0.9648, 0.0498, 0.839] 
2023-10-26 16:45:15.818926: Epoch time: 4.16 s 
2023-10-26 16:45:16.990242:  
2023-10-26 16:45:16.990563: Epoch 909 
2023-10-26 16:45:16.990804: Current learning rate: 0.00116 
2023-10-26 16:45:21.102736: train_loss -0.9117 
2023-10-26 16:45:21.103142: val_loss -0.6664 
2023-10-26 16:45:21.103397: Pseudo dice [0.8098, 0.9196, 0.9674, 0.0043, 0.7777] 
2023-10-26 16:45:21.103637: Epoch time: 4.11 s 
2023-10-26 16:45:22.268134:  
2023-10-26 16:45:22.268455: Epoch 910 
2023-10-26 16:45:22.268701: Current learning rate: 0.00115 
2023-10-26 16:45:26.486814: train_loss -0.9132 
2023-10-26 16:45:26.487190: val_loss -0.7278 
2023-10-26 16:45:26.487443: Pseudo dice [0.8411, 0.9231, 0.965, 0.4116, 0.786] 
2023-10-26 16:45:26.487685: Epoch time: 4.22 s 
2023-10-26 16:45:27.659623:  
2023-10-26 16:45:27.659912: Epoch 911 
2023-10-26 16:45:27.660146: Current learning rate: 0.00113 
2023-10-26 16:45:31.786256: train_loss -0.9131 
2023-10-26 16:45:31.786635: val_loss -0.6803 
2023-10-26 16:45:31.786896: Pseudo dice [0.8405, 0.9201, 0.965, 0.3486, 0.7419] 
2023-10-26 16:45:31.787143: Epoch time: 4.13 s 
2023-10-26 16:45:32.963517:  
2023-10-26 16:45:32.963857: Epoch 912 
2023-10-26 16:45:32.964164: Current learning rate: 0.00112 
2023-10-26 16:45:37.030453: train_loss -0.9155 
2023-10-26 16:45:37.030829: val_loss -0.6881 
2023-10-26 16:45:37.031099: Pseudo dice [0.8335, 0.9209, 0.966, 0.3251, 0.76] 
2023-10-26 16:45:37.031333: Epoch time: 4.07 s 
2023-10-26 16:45:38.191194:  
2023-10-26 16:45:38.191492: Epoch 913 
2023-10-26 16:45:38.191734: Current learning rate: 0.00111 
2023-10-26 16:45:42.400037: train_loss -0.9118 
2023-10-26 16:45:42.400453: val_loss -0.7065 
2023-10-26 16:45:42.400730: Pseudo dice [0.8323, 0.9175, 0.9664, 0.4461, 0.7931] 
2023-10-26 16:45:42.400990: Epoch time: 4.21 s 
2023-10-26 16:45:43.793906:  
2023-10-26 16:45:43.794214: Epoch 914 
2023-10-26 16:45:43.794473: Current learning rate: 0.0011 
2023-10-26 16:45:48.037161: train_loss -0.9123 
2023-10-26 16:45:48.037548: val_loss -0.6989 
2023-10-26 16:45:48.037800: Pseudo dice [0.8296, 0.9187, 0.9649, 0.2872, 0.7964] 
2023-10-26 16:45:48.038039: Epoch time: 4.24 s 
2023-10-26 16:45:49.224891:  
2023-10-26 16:45:49.225171: Epoch 915 
2023-10-26 16:45:49.225405: Current learning rate: 0.00109 
2023-10-26 16:45:53.654514: train_loss -0.9149 
2023-10-26 16:45:53.655044: val_loss -0.7275 
2023-10-26 16:45:53.655384: Pseudo dice [0.8397, 0.9225, 0.9648, 0.5784, 0.7508] 
2023-10-26 16:45:53.655653: Epoch time: 4.43 s 
2023-10-26 16:45:54.803550:  
2023-10-26 16:45:54.803838: Epoch 916 
2023-10-26 16:45:54.804081: Current learning rate: 0.00108 
2023-10-26 16:45:59.257487: train_loss -0.9159 
2023-10-26 16:45:59.257818: val_loss -0.6475 
2023-10-26 16:45:59.258067: Pseudo dice [0.8238, 0.9187, 0.9646, 0.1936, 0.6972] 
2023-10-26 16:45:59.258285: Epoch time: 4.45 s 
2023-10-26 16:46:00.397536:  
2023-10-26 16:46:00.397835: Epoch 917 
2023-10-26 16:46:00.398086: Current learning rate: 0.00106 
2023-10-26 16:46:04.730369: train_loss -0.9116 
2023-10-26 16:46:04.730701: val_loss -0.6971 
2023-10-26 16:46:04.730944: Pseudo dice [0.828, 0.9224, 0.9667, 0.1045, 0.7982] 
2023-10-26 16:46:04.731164: Epoch time: 4.33 s 
2023-10-26 16:46:05.868348:  
2023-10-26 16:46:05.868654: Epoch 918 
2023-10-26 16:46:05.868903: Current learning rate: 0.00105 
2023-10-26 16:46:10.188982: train_loss -0.9133 
2023-10-26 16:46:10.189331: val_loss -0.6844 
2023-10-26 16:46:10.189583: Pseudo dice [0.8343, 0.92, 0.9668, 0.4081, 0.7416] 
2023-10-26 16:46:10.189802: Epoch time: 4.32 s 
2023-10-26 16:46:11.419080:  
2023-10-26 16:46:11.419424: Epoch 919 
2023-10-26 16:46:11.419688: Current learning rate: 0.00104 
2023-10-26 16:46:15.748055: train_loss -0.9142 
2023-10-26 16:46:15.748420: val_loss -0.6788 
2023-10-26 16:46:15.748668: Pseudo dice [0.8367, 0.9204, 0.9685, 0.5285, 0.6371] 
2023-10-26 16:46:15.748901: Epoch time: 4.33 s 
2023-10-26 16:46:17.113361:  
2023-10-26 16:46:17.113765: Epoch 920 
2023-10-26 16:46:17.114086: Current learning rate: 0.00103 
2023-10-26 16:46:21.302918: train_loss -0.915 
2023-10-26 16:46:21.303342: val_loss -0.7342 
2023-10-26 16:46:21.303852: Pseudo dice [0.84, 0.9245, 0.9667, 0.5764, 0.7641] 
2023-10-26 16:46:21.304131: Epoch time: 4.19 s 
2023-10-26 16:46:22.459728:  
2023-10-26 16:46:22.460042: Epoch 921 
2023-10-26 16:46:22.460282: Current learning rate: 0.00102 
2023-10-26 16:46:26.784775: train_loss -0.9189 
2023-10-26 16:46:26.785145: val_loss -0.7039 
2023-10-26 16:46:26.785401: Pseudo dice [0.8312, 0.9213, 0.9682, 0.4234, 0.7741] 
2023-10-26 16:46:26.785627: Epoch time: 4.33 s 
2023-10-26 16:46:27.951134:  
2023-10-26 16:46:27.951441: Epoch 922 
2023-10-26 16:46:27.951701: Current learning rate: 0.00101 
2023-10-26 16:46:32.198023: train_loss -0.9154 
2023-10-26 16:46:32.198420: val_loss -0.7107 
2023-10-26 16:46:32.198735: Pseudo dice [0.835, 0.9205, 0.9655, 0.5093, 0.7647] 
2023-10-26 16:46:32.199013: Epoch time: 4.25 s 
2023-10-26 16:46:33.406745:  
2023-10-26 16:46:33.407048: Epoch 923 
2023-10-26 16:46:33.407285: Current learning rate: 0.001 
2023-10-26 16:46:37.579888: train_loss -0.9131 
2023-10-26 16:46:37.580279: val_loss -0.7227 
2023-10-26 16:46:37.580532: Pseudo dice [0.8361, 0.9204, 0.965, 0.4206, 0.8538] 
2023-10-26 16:46:37.580770: Epoch time: 4.17 s 
2023-10-26 16:46:38.787367:  
2023-10-26 16:46:38.787668: Epoch 924 
2023-10-26 16:46:38.787951: Current learning rate: 0.00098 
2023-10-26 16:46:43.023584: train_loss -0.9137 
2023-10-26 16:46:43.023986: val_loss -0.6713 
2023-10-26 16:46:43.024244: Pseudo dice [0.8474, 0.924, 0.9678, 0.441, 0.7007] 
2023-10-26 16:46:43.024464: Epoch time: 4.24 s 
2023-10-26 16:46:44.195672:  
2023-10-26 16:46:44.195974: Epoch 925 
2023-10-26 16:46:44.196273: Current learning rate: 0.00097 
2023-10-26 16:46:48.505089: train_loss -0.9125 
2023-10-26 16:46:48.505498: val_loss -0.6918 
2023-10-26 16:46:48.505762: Pseudo dice [0.8359, 0.9245, 0.9667, 0.5147, 0.7069] 
2023-10-26 16:46:48.506006: Epoch time: 4.31 s 
2023-10-26 16:46:49.666412:  
2023-10-26 16:46:49.666721: Epoch 926 
2023-10-26 16:46:49.666992: Current learning rate: 0.00096 
2023-10-26 16:46:53.923264: train_loss -0.9134 
2023-10-26 16:46:53.923655: val_loss -0.6943 
2023-10-26 16:46:53.923913: Pseudo dice [0.8316, 0.9223, 0.9672, 0.5349, 0.7257] 
2023-10-26 16:46:53.924131: Epoch time: 4.26 s 
2023-10-26 16:46:55.288980:  
2023-10-26 16:46:55.289276: Epoch 927 
2023-10-26 16:46:55.289526: Current learning rate: 0.00095 
2023-10-26 16:46:59.395699: train_loss -0.9192 
2023-10-26 16:46:59.396129: val_loss -0.7022 
2023-10-26 16:46:59.396387: Pseudo dice [0.8437, 0.9246, 0.965, 0.4786, 0.7663] 
2023-10-26 16:46:59.396625: Epoch time: 4.11 s 
2023-10-26 16:47:00.567057:  
2023-10-26 16:47:00.567387: Epoch 928 
2023-10-26 16:47:00.567644: Current learning rate: 0.00094 
2023-10-26 16:47:04.748016: train_loss -0.9171 
2023-10-26 16:47:04.748378: val_loss -0.7452 
2023-10-26 16:47:04.748637: Pseudo dice [0.8335, 0.9233, 0.967, 0.6095, 0.8196] 
2023-10-26 16:47:04.748884: Epoch time: 4.18 s 
2023-10-26 16:47:05.920215:  
2023-10-26 16:47:05.920514: Epoch 929 
2023-10-26 16:47:05.920763: Current learning rate: 0.00092 
2023-10-26 16:47:10.229407: train_loss -0.9131 
2023-10-26 16:47:10.229746: val_loss -0.647 
2023-10-26 16:47:10.230007: Pseudo dice [0.8397, 0.9229, 0.9667, 0.3255, 0.6213] 
2023-10-26 16:47:10.230221: Epoch time: 4.31 s 
2023-10-26 16:47:11.398557:  
2023-10-26 16:47:11.398862: Epoch 930 
2023-10-26 16:47:11.399113: Current learning rate: 0.00091 
2023-10-26 16:47:15.646667: train_loss -0.916 
2023-10-26 16:47:15.647089: val_loss -0.7022 
2023-10-26 16:47:15.647360: Pseudo dice [0.8402, 0.9264, 0.9666, 0.4558, 0.7145] 
2023-10-26 16:47:15.647597: Epoch time: 4.25 s 
2023-10-26 16:47:16.806967:  
2023-10-26 16:47:16.807255: Epoch 931 
2023-10-26 16:47:16.807504: Current learning rate: 0.0009 
2023-10-26 16:47:21.071548: train_loss -0.9179 
2023-10-26 16:47:21.071910: val_loss -0.7326 
2023-10-26 16:47:21.072171: Pseudo dice [0.8372, 0.9244, 0.9649, 0.2727, 0.828] 
2023-10-26 16:47:21.072391: Epoch time: 4.27 s 
2023-10-26 16:47:22.246056:  
2023-10-26 16:47:22.246403: Epoch 932 
2023-10-26 16:47:22.246667: Current learning rate: 0.00089 
2023-10-26 16:47:26.488553: train_loss -0.9203 
2023-10-26 16:47:26.488929: val_loss -0.7254 
2023-10-26 16:47:26.489177: Pseudo dice [0.8407, 0.9262, 0.9658, 0.5522, 0.7753] 
2023-10-26 16:47:26.489391: Epoch time: 4.24 s 
2023-10-26 16:47:27.805634:  
2023-10-26 16:47:27.805937: Epoch 933 
2023-10-26 16:47:27.806181: Current learning rate: 0.00088 
2023-10-26 16:47:31.932276: train_loss -0.918 
2023-10-26 16:47:31.932710: val_loss -0.6757 
2023-10-26 16:47:31.933077: Pseudo dice [0.826, 0.9223, 0.967, 0.4518, 0.605] 
2023-10-26 16:47:31.933460: Epoch time: 4.13 s 
2023-10-26 16:47:33.161804:  
2023-10-26 16:47:33.162173: Epoch 934 
2023-10-26 16:47:33.162506: Current learning rate: 0.00087 
2023-10-26 16:47:37.360738: train_loss -0.9187 
2023-10-26 16:47:37.361142: val_loss -0.7008 
2023-10-26 16:47:37.361399: Pseudo dice [0.8404, 0.9248, 0.9667, 0.4887, 0.719] 
2023-10-26 16:47:37.361833: Epoch time: 4.2 s 
2023-10-26 16:47:38.581711:  
2023-10-26 16:47:38.582014: Epoch 935 
2023-10-26 16:47:38.582255: Current learning rate: 0.00085 
2023-10-26 16:47:42.820895: train_loss -0.9151 
2023-10-26 16:47:42.821258: val_loss -0.7016 
2023-10-26 16:47:42.821510: Pseudo dice [0.8354, 0.9237, 0.9663, 0.3601, 0.7661] 
2023-10-26 16:47:42.821744: Epoch time: 4.24 s 
2023-10-26 16:47:44.020056:  
2023-10-26 16:47:44.020341: Epoch 936 
2023-10-26 16:47:44.020583: Current learning rate: 0.00084 
2023-10-26 16:47:48.286267: train_loss -0.9213 
2023-10-26 16:47:48.286674: val_loss -0.6759 
2023-10-26 16:47:48.286943: Pseudo dice [0.83, 0.9217, 0.9659, 0.3392, 0.7315] 
2023-10-26 16:47:48.287207: Epoch time: 4.27 s 
2023-10-26 16:47:49.472048:  
2023-10-26 16:47:49.472364: Epoch 937 
2023-10-26 16:47:49.472603: Current learning rate: 0.00083 
2023-10-26 16:47:53.817388: train_loss -0.9131 
2023-10-26 16:47:53.817740: val_loss -0.7314 
2023-10-26 16:47:53.817983: Pseudo dice [0.833, 0.9245, 0.9667, 0.5019, 0.8197] 
2023-10-26 16:47:53.818197: Epoch time: 4.35 s 
2023-10-26 16:47:54.989235:  
2023-10-26 16:47:54.989506: Epoch 938 
2023-10-26 16:47:54.989745: Current learning rate: 0.00082 
2023-10-26 16:47:59.133631: train_loss -0.9141 
2023-10-26 16:47:59.134050: val_loss -0.7002 
2023-10-26 16:47:59.134292: Pseudo dice [0.8371, 0.9262, 0.9667, 0.3914, 0.7684] 
2023-10-26 16:47:59.134530: Epoch time: 4.14 s 
2023-10-26 16:48:00.302102:  
2023-10-26 16:48:00.302401: Epoch 939 
2023-10-26 16:48:00.302636: Current learning rate: 0.00081 
2023-10-26 16:48:04.230963: train_loss -0.9146 
2023-10-26 16:48:04.231345: val_loss -0.7147 
2023-10-26 16:48:04.231625: Pseudo dice [0.835, 0.9231, 0.9657, 0.3205, 0.8097] 
2023-10-26 16:48:04.231867: Epoch time: 3.93 s 
2023-10-26 16:48:05.546550:  
2023-10-26 16:48:05.546835: Epoch 940 
2023-10-26 16:48:05.547079: Current learning rate: 0.00079 
2023-10-26 16:48:09.528798: train_loss -0.9094 
2023-10-26 16:48:09.529189: val_loss -0.7231 
2023-10-26 16:48:09.529438: Pseudo dice [0.8388, 0.9238, 0.9665, 0.5206, 0.7819] 
2023-10-26 16:48:09.529671: Epoch time: 3.98 s 
2023-10-26 16:48:10.678849:  
2023-10-26 16:48:10.679169: Epoch 941 
2023-10-26 16:48:10.679420: Current learning rate: 0.00078 
2023-10-26 16:48:14.687068: train_loss -0.9184 
2023-10-26 16:48:14.687493: val_loss -0.7133 
2023-10-26 16:48:14.687757: Pseudo dice [0.8356, 0.9186, 0.9667, 0.5233, 0.7591] 
2023-10-26 16:48:14.688007: Epoch time: 4.01 s 
2023-10-26 16:48:15.833516:  
2023-10-26 16:48:15.833814: Epoch 942 
2023-10-26 16:48:15.834059: Current learning rate: 0.00077 
2023-10-26 16:48:19.775537: train_loss -0.9141 
2023-10-26 16:48:19.775905: val_loss -0.7211 
2023-10-26 16:48:19.776166: Pseudo dice [0.8384, 0.9247, 0.9633, 0.4569, 0.7868] 
2023-10-26 16:48:19.776397: Epoch time: 3.94 s 
2023-10-26 16:48:20.919485:  
2023-10-26 16:48:20.919793: Epoch 943 
2023-10-26 16:48:20.920053: Current learning rate: 0.00076 
2023-10-26 16:48:24.928409: train_loss -0.9151 
2023-10-26 16:48:24.928828: val_loss -0.6828 
2023-10-26 16:48:24.929200: Pseudo dice [0.8493, 0.927, 0.9664, 0.4487, 0.6809] 
2023-10-26 16:48:24.929499: Epoch time: 4.01 s 
2023-10-26 16:48:26.079253:  
2023-10-26 16:48:26.079561: Epoch 944 
2023-10-26 16:48:26.079800: Current learning rate: 0.00075 
2023-10-26 16:48:30.169256: train_loss -0.9162 
2023-10-26 16:48:30.169663: val_loss -0.6618 
2023-10-26 16:48:30.169929: Pseudo dice [0.829, 0.9192, 0.9662, 0.0, 0.8018] 
2023-10-26 16:48:30.170159: Epoch time: 4.09 s 
2023-10-26 16:48:31.326045:  
2023-10-26 16:48:31.326335: Epoch 945 
2023-10-26 16:48:31.326571: Current learning rate: 0.00074 
2023-10-26 16:48:35.394423: train_loss -0.9126 
2023-10-26 16:48:35.394773: val_loss -0.6785 
2023-10-26 16:48:35.395033: Pseudo dice [0.8214, 0.9219, 0.9676, 0.0478, 0.7744] 
2023-10-26 16:48:35.395250: Epoch time: 4.07 s 
2023-10-26 16:48:36.573588:  
2023-10-26 16:48:36.573860: Epoch 946 
2023-10-26 16:48:36.574121: Current learning rate: 0.00072 
2023-10-26 16:48:40.622825: train_loss -0.9184 
2023-10-26 16:48:40.623209: val_loss -0.692 
2023-10-26 16:48:40.623489: Pseudo dice [0.8351, 0.9235, 0.9669, 0.3118, 0.7365] 
2023-10-26 16:48:40.623730: Epoch time: 4.05 s 
2023-10-26 16:48:41.954885:  
2023-10-26 16:48:41.955183: Epoch 947 
2023-10-26 16:48:41.955412: Current learning rate: 0.00071 
2023-10-26 16:48:46.028316: train_loss -0.917 
2023-10-26 16:48:46.028677: val_loss -0.6603 
2023-10-26 16:48:46.028948: Pseudo dice [0.8331, 0.9207, 0.9652, 0.2915, 0.7442] 
2023-10-26 16:48:46.029181: Epoch time: 4.07 s 
2023-10-26 16:48:47.207065:  
2023-10-26 16:48:47.207371: Epoch 948 
2023-10-26 16:48:47.207618: Current learning rate: 0.0007 
2023-10-26 16:48:51.317897: train_loss -0.9218 
2023-10-26 16:48:51.318280: val_loss -0.6621 
2023-10-26 16:48:51.318586: Pseudo dice [0.8367, 0.9203, 0.9653, 0.3532, 0.7343] 
2023-10-26 16:48:51.318856: Epoch time: 4.11 s 
2023-10-26 16:48:52.478924:  
2023-10-26 16:48:52.479223: Epoch 949 
2023-10-26 16:48:52.479465: Current learning rate: 0.00069 
2023-10-26 16:48:56.593755: train_loss -0.9123 
2023-10-26 16:48:56.594135: val_loss -0.6893 
2023-10-26 16:48:56.594387: Pseudo dice [0.8415, 0.9236, 0.9663, 0.5784, 0.6999] 
2023-10-26 16:48:56.594614: Epoch time: 4.12 s 
2023-10-26 16:48:57.845519:  
2023-10-26 16:48:57.845805: Epoch 950 
2023-10-26 16:48:57.846047: Current learning rate: 0.00067 
2023-10-26 16:49:01.874717: train_loss -0.9167 
2023-10-26 16:49:01.875081: val_loss -0.674 
2023-10-26 16:49:01.875325: Pseudo dice [0.834, 0.9202, 0.9654, 0.1762, 0.745] 
2023-10-26 16:49:01.875541: Epoch time: 4.03 s 
2023-10-26 16:49:03.029084:  
2023-10-27 09:07:30.616539: Epoch 950 
2023-10-27 09:07:30.617072: Current learning rate: 0.00067 
2023-10-27 09:07:36.479557: train_loss -0.9141 
2023-10-27 09:07:36.480053: val_loss -0.6742 
2023-10-27 09:07:36.480365: Pseudo dice [0.8341, 0.9216, 0.9672, 0.3416, 0.673] 
2023-10-27 09:07:36.480686: Epoch time: 5.86 s 
2023-10-27 09:07:37.700794:  
2023-10-27 09:07:37.701223: Epoch 951 
2023-10-27 09:07:37.701523: Current learning rate: 0.00066 
2023-10-27 09:07:42.412765: train_loss -0.9169 
2023-10-27 09:07:42.413340: val_loss -0.6995 
2023-10-27 09:07:42.413633: Pseudo dice [0.8257, 0.9221, 0.9666, 0.2458, 0.8038] 
2023-10-27 09:07:42.413886: Epoch time: 4.71 s 
2023-10-27 09:07:43.632385:  
2023-10-27 09:07:43.632796: Epoch 952 
2023-10-27 09:07:43.633098: Current learning rate: 0.00065 
2023-10-27 09:07:48.585483: train_loss -0.9158 
2023-10-27 09:07:48.585963: val_loss -0.6905 
2023-10-27 09:07:48.586246: Pseudo dice [0.8351, 0.9228, 0.9659, 0.3501, 0.7457] 
2023-10-27 09:07:48.586533: Epoch time: 4.95 s 
2023-10-27 09:07:50.017006:  
2023-10-27 09:07:50.017583: Epoch 953 
2023-10-27 09:07:50.017879: Current learning rate: 0.00064 
2023-10-27 09:07:54.434256: train_loss -0.9174 
2023-10-27 09:07:54.434866: val_loss -0.7099 
2023-10-27 09:07:54.435198: Pseudo dice [0.8284, 0.9255, 0.9655, 0.323, 0.7403] 
2023-10-27 09:07:54.435518: Epoch time: 4.42 s 
2023-10-27 09:07:55.653186:  
2023-10-27 09:07:55.653654: Epoch 954 
2023-10-27 09:07:55.653919: Current learning rate: 0.00063 
2023-10-27 09:07:59.935136: train_loss -0.9152 
2023-10-27 09:07:59.935635: val_loss -0.6882 
2023-10-27 09:07:59.935924: Pseudo dice [0.8293, 0.9238, 0.9654, 0.3389, 0.7695] 
2023-10-27 09:07:59.936177: Epoch time: 4.28 s 
2023-10-27 09:08:01.158705:  
2023-10-27 09:08:01.159187: Epoch 955 
2023-10-27 09:08:01.159549: Current learning rate: 0.00061 
2023-10-27 09:08:05.486322: train_loss -0.9159 
2023-10-27 09:08:05.486831: val_loss -0.669 
2023-10-27 09:08:05.487130: Pseudo dice [0.8346, 0.9231, 0.9654, 0.25, 0.6707] 
2023-10-27 09:08:05.487481: Epoch time: 4.33 s 
2023-10-27 09:08:06.698198:  
2023-10-27 09:08:06.698574: Epoch 956 
2023-10-27 09:08:06.698843: Current learning rate: 0.0006 
2023-10-27 09:08:10.930284: train_loss -0.9205 
2023-10-27 09:08:10.930826: val_loss -0.6896 
2023-10-27 09:08:10.931124: Pseudo dice [0.8361, 0.925, 0.9662, 0.3958, 0.7332] 
2023-10-27 09:08:10.931398: Epoch time: 4.23 s 
2023-10-27 09:08:12.138166:  
2023-10-27 09:08:12.138552: Epoch 957 
2023-10-27 09:08:12.138821: Current learning rate: 0.00059 
2023-10-27 09:08:16.453895: train_loss -0.92 
2023-10-27 09:08:16.454391: val_loss -0.644 
2023-10-27 09:08:16.454728: Pseudo dice [0.8359, 0.919, 0.966, 0.2296, 0.7362] 
2023-10-27 09:08:16.454979: Epoch time: 4.32 s 
2023-10-27 09:08:17.661077:  
2023-10-27 09:08:17.661398: Epoch 958 
2023-10-27 09:08:17.661674: Current learning rate: 0.00058 
2023-10-27 09:08:21.905162: train_loss -0.923 
2023-10-27 09:08:21.909061: val_loss -0.6583 
2023-10-27 09:08:21.909433: Pseudo dice [0.8293, 0.9205, 0.9651, 0.179, 0.7336] 
2023-10-27 09:08:21.909782: Epoch time: 4.24 s 
2023-10-27 09:08:23.116487:  
2023-10-27 09:08:23.119985: Epoch 959 
2023-10-27 09:08:23.120656: Current learning rate: 0.00056 
2023-10-27 09:08:27.403369: train_loss -0.9139 
2023-10-27 09:08:27.407742: val_loss -0.6557 
2023-10-27 09:08:27.408547: Pseudo dice [0.8329, 0.9188, 0.9653, 0.2379, 0.748] 
2023-10-27 09:08:27.408836: Epoch time: 4.29 s 
2023-10-27 09:08:28.790842:  
2023-10-27 09:08:28.794573: Epoch 960 
2023-10-27 09:08:28.795022: Current learning rate: 0.00055 
2023-10-27 09:08:33.047484: train_loss -0.9153 
2023-10-27 09:08:33.048029: val_loss -0.6939 
2023-10-27 09:08:33.048329: Pseudo dice [0.8308, 0.9223, 0.967, 0.2493, 0.7751] 
2023-10-27 09:08:33.048918: Epoch time: 4.26 s 
2023-10-27 09:08:34.264484:  
2023-10-27 09:08:34.264866: Epoch 961 
2023-10-27 09:08:34.265149: Current learning rate: 0.00054 
2023-10-27 09:08:38.597355: train_loss -0.9165 
2023-10-27 09:08:38.597928: val_loss -0.6579 
2023-10-27 09:08:38.598235: Pseudo dice [0.8285, 0.9195, 0.9667, 0.1739, 0.7326] 
2023-10-27 09:08:38.598504: Epoch time: 4.33 s 
2023-10-27 09:08:39.807588:  
2023-10-27 09:08:39.807937: Epoch 962 
2023-10-27 09:08:39.808215: Current learning rate: 0.00053 
2023-10-27 09:08:44.112275: train_loss -0.9166 
2023-10-27 09:08:44.112763: val_loss -0.6827 
2023-10-27 09:08:44.113119: Pseudo dice [0.839, 0.9251, 0.9671, 0.2273, 0.7568] 
2023-10-27 09:08:44.113425: Epoch time: 4.31 s 
2023-10-27 09:08:45.348740:  
2023-10-27 09:08:45.349090: Epoch 963 
2023-10-27 09:08:45.349358: Current learning rate: 0.00051 
2023-10-27 09:08:49.607444: train_loss -0.9175 
2023-10-27 09:08:49.607894: val_loss -0.6688 
2023-10-27 09:08:49.608186: Pseudo dice [0.8342, 0.9208, 0.9663, 0.3074, 0.7209] 
2023-10-27 09:08:49.608478: Epoch time: 4.26 s 
2023-10-27 09:08:50.807516:  
2023-10-27 09:08:50.807856: Epoch 964 
2023-10-27 09:08:50.808234: Current learning rate: 0.0005 
2023-10-27 09:08:55.138661: train_loss -0.9187 
2023-10-27 09:08:55.139208: val_loss -0.6728 
2023-10-27 09:08:55.139504: Pseudo dice [0.8362, 0.9238, 0.965, 0.3487, 0.7252] 
2023-10-27 09:08:55.139758: Epoch time: 4.33 s 
2023-10-27 09:08:56.341935:  
2023-10-27 09:08:56.342262: Epoch 965 
2023-10-27 09:08:56.342533: Current learning rate: 0.00049 
2023-10-27 09:09:00.652813: train_loss -0.9146 
2023-10-27 09:09:00.653313: val_loss -0.6014 
2023-10-27 09:09:00.653606: Pseudo dice [0.8401, 0.9194, 0.9655, 0.2731, 0.6481] 
2023-10-27 09:09:00.653850: Epoch time: 4.31 s 
2023-10-27 09:09:02.033199:  
2023-10-27 09:09:02.033538: Epoch 966 
2023-10-27 09:09:02.033811: Current learning rate: 0.00048 
2023-10-27 09:09:06.385555: train_loss -0.9167 
2023-10-27 09:09:06.386074: val_loss -0.6359 
2023-10-27 09:09:06.386363: Pseudo dice [0.834, 0.9228, 0.9672, 0.2723, 0.6479] 
2023-10-27 09:09:06.386636: Epoch time: 4.35 s 
2023-10-27 09:09:07.585966:  
2023-10-27 09:09:07.586351: Epoch 967 
2023-10-27 09:09:07.586619: Current learning rate: 0.00046 
2023-10-27 09:09:11.931180: train_loss -0.9194 
2023-10-27 09:09:11.931607: val_loss -0.6985 
2023-10-27 09:09:11.931926: Pseudo dice [0.8382, 0.9272, 0.9657, 0.2441, 0.7552] 
2023-10-27 09:09:11.932230: Epoch time: 4.35 s 
2023-10-27 09:09:13.127946:  
2023-10-27 09:09:13.128293: Epoch 968 
2023-10-27 09:09:13.128563: Current learning rate: 0.00045 
2023-10-27 09:09:17.484069: train_loss -0.9205 
2023-10-27 09:09:17.484574: val_loss -0.6992 
2023-10-27 09:09:17.484877: Pseudo dice [0.8368, 0.9263, 0.9662, 0.2472, 0.7741] 
2023-10-27 09:09:17.485177: Epoch time: 4.36 s 
2023-10-27 09:09:18.692014:  
2023-10-27 09:09:18.692362: Epoch 969 
2023-10-27 09:09:18.692636: Current learning rate: 0.00044 
2023-10-27 09:09:23.038688: train_loss -0.9167 
2023-10-27 09:09:23.039141: val_loss -0.6805 
2023-10-27 09:09:23.039442: Pseudo dice [0.8328, 0.9205, 0.9655, 0.2341, 0.7826] 
2023-10-27 09:09:23.039695: Epoch time: 4.35 s 
2023-10-27 09:09:24.252079:  
2023-10-27 09:09:24.252531: Epoch 970 
2023-10-27 09:09:24.252810: Current learning rate: 0.00043 
2023-10-27 09:09:28.549161: train_loss -0.9186 
2023-10-27 09:09:28.549682: val_loss -0.653 
2023-10-27 09:09:28.549976: Pseudo dice [0.8379, 0.9253, 0.9664, 0.2592, 0.6943] 
2023-10-27 09:09:28.550247: Epoch time: 4.3 s 
2023-10-27 09:09:29.757670:  
2023-10-27 09:09:29.758005: Epoch 971 
2023-10-27 09:09:29.758284: Current learning rate: 0.00041 
2023-10-27 09:09:34.113602: train_loss -0.916 
2023-10-27 09:09:34.114195: val_loss -0.6558 
2023-10-27 09:09:34.114500: Pseudo dice [0.836, 0.9233, 0.9663, 0.235, 0.7114] 
2023-10-27 09:09:34.114771: Epoch time: 4.36 s 
2023-10-27 09:09:35.510702:  
2023-10-27 09:09:35.511030: Epoch 972 
2023-10-27 09:09:35.511323: Current learning rate: 0.0004 
2023-10-27 09:09:39.900177: train_loss -0.9192 
2023-10-27 09:09:39.900732: val_loss -0.672 
2023-10-27 09:09:39.901024: Pseudo dice [0.8377, 0.9243, 0.9675, 0.2983, 0.7184] 
2023-10-27 09:09:39.901333: Epoch time: 4.39 s 
2023-10-27 09:09:41.106925:  
2023-10-27 09:09:41.107249: Epoch 973 
2023-10-27 09:09:41.107516: Current learning rate: 0.00039 
2023-10-27 09:09:45.450590: train_loss -0.9181 
2023-10-27 09:09:45.451114: val_loss -0.5906 
2023-10-27 09:09:45.451437: Pseudo dice [0.8273, 0.9194, 0.9655, 0.2543, 0.62] 
2023-10-27 09:09:45.451702: Epoch time: 4.34 s 
2023-10-27 09:09:46.662849:  
2023-10-27 09:09:46.663355: Epoch 974 
2023-10-27 09:09:46.663642: Current learning rate: 0.00037 
2023-10-27 09:09:50.985120: train_loss -0.919 
2023-10-27 09:09:50.985567: val_loss -0.7011 
2023-10-27 09:09:50.985880: Pseudo dice [0.8352, 0.9236, 0.9653, 0.2956, 0.7665] 
2023-10-27 09:09:50.986135: Epoch time: 4.32 s 
2023-10-27 09:09:52.185213:  
2023-10-27 09:09:52.185568: Epoch 975 
2023-10-27 09:09:52.185840: Current learning rate: 0.00036 
2023-10-27 09:09:56.598004: train_loss -0.9213 
2023-10-27 09:09:56.598480: val_loss -0.6491 
2023-10-27 09:09:56.598758: Pseudo dice [0.8327, 0.9176, 0.9644, 0.2303, 0.7208] 
2023-10-27 09:09:56.599040: Epoch time: 4.41 s 
2023-10-27 09:09:57.804732:  
2023-10-27 09:09:57.805138: Epoch 976 
2023-10-27 09:09:57.805432: Current learning rate: 0.00035 
2023-10-27 09:10:02.146850: train_loss -0.9165 
2023-10-27 09:10:02.147352: val_loss -0.6785 
2023-10-27 09:10:02.147656: Pseudo dice [0.8376, 0.9257, 0.9658, 0.2751, 0.7215] 
2023-10-27 09:10:02.147913: Epoch time: 4.34 s 
2023-10-27 09:10:03.360507:  
2023-10-27 09:10:03.360843: Epoch 977 
2023-10-27 09:10:03.361145: Current learning rate: 0.00034 
2023-10-27 09:10:07.642398: train_loss -0.923 
2023-10-27 09:10:07.642859: val_loss -0.6369 
2023-10-27 09:10:07.643180: Pseudo dice [0.831, 0.9218, 0.9663, 0.2767, 0.6946] 
2023-10-27 09:10:07.643455: Epoch time: 4.28 s 
2023-10-27 09:10:08.835108:  
2023-10-27 09:10:08.835422: Epoch 978 
2023-10-27 09:10:08.835678: Current learning rate: 0.00032 
2023-10-27 09:10:13.116432: train_loss -0.9154 
2023-10-27 09:10:13.116940: val_loss -0.7021 
2023-10-27 09:10:13.117363: Pseudo dice [0.8392, 0.9248, 0.9642, 0.2964, 0.7779] 
2023-10-27 09:10:13.117687: Epoch time: 4.28 s 
2023-10-27 09:10:14.514952:  
2023-10-27 09:10:14.515401: Epoch 979 
2023-10-27 09:10:14.515685: Current learning rate: 0.00031 
2023-10-27 09:10:18.796002: train_loss -0.9214 
2023-10-27 09:10:18.796457: val_loss -0.6555 
2023-10-27 09:10:18.796751: Pseudo dice [0.8364, 0.9215, 0.9649, 0.3197, 0.7059] 
2023-10-27 09:10:18.796998: Epoch time: 4.28 s 
2023-10-27 09:10:19.997952:  
2023-10-27 09:10:19.998301: Epoch 980 
2023-10-27 09:10:19.998592: Current learning rate: 0.0003 
2023-10-27 09:10:24.261883: train_loss -0.9199 
2023-10-27 09:10:24.262368: val_loss -0.6925 
2023-10-27 09:10:24.262706: Pseudo dice [0.8363, 0.9227, 0.965, 0.2717, 0.7705] 
2023-10-27 09:10:24.262997: Epoch time: 4.26 s 
2023-10-27 09:10:25.463470:  
2023-10-27 09:10:25.463817: Epoch 981 
2023-10-27 09:10:25.464089: Current learning rate: 0.00028 
2023-10-27 09:10:29.766803: train_loss -0.9195 
2023-10-27 09:10:29.767273: val_loss -0.6755 
2023-10-27 09:10:29.767587: Pseudo dice [0.8327, 0.9195, 0.9643, 0.2792, 0.7525] 
2023-10-27 09:10:29.767864: Epoch time: 4.3 s 
2023-10-27 09:10:30.964759:  
2023-10-27 09:10:30.965110: Epoch 982 
2023-10-27 09:10:30.965385: Current learning rate: 0.00027 
2023-10-27 09:10:35.295200: train_loss -0.9159 
2023-10-27 09:10:35.295713: val_loss -0.6309 
2023-10-27 09:10:35.296207: Pseudo dice [0.8277, 0.9216, 0.9662, 0.2508, 0.6568] 
2023-10-27 09:10:35.296520: Epoch time: 4.33 s 
2023-10-27 09:10:36.499860:  
2023-10-27 09:10:36.500230: Epoch 983 
2023-10-27 09:10:36.500521: Current learning rate: 0.00026 
2023-10-27 09:10:40.802325: train_loss -0.9169 
2023-10-27 09:10:40.806709: val_loss -0.6275 
2023-10-27 09:10:40.806993: Pseudo dice [0.831, 0.9203, 0.965, 0.3202, 0.6076] 
2023-10-27 09:10:40.807283: Epoch time: 4.3 s 
2023-10-27 09:10:42.013287:  
2023-10-27 09:10:42.013613: Epoch 984 
2023-10-27 09:10:42.013919: Current learning rate: 0.00024 
2023-10-27 09:10:46.378745: train_loss -0.9215 
2023-10-27 09:10:46.382954: val_loss -0.7043 
2023-10-27 09:10:46.383750: Pseudo dice [0.8288, 0.9226, 0.9654, 0.2872, 0.8132] 
2023-10-27 09:10:46.384108: Epoch time: 4.37 s 
2023-10-27 09:10:47.754609:  
2023-10-27 09:10:47.755247: Epoch 985 
2023-10-27 09:10:47.755574: Current learning rate: 0.00023 
2023-10-27 09:10:52.074641: train_loss -0.9215 
2023-10-27 09:10:52.078243: val_loss -0.6258 
2023-10-27 09:10:52.078553: Pseudo dice [0.829, 0.9191, 0.9658, 0.2331, 0.7133] 
2023-10-27 09:10:52.078832: Epoch time: 4.32 s 
2023-10-27 09:10:53.299396:  
2023-10-27 09:10:53.299811: Epoch 986 
2023-10-27 09:10:53.300148: Current learning rate: 0.00021 
2023-10-27 09:10:57.689324: train_loss -0.9119 
2023-10-27 09:10:57.689769: val_loss -0.7107 
2023-10-27 09:10:57.690078: Pseudo dice [0.8268, 0.922, 0.9662, 0.2456, 0.8439] 
2023-10-27 09:10:57.690354: Epoch time: 4.39 s 
2023-10-27 09:10:58.901821:  
2023-10-27 09:10:58.902166: Epoch 987 
2023-10-27 09:10:58.902446: Current learning rate: 0.0002 
2023-10-27 09:11:03.248554: train_loss -0.9169 
2023-10-27 09:11:03.252345: val_loss -0.699 
2023-10-27 09:11:03.252883: Pseudo dice [0.8221, 0.9221, 0.9669, 0.3054, 0.7705] 
2023-10-27 09:11:03.253276: Epoch time: 4.35 s 
2023-10-27 09:11:04.477131:  
2023-10-27 09:11:04.477518: Epoch 988 
2023-10-27 09:11:04.477822: Current learning rate: 0.00019 
2023-10-27 09:11:08.829117: train_loss -0.9173 
2023-10-27 09:11:08.829574: val_loss -0.6557 
2023-10-27 09:11:08.829875: Pseudo dice [0.8286, 0.9206, 0.9661, 0.2949, 0.7259] 
2023-10-27 09:11:08.830185: Epoch time: 4.35 s 
2023-10-27 09:11:10.035646:  
2023-10-27 09:11:10.035969: Epoch 989 
2023-10-27 09:11:10.036246: Current learning rate: 0.00017 
2023-10-27 09:11:14.373733: train_loss -0.9196 
2023-10-27 09:11:14.374308: val_loss -0.6761 
2023-10-27 09:11:14.374604: Pseudo dice [0.8336, 0.9221, 0.9658, 0.2493, 0.7202] 
2023-10-27 09:11:14.374880: Epoch time: 4.34 s 
2023-10-27 09:11:15.586029:  
2023-10-27 09:11:15.586404: Epoch 990 
2023-10-27 09:11:15.586666: Current learning rate: 0.00016 
2023-10-27 09:11:19.963986: train_loss -0.9169 
2023-10-27 09:11:19.964421: val_loss -0.6793 
2023-10-27 09:11:19.964725: Pseudo dice [0.8319, 0.9222, 0.9658, 0.2446, 0.7685] 
2023-10-27 09:11:19.964988: Epoch time: 4.38 s 
2023-10-27 09:11:21.172540:  
2023-10-27 09:11:21.172864: Epoch 991 
2023-10-27 09:11:21.173138: Current learning rate: 0.00014 
2023-10-27 09:11:25.548911: train_loss -0.9166 
2023-10-27 09:11:25.552159: val_loss -0.6926 
2023-10-27 09:11:25.552488: Pseudo dice [0.8316, 0.922, 0.9654, 0.3417, 0.7496] 
2023-10-27 09:11:25.552752: Epoch time: 4.38 s 
2023-10-27 09:11:26.939527:  
2023-10-27 09:11:26.939866: Epoch 992 
2023-10-27 09:11:26.940145: Current learning rate: 0.00013 
2023-10-27 09:11:31.322225: train_loss -0.9213 
2023-10-27 09:11:31.322704: val_loss -0.6968 
2023-10-27 09:11:31.323035: Pseudo dice [0.8242, 0.9212, 0.9671, 0.2542, 0.8353] 
2023-10-27 09:11:31.323343: Epoch time: 4.38 s 
2023-10-27 09:11:32.544093:  
2023-10-27 09:11:32.544562: Epoch 993 
2023-10-27 09:11:32.544893: Current learning rate: 0.00011 
2023-10-27 09:11:36.956998: train_loss -0.9162 
2023-10-27 09:11:36.960341: val_loss -0.7032 
2023-10-27 09:11:36.960646: Pseudo dice [0.8333, 0.925, 0.9674, 0.249, 0.7887] 
2023-10-27 09:11:36.960927: Epoch time: 4.41 s 
2023-10-27 09:11:38.169814:  
2023-10-27 09:11:38.170160: Epoch 994 
2023-10-27 09:11:38.170430: Current learning rate: 0.0001 
2023-10-27 09:11:42.561158: train_loss -0.9182 
2023-10-27 09:11:42.561579: val_loss -0.6734 
2023-10-27 09:11:42.561878: Pseudo dice [0.8272, 0.9236, 0.9663, 0.1944, 0.738] 
2023-10-27 09:11:42.562165: Epoch time: 4.39 s 
2023-10-27 09:11:43.772482:  
2023-10-27 09:11:43.772808: Epoch 995 
2023-10-27 09:11:43.773075: Current learning rate: 8e-05 
2023-10-27 09:11:48.221288: train_loss -0.9161 
2023-10-27 09:11:48.221764: val_loss -0.6545 
2023-10-27 09:11:48.222075: Pseudo dice [0.8274, 0.9252, 0.968, 0.1932, 0.6593] 
2023-10-27 09:11:48.222345: Epoch time: 4.45 s 
2023-10-27 09:11:49.440694:  
2023-10-27 09:11:49.441024: Epoch 996 
2023-10-27 09:11:49.441306: Current learning rate: 7e-05 
2023-10-27 09:11:53.807270: train_loss -0.9159 
2023-10-27 09:11:53.807729: val_loss -0.6317 
2023-10-27 09:11:53.808030: Pseudo dice [0.8354, 0.9213, 0.9658, 0.1799, 0.6545] 
2023-10-27 09:11:53.808295: Epoch time: 4.37 s 
2023-10-27 09:11:55.026757:  
2023-10-27 09:11:55.027146: Epoch 997 
2023-10-27 09:11:55.027418: Current learning rate: 5e-05 
2023-10-27 09:11:59.371819: train_loss -0.9175 
2023-10-27 09:11:59.375778: val_loss -0.6653 
2023-10-27 09:11:59.376093: Pseudo dice [0.8401, 0.9229, 0.9654, 0.2876, 0.7437] 
2023-10-27 09:11:59.376536: Epoch time: 4.35 s 
2023-10-27 09:12:00.769276:  
2023-10-27 09:12:00.769620: Epoch 998 
2023-10-27 09:12:00.769878: Current learning rate: 4e-05 
2023-10-27 09:12:05.183712: train_loss -0.9182 
2023-10-27 09:12:05.184211: val_loss -0.6336 
2023-10-27 09:12:05.184526: Pseudo dice [0.8316, 0.9201, 0.9657, 0.253, 0.7066] 
2023-10-27 09:12:05.184801: Epoch time: 4.42 s 
2023-10-27 09:12:06.392489:  
2023-10-27 09:12:06.392894: Epoch 999 
2023-10-27 09:12:06.393450: Current learning rate: 2e-05 
2023-10-27 09:12:10.746897: train_loss -0.9188 
2023-10-27 09:12:10.750414: val_loss -0.6443 
2023-10-27 09:12:10.750700: Pseudo dice [0.8374, 0.9226, 0.9651, 0.2527, 0.6617] 
2023-10-27 09:12:10.750956: Epoch time: 4.36 s 
2023-10-27 09:12:12.122544: Training done. 
2023-10-27 09:12:12.131491: Using splits from existing split file: /workspace/nnUNet_preprocessed/Dataset001_NeedlePhantomV1/splits_final.json 
2023-10-27 09:12:12.132047: The split file contains 5 splits. 
2023-10-27 09:12:12.132261: Desired fold for training: 2 
2023-10-27 09:12:12.132476: This split has 36 training and 8 validation cases. 
2023-10-27 09:12:12.132827: predicting t2_haste_tra_2_2mm_001 
2023-10-27 09:12:12.433819: predicting t2_haste_tra_2_2mm_015 
2023-10-27 09:12:12.481711: predicting t2_haste_tra_2_2mm_018 
2023-10-27 09:12:12.513209: predicting t2_haste_tra_2_2mm_019 
2023-10-27 09:12:12.544703: predicting t2_haste_tra_2_2mm_101 
2023-10-27 09:12:12.576014: predicting t2_haste_tra_2_2mm_115 
2023-10-27 09:12:12.607980: predicting t2_haste_tra_2_2mm_118 
2023-10-27 09:12:12.640351: predicting t2_haste_tra_2_2mm_119 
2023-10-27 09:12:22.007902: Validation complete 
2023-10-27 09:12:22.011343: Mean Validation Dice:  0.6708371630138255 
